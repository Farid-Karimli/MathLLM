CHAPTER
SEVEN
DIFFERENTIATION

In elementary Calculus we learn that integration and differentiation are inverses of each other. This fundamental relation persists to a large extent in the context of the Lebesgue integral. We shall see that some of the most important facts about differentiation of integrals and integration of derivatives can be obtained with a minimum of effort by first studying derivatives of measures and the associated maximal functions. The Radon-Nikodym theorem and the Lebesgue decomposition will play a prominent role.

Derivatives of Measures
We begin with a simple, theorem whose main purpose is to motivate the definitions that follow.
7.1 Theorem Suppose $\mu$ is a complex Borel measure on $R^1$ and
$$
f(x)=\mu((-\infty, x)) \quad\left(x \in R^1\right) .
$$

If $x \in R^1$ and $A$ is a complex number, each of the following two statements implies the other:
(a) $f$ is differentiable at $x$ and $f^{\prime}(x)=A$.
(b) To every $\epsilon>0$ corresponds a $\delta>0$ such that
$$
\left|\frac{\mu(I)}{m(I)}-A\right|<\epsilon
$$
for every open segment $I$ that contains $x$ and whose length is less than $\delta$. Here $m$ denotes Lebesgue measure on $R^1$.
7.2 Definitions Theorem 7.1 suggests that one might define the derivative of $\mu$ at $x$ to be the limit of the quotients $\mu(I) / m(I)$, as the segments $I$ shrink to $x$, and that an analogous definition might be appropriate in several variables, i.e., in $R^k$ rather than in $R^1$.
Accordingly, let us fix a dimension $k$, denote the open ball with center $x \in R^k$ and radius $r>0$ by
$$
B(x, r)=\left\{y \in R^k:|y-x|<r\right\}
$$
(the absolute value indicates the euclidean metric, as in Sec. 2.19), associate to any complex Borel measure $\mu$ on $R^k$ the quotients
$$
\left(Q_r \mu\right)(x)=\frac{\mu(B(x, r))}{m(B(x, r))},
$$
where $m=m_k$ is Lebesgue measure on $R^k$, and define the symmetric derivative of $\mu$ at $x$ to be
$$
(D \mu)(x)=\lim _{r \rightarrow 0}\left(Q_r \mu\right)(x)
$$
at those points $x \in R^k$ at which this limit exists.
We shall study $D \mu$ by means of the maximal function $M \mu$. For $\mu \geq 0$, this is defined by
$$
(M \mu)(x)=\sup _{0<r<\infty}\left(Q_r \mu\right)(x),
$$
and the maximal function of a complex Borel measure $\mu$ is, by definition, that of its total variation $|\mu|$.

The functions $M \mu: R^k \rightarrow[0, \infty]$ are lower semicontinuous, hence measurable.

To see this, assume $\mu \geq 0$, pick $\lambda>0$, let $E=\{M \mu>\lambda\}$, and fix $x \in E$. Then there is an $r>0$ such that
$$
\mu(B(x, r))=\operatorname{tm}(B(x, r))
$$
for some $t>\lambda$, and there is a $\delta>0$ that satisfies
$$
(r+\delta)^k<r^k t / \lambda
$$

If $|y-x|<\delta$, then $B(y, r+\delta) \supset B(x, r)$, and therefore
$$
\mu(B(y, r+\delta)) \geq t m(B(x, r))=t[r /(r+\delta)]^k m(B(y, r+\delta))>\lambda m(B(y, r+\delta)) .
$$

Thus $B(x, \delta) \subset E$. This proves that $E$ is open.
Our first objective is the "maximal theorem" 7.4. The following covering lemma will be used in its proof.

7.3 Lemma If $W$ is the union of a finite collection of balls $B\left(x_i, r_i\right), 1 \leq i \leq N$, then there is a set $S \subset\{1, \ldots, N\}$ so that
(a) the balls $B\left(x_i, r_i\right)$ with $i \in S$ are disjoint,
(b) $W \subset \bigcup_{i \in S} B\left(x_i, 3 r_i\right)$, and
(c) $m(W) \leq 3^k \sum_{i \in S} m\left(B\left(x_i, r_i\right)\right)$.

Proof Order the balls $B_i=B\left(x_i, r_i\right)$ so that $r_1 \geq r_2 \geq \cdots \geq r_N$. Put $i_1=1$. Discard all $B_j$ that intersect $B_{i_1}$. Let $B_{i_2}$ be the first of the remaining $B_j$, if there are any. Discard all $B_j$ with $j>i_2$ that intersect $B_{i_2}$, let $B_{i_3}$ be the first of the remaining ones, and so on, as long as possible. This process stops after a finite number of steps and gives $S=\left\{i_1, i_2, \ldots\right\}$.

It is clear that $(a)$ holds. Every discarded $B_j$ is a subset of $B\left(x_i, 3 r_i\right)$ for some $i \in S$, for if $r^{\prime} \leq r$ and $B\left(x^{\prime}, r^{\prime}\right)$ intersects $B(x, r)$, then $B\left(x^{\prime}, r^{\prime}\right) \subset B(x, 3 r)$. This proves $(b)$, and $(c)$ follows from $(b)$ because in $R^k$.
$$
m(B(x, 3 r))=3^k m(B(x, r))
$$

The following theorem says, roughly speaking, that the maximal function of a measure cannot be large on a large set.
7.4 Theorem If $\mu$ is a complex Borel measure on $R^k$ and $\lambda$ is a positive number, then
$$
m\{M \mu>\lambda\} \leq 3^k \lambda^{-1}\|\mu\| .
$$

Here $\|\mu\|=|\mu|\left(R^k\right)$, and the left side of (1) is an abbreviation for the more cumbersome expression
$$
m\left(\left\{x \in R^k:(M \mu)(x)>\lambda\right\}\right) .
$$

We shall often simplify notation in this way.
ProOF Fix $\mu$ and $\lambda$. Let $K$ be a compact subset of the open set $\{M \mu>\lambda\}$. Each $x \in K$ is the center of an open ball $B$ for which
$$
|\mu|(B)>\lambda m(B) \text {. }
$$

Some finite collection of these $B$ 's covers $K$, and Lemma 7.3 gives us a disjoint subcollection, say $\left\{B_1, \ldots, B_n\right\}$, that satisfies
$$
m(K) \leq 3^k \sum_1^n m\left(B_i\right) \leq 3^k \lambda^{-1} \sum_1^n|\mu|\left(B_i\right) \leq 3^k \lambda^{-1}\|\mu\| .
$$

The disjointness of $\left\{B_1, \ldots, B_n\right\}$ was used in the last inequality.
Now (1) follows by taking the supremum over all compact $K \subset\{M \mu>\lambda\}$.

7.5 Weak $L^1$ If $f \in L^1\left(R^k\right)$ and $\lambda>0$, then
$$
m\{|f|>\lambda\} \leq \lambda^{-1}\|f\|_1
$$
because, putting $E=\{|f|>\lambda\}$, we have
$$
\lambda m(E) \leq \int_E|f| d m \leq \int_{R^k}|f| d m=\|f\|_1 .
$$

Accordingly, any measurable function $f$ for which
$$
\lambda \cdot m\{|f|>\lambda\}
$$
is a bounded function of $\lambda$ on $(0, \infty)$ is said to belong to weak $L^1$.
Thus weak $L^1$ contains $L^1$. That it is actually larger is shown most simply by the function $1 / x$ on $(0,1)$.

We associate to each $f \in L^1\left(R^k\right)$ its maximal function $M f: R^k \rightarrow[0, \infty]$, by setting
$$
(M f)(x)=\sup _{0<r<\infty} \frac{1}{m\left(B_r\right)} \int_{B(x, r)}|f| d m .
$$
[We wrote $B_r$ in place of $B(x, r)$ because $m(B(x, r))$ depends only on the radius $r$.] If we identify $f$ with the measure $\mu$ given by $d \mu=f d m$, we see that (4) agrees with the previously defined $M \mu$. Theorem 7.4 states therefore that the "maximal operator" $M$ sends $L^1$ to weak $L^1$, with a bound (namely $3^k$ ) that depends only on the space $R^k$ :
For every $f \in L^1\left(R^k\right)$ and every $\lambda>0$,
$$
m\{M f>\lambda\} \leq 3^k \lambda^{-1}\|f\|_1 .
$$
7.6 Lebesgue points If $f \in L^1\left(R^k\right)$, any $x \in R^k$ for which it is true that
$$
\lim _{r \rightarrow 0} \frac{1}{m\left(B_r\right)} \int_{B(x, r)}|f(y)-f(x)| d m(y)=0
$$
is called a Lebesgue point of $f$.
For example, (1) holds if $f$ is continuous at the point $x$. In general, (1) means that the averages of $|f-f(x)|$ are small on small balls centered at $x$. The Lebesgue points of $f$ are thus points where $f$ does not oscillate too much, in an average sense.

It is probably far from obvious that every $f \in L^1$ has Lebesgue points. But the following remarkable theorem shows that they always exist. (See also Exercise 23.)
7.7 Theorem If $f \in L^1\left(R^k\right)$, then almost every $x \in R^k$ is a Lebesgue point of $f$.

DIFFERENTIATION 139

Proof Define
$$
\left(T_r f\right)(x)=\frac{1}{m\left(B_r\right)} \int_{B(x, r)}|f-f(x)| d m
$$
for $x \in R^k, r>0$, and put
$$
(T f)(x)=\lim _{r \rightarrow 0} \sup \left(T_r f\right)(x) .
$$

We have to prove that $T f=0$ a.e. $[m]$.
Pick $y>0$. Let $n$ be a positive integer. By Theorem 3.14, there exists $g \in C\left(R^k\right)$ so that $\|f-g\|_1<1 / n$ : Put $h=f-g$.
Since $g$ is continuous, $T g=0$. Since
$$
\left(T_r h\right)(x) \leq \frac{1}{m\left(B_r\right)} \int_{B(x, r)}|h| d m+|h(x)|
$$
we have
$$
T h \leq M h+|h| .
$$

Since $T_r f \leq T_r g+T_r h$, it follows that
$$
T f \leq M h+|h| .
$$

Therefore
$$
\{T f>2 y\} \subset\{M h>y\} \cup\{|h|>y\} .
$$

Denote the union on the right of (6) by $E(y, n)$. Since $\|h\|_1<1 / n$, Theorem 7.4 and the inequality $7.5(1)$ show that
$$
m(E(y, n)) \leq\left(3^k+1\right) /(y n) .
$$

The left side of (6) is independent of $n$. Hence
$$
\{T f>2 y\} \subset \bigcap_{n=1}^{\infty} E(y, n) .
$$

This intersection has measure 0 , by (7), so that $\{T f>2 y\}$ is a subset of a set of measure 0 . Since Lebesgue measure is complete, $\{T f>2 y\}$ is Lebesgue measurable, and has measure 0 . This holds for every positive $y$. Hence $T f=0$ a.e. $[m]$.
$/ / /$

Theorem 7.7 yields interesting information, with very little effort, about topics such as
(a) differentiation of absolutely continuous measures,
(b) differentiation using sets other than balls,
(c) differentiation of indefinite integrals in $R^1$,
(d) metric density of measurable sets.

We shall now discuss these topics.
7.8 Theorem Suppose $\mu$ is a complex Borel measure on $R^k$, and $\mu \ll m$. Let $f$ be the Radon-Nikodym derivative of $\mu$ with respect to $m$. Then $D \mu=f$ a.e. $[m]$, and
$$
\mu(E)=\int_E(D \mu) d m
$$
for all Borel sets $E \subset R^k$.
In other words, the Radon-Nikodym derivative can also be obtained as a limit of the quotients $Q_r \mu$.
Proof The Radon-Nikodym theorem asserts that (1) holds with $f$ in place of $D \mu$. At any Lebesgue point $x$ of $f$, it follows that
$$
f(x)=\lim _{r \rightarrow 0} \frac{1}{m\left(B_r\right)} \int_{B(x, r)} f d m=\lim _{r \rightarrow 0} \frac{\mu(B(x, r))}{m(B(x, r))} .
$$

Thus $(D \mu)(x)$ exists and equals $f(x)$ at every Lebesgue point of $f$, hence a.e. $[m]$.
$/ / /$
7.9 Nicely shrinking sets Suppose $x \in R^k$. A sequence $\left\{E_i\right\}$ of Borel sets in $R^k$ is said to shrink to $x$ nicely if there is a number $\alpha>0$ with the following property: There is a sequence of balls $B\left(x, r_i\right)$, with $\lim r_i=0$, such that $E_i \subset B\left(x, r_i\right)$ and
$$
m\left(E_i\right) \geq \alpha \cdot m\left(B\left(x, r_i\right)\right)
$$
for $i=1,2,3, \ldots$.
Note that it is not required that $x \in E_i$, nor even that $x$ be in the closure of $E_i$. Condition (1) is a quantitative version of the requirement that each $E_i$ must occupy a substantial portion of some spherical neighborhood of $x$. For example, a nested sequence of $k$-cells whose longest edge is at most 1,000 times as long as its shortest edge and whose diameter tends to 0 shrinks nicely. A nested sequence of rectangles (in $R^2$ ) whose edges have lengths $1 / i$ and $(1 / i)^2$ does not shrink nicely.
7.10 Theorem Associate to each $x \in R^k$ a sequence $\left\{E_i(x)\right\}$ that shrinks to $x$ nicely, and let $f \in L^1\left(R^k\right)$. Then
$$
f(x)=\lim _{i \rightarrow \infty} \frac{1}{m\left(E_i(x)\right)} \int_{E_i(x)} f d m
$$
at every Lebesgue point of $f$, hence a.e. $[m]$.

Proof Let $x$ be a Lebesgue point of $f$ and let $\alpha(x)$ and $B\left(x, r_i\right)$ be the positive number and the balls that are associated to the sequence $\left\{E_i(x)\right\}$. Then, because $E_i(x) \subset B\left(x, r_i\right)$,
$$
\frac{\alpha(x)}{m\left(E_i(x)\right)} \int_{E_i(x)}|f-f(x)| d m \leq \frac{1}{m\left(B\left(x, r_i\right)\right)} \int_{B\left(x, r_i\right)}|f-f(x)| d m .
$$

The right side converges to 0 as $i \rightarrow \infty$, because $r_i \rightarrow 0$ and $x$ is a Lebesgue point of $f$. Hence the left side converges to 0 , and (1) follows.

Note that no relation of any sort was assumed to exist between $\left\{E_i(x)\right\}$ and $\left\{E_i(y)\right\}$, for different points $x$ and $y$.

Note also that Theorem 7.10 leads to a correspondingly stronger form of Theorem 7.8. We omit the details.
7.11 Theorem If $f \in L^1\left(R^1\right)$ and
$$
F(x)=\int_{-\infty}^x f d m \quad(-\infty<x<\infty),
$$
then $F^{\prime}(x)=f(x)$ at every Lebesgue point of $f$, hence a.e. $[m]$.
(This is the easy half of the fundamental theorem of Calculus, extended to Lebesgue integrals.)
ProOF Let $\left\{\delta_i\right\}$ be a sequence of positive numbers that converges to 0 . Theorem 7.10, with $E_i(x)=\left[x, x+\delta_i\right]$, shows then that the right-hand derivative of $F$ exists at all Lebesgue points of $x$ of $f$ and that it is equal to $f(x)$ at these points. If we let $E_i(x)$ be $\left[x-\delta_i, x\right]$ instead, we obtain the same result for the left-hand derivative of $F$ at $x$.
//I
7.12 Metric density Let $E$ be a Lebesgue measurable subset of $R^k$. The metric density of $E$ at a point $x \in R^k$ is defined to be
$$
\lim _{r \rightarrow 0} \frac{m(E \cap B(x, r))}{m(B(x, r))}
$$
provided, of course, that this limit exists.
If we let $f$ be the characteristic function of $E$ and apply Theorem 7.8 or Theorem 7.10, we see that the metric density of $E$ is 1 at almost every point of $E$, and that it is 0 at almost every point of the complement of $E$.

Here is a rather striking consequence of this, which should be compared with Exercise 8 in Chap. 2:
If $\epsilon>0$, there is no set $E \subset R^1$ that satisfies
$$
\epsilon<\frac{m(E \cap I)}{m(I)}<1-\epsilon
$$
for every segment $I$.

Having dealt with differentiation of absolutely continuous measures, we now turn to those that are singular with respect to $m$.
7.13 Theorem Associate to each $x \in R^k$ a sequence $\left\{E_i(x)\right\}$ that shrinks to $x$ nicely. If $\mu$ is a complex Borel measure and $\mu \perp m$, then
$$
\lim _{i \rightarrow \infty} \frac{\mu\left(E_i(x)\right)}{m\left(E_i(x)\right)}=0 \quad \text { a.e. }[m] .
$$

Proof The Jordan decomposition theorem shows that it suffices to prove (1) under the additional assumption that $\mu \geq 0$. In that case, arguing as in the proof of Theorem 7.10, we have
$$
\frac{\alpha(x) \mu\left(E_i(x)\right)}{m\left(E_i(x)\right)} \leq \frac{\mu\left(E_i(x)\right)}{m\left(B\left(x, r_i\right)\right)} \leq \frac{\mu\left(B\left(x, r_i\right)\right)}{m\left(B\left(x, r_i\right)\right)} .
$$

Hence (1) is a consequence of the special case
$$
(D \mu)(x)=0 \quad \text { a.e. }[m],
$$
which will now be proved.
The upper derivative $\bar{D} \mu$, defined by
$$
(\bar{D} \mu)(x)=\lim _{n \rightarrow \infty}\left[\sup _{0<r<1 / n}\left(Q_r \mu\right)(x)\right] \quad\left(x \in R^k\right)
$$
is a Borel function, because the quantity in brackets decreases as $n$ increases and is, for each $n$, a lower semicontinuous function of $x$; the reasoning used in Sec. 7.2 proves this.

Choose $\lambda>0, \epsilon>0$. Since $\mu \perp m, \mu$ is concentrated on a set of Lebesgue measure 0 . The regularity of $\mu$ (Theorem 2.18) shows therefore that there is a compact set $K$, with $m(K)=0, \mu(K)>\|\mu\|-\epsilon$.

Define $\mu_1(E)=\mu(K \cap E)$, for any Borel set $E \subset R^k$, and put $\mu_2=\mu-\mu_1$. Then $\left\|\mu_2\right\|<\epsilon$, and, for every $x$ outside $K$,
$$
(\bar{D} \mu)(x)=\left(\bar{D} \mu_2\right)(x) \leq\left(M \mu_2\right)(x) .
$$

Hence
$$
\{\bar{D} \mu>\lambda\} \subset K \cup\left\{M \mu_2>\lambda\right\},
$$
and Theorem 7.4 shows that
$$
m\{\bar{D} \mu>\lambda\} \leq 3^k \lambda^{-1}\left\|\mu_2\right\|<3^k \lambda^{-1} \epsilon .
$$

Since (6) holds for every $\epsilon>0$ and for every $\lambda>0$, we conclude that $\bar{D} \mu=0$ a.e. $[m]$, i.e., that (2) holds.

Theorems 7.10 and 7.13 can be combined in the following way:


7.14 Theorem Suppose that to each $x \in R^k$ is associated some sequence $\left\{E_i(x)\right\}$ that shrinks to $x$ nicely, and that $\mu$ is a complex Borel measure on $R^k$.

Let $d \mu=f d m+d \mu_s$ be the Lebesgue decomposition of $\mu$ with respect to $m$. Then
$$
\lim _{i \rightarrow \infty} \frac{\mu\left(E_i(x)\right)}{m\left(E_i(x)\right)}=f(x) \quad \text { a.e. }[m] .
$$

In particular, $\mu \perp m$ if and only if $(D \mu)(x)=0$ a.e. $[m]$.
The following result contrasts strongly with Theorem 7.13:
7.15 Theorem If $\mu$ is a positive Borel measure on $R^k$ and $\mu \perp m$, then
$$
(D \mu)(x)=\infty \quad \text { a.e. }[\mu] .
$$

Proof There is a Borel set $S \subset R^k$ with $m(S)=0$ and $\mu\left(R^k-S\right)=0$, and there are open sets $V_j \supset S$ with $m\left(V_j\right)<1 / j$, for $j=1,2,3, \ldots$.

For $N=1,2,3, \ldots$, let $E_N$ be the set of all $x \in S$ to which correspond radii $r_i=r_i(x)$, with $\lim r_i=0$, such that
$$
\mu\left(B\left(x, r_i\right)\right)<N m\left(B\left(x, r_i\right)\right) .
$$

Then (1) holds for every $x \in S-\bigcup_N E_N$.
Fix $N$ and $j$, for the moment. Every $x \in E_N$ is then the center of a ball $B_x \subset V_j$ that satisfies (2). Let $\beta_x$ be the open ball with center $x$ whose radius is $1 / 3$ of that of $B_x$. The union of these balls $\beta_x$ is an open set $W_{j, N}$ that contains $E_N$ and lies in $V_j$. We claim that
$$
\mu\left(\boldsymbol{W}_{j, N}\right)<3^k N / j
$$

To prove (3), let $K \subset W_{j, N}$ be compact. Finitely many $\beta_x$ cover $K$. Lemma 7.3 shows therefore that there is a finite set $F \subset E_N$ with the following properties:
(a) $\left\{\beta_x: x \in F\right\}$ is a disjoint collection, and
(b) $K \subset \bigcup_{x \in F} B_x$.

Thus
$$
\begin{aligned}
\mu(K) & \leq \sum_{x \in F} \mu\left(B_x\right)<N \sum_{x \in F} m\left(B_x\right) \\
& =3^k N \sum_{x \in F} m\left(\beta_x\right) \leq 3^k N m\left(V_j\right)<3^k N / j .
\end{aligned}
$$

This proves (3).
Now put $\Omega_N=\bigcap_j W_{j, N}$. Then $E_N \subset \Omega_N, \Omega_N$ is a $G_\delta, \mu\left(\Omega_N\right)=0$, and $(D \mu)(x)=\infty$ at every point of $S-\bigcup_N \Omega_N$.


The Fundamental Theorem of Calculus
7.16 This theorem concerns functions defined on some compact interval $[a, b]$ in $R^1$. It has two parts. The first asserts, roughly speaking, that the derivative of the indefinite integral of a function is that same function. We dealt with this in Theorem 7.11. The second part goes the other way: one returns to the original function by integrating its derivative. More precisely
$$
f(x)-f(a)=\int_a^x f^{\prime}(t) d t \quad(a \leq x \leq b)
$$

In the elementary version of this theorem, one assumes that $f$ is differentiable at every point of $[a, b]$ and that $f^{\prime}$ is a continuous function. The proof of (1) is then easy.

In trying to extend (1) to the setting of the Lebesgue integral, questions such as the following come up naturally:
Is it enough to assume that $f^{\prime} \in L^1$, rather than that $f^{\prime}$ is continuous?
If $f$ is continuous and differentiable at almost all points of $[a, b]$, must (1) then hold?

Before proving any positive results, here are two examples that show how (1) can fail.
(a) Put $f(x)=x^2 \sin \left(x^{-2}\right)$ if $x \neq 0, f(0)=0$. Then $f$ is differentiable at every point, but
$$
\int_0^1\left|f^{\prime}(t)\right| d t=\infty
$$
so $f^{\prime} \notin L^1$.
If we interpret the integral in (1) (with $[0,1]$ in place of $[a, b]$ ) as the limit, as $\epsilon \rightarrow 0$, of the integrals over $[\epsilon, 1]$, then (1) still holds for this $f$.

More complicated situations can arise where this kind of passage to the limit is of no use. There are integration processes, due to Denjoy and Perron (see [18], [28]), which are so designed that (1) holds whenever $f$ is differentiable at every point. These fail to have the property that the integrability of $f$ implies that of $|f|$, and therefore do not play such an important role in analysis.
(b) Suppose $f$ is continuous on $[a, b], f$ is differentiable at almost every point of $[a, b]$, and $f^{\prime} \in L^1$ on $[a, b]$. Do these assumptions imply that (1) holds?
Answer: No.
Choose $\left\{\delta_n\right\}$ so that $1=\delta_0>\delta_1>\delta_2>\cdots, \delta_n \rightarrow 0$. Put $E_0=[0,1]$. Suppose $n \geq 0$ and $E_n$ is constructed so that $E_n$ is the union of $2^n$ disjoint closed intervals, each of length $2^{-n} \delta_n$. Delete a segment in the center of each of these $2^n$ intervals, so that each of the remaining $2^{n+1}$ intervals has length $2^{-n-1} \delta_{n+1}$ (this is possible, since $\delta_{n+1}<\delta_n$ ), and let $E_{n+1}$ be the union of these $2^{n+1}$ intervals. Then $E_1 \supset E_2 \supset \cdots, m\left(E_n\right)=\delta_n$, and if
$$
E=\bigcap_{n=1}^{\infty} E_n,
$$
then $E$ is compact and $m(E)=0$. (In fact, $E$ is perfect.) Put
$$
g_n=\delta_n^{-1} \chi_{\dot{E}_n} \quad \text { and } \quad f_n(x)=\int_0^x g_n(t) d t \quad(n=0,1,2, \ldots) .
$$

Then $f_n(0)=0, f_n(1)=1$, and each $f_n$ is a monotonic function which is constant on each segment in the complement of $E_n$. If $I$ is one of the $2^n$ intervals whose union is $E_n$, then
$$
\int_I g_n(t) d t=\int_I g_{n+1}(t) d t=2^{-n}
$$

It follows from (5) that
$$
f_{n+1}(x)=f_n(x) \quad\left(x \notin E_n\right)
$$
and that
$$
\left|f_n(x)-f_{n+1}(x)\right| \leq \int_I\left|g_n-g_{n+1}\right|<2^{-n+1} \quad\left(x \in E_n\right) .
$$

Hence $\left\{f_n\right\}$ converges uniformly to a continuous monotonic function $f$, with $f(0)=0, f(1)=1$, and $f^{\prime}(x)=0$ for all $x \notin E$. Since $m(E)=0$, we have $f^{\prime}=0$ a.e.
Thus (1) fails.
If $\delta_n=(2 / 3)^n$, the set $E$ is Cantor's "middle thirds" set.

Having seen what can go wrong, assume now that $f^{\prime} \in L^1$ and that (1) does hold. There is then a measure $\mu$, defined by $d \mu=f^{\prime} d m$. Since $\mu \ll m$, Theorem 6.11 shows that there corresponds to each $\epsilon>0$ a $\delta>0$ so that $|\mu|(E)<\epsilon$ whenever $E$ is a union of disjoint segments whose total length is less than $\delta$. Since $f(y)-f(x)=\mu((x, y))$ if $a \leq x<y \leq b$, it follows that the absolute continuity of $f$, as defined below, is necessary for (1). Theorem 7.20 will show that this necessary condition is also sufficient.
7.17 Definition A complex function $f$, defined on an interval $I=[a, b]$, is said to be absolutely continuous on $I$ (briefly, $f$ is $\mathrm{AC}$ on $I$ ) if there corresponds to every $\epsilon>0$ a $\delta>0$ so that
$$
\sum_{i=1}^n\left|f\left(\beta_i\right)-f\left(\alpha_i\right)\right|<\epsilon
$$
for any $n$ and any disjoint collection of segments $\left(\alpha_1, \beta_1\right), \ldots,\left(\alpha_n, \beta_n\right)$ in $I$ whose lengths satisfy
$$
\sum_{i=1}^n\left(\beta_i-\alpha_i\right)<\delta
$$

Such an $f$ is obviously continuous: simply take $n=1$.
In the following theorem, the implication $(b) \rightarrow(c)$ is probably the most interesting. That $(a) \rightarrow(c)$ without assuming monotonicity of $f$ is the content of Theorem 7.20.
7.18 Theorem Let $I=[a, b]$, let $f: I \rightarrow R^1$ be continuous and nondecreasing. Each of the following three statements about $f$ implies the other two:
(a) $f$ is $\mathrm{AC}$ on $I$.
(b) $f$ maps sets of measure 0 to sets of measure 0 .
(c) $f$ is differentiable a.e. on $I, f^{\prime} \in L^1$, and
$$
f(x)-f(a)=\int_a^x f^{\prime}(t) d t \quad(\alpha \leq x \leq b) .
$$

Note that the functions constructed in Example 7.16(b) map certain compact sets of measure 0 onto the whole unit interval!
Exercise 12 complements this theorem.
Proof We will show that $(a) \rightarrow(b) \rightarrow(c) \rightarrow(a)$.
Let $\mathfrak{M}$ denote the $\sigma$-algebra of all Lebesgue measurable subsets of $R^1$.
Assume $f$ is AC on $I$, pick $E \subset I$ so that $E \in \mathfrak{M}$ and $m(E)=0$. We have to show that $f(E) \in \mathfrak{M}$ and $m(f(E))=0$. Without loss of generality, assume that neither $a$ nor $b$ lie in $E$.
Choose $\epsilon>0$. Associate $\delta>0$ to $f$ and $\epsilon$, as in Definition 7.17. There is then an open set $V$ with $m(V)<\delta$, so that $E \subset V \subset I$. Let $\left(\alpha_i, \beta_i\right)$ be the disjoint segments whose union is $V$. Then $\sum\left(\beta_i-\alpha_i\right)<\delta$, and our choice of $\delta$ shows that therefore
$$
\sum_i\left(f\left(\beta_i\right)-f\left(\alpha_i\right)\right) \leq \epsilon
$$
[Definition 7.17 was stated in terms of finite sums; thus (2) holds for every partial sum of the (possibly) infinite series, hence (2) holds also for the sum of the whole series, as stated.]

Since $E \subset V, f(E) \subset \bigcup\left[f\left(\alpha_i\right), f\left(\beta_i\right)\right]$. The Lebesgue measure of this union is the left side of (2). This says that $f(E)$ is a subset of Borel sets of arbitrarily small measure. Since Lebesgue measure is complete, it follows that $f(E) \in \mathfrak{M}$ and $m(f(E))=0$.
We have now proved that $(a)$ implies $(b)$.

Assume next that $(b)$ holds. Define
$$
g(x)=x+f(x) \quad(a \leq x \leq b) .
$$

If the $f$-image of some segment of length $\eta$ has length $\eta^{\prime}$, then the $g$-image of that same segment has length $\eta+\eta^{\prime}$. From this it follows easily that $g$ satisfies $(b)$, since $f$ does.

Now suppose $E \subset I, E \in \mathfrak{M}$. Then $E=E_1 \cup E_0$ where $m\left(E_0\right)=0$ and $E_1$ is an $F_\sigma$ (Theorem 2.20). Thus $E_1$ is a countable union of compact sets, and so is $g\left(E_1\right)$, because $g$ is continuous. Since $g$ satisfies $(b), m\left(g\left(E_0\right)\right)=0$. Since $g(E)=g\left(E_1\right) \cup g\left(E_0\right)$, we conclude: $g(E) \in \mathfrak{M}$.
Therefore we can define
$$
\mu(E)=m(g(E)) \quad(E \subset I, E \in \mathfrak{M}) .
$$

Since $g$ is one-to-one (this is our reason for working with $g$ rather than $f$ ), disjoint sets in $I$ have disjoint $g$-images. The countable additivity of $m$ shows therefore that $\mu$ is a (positive, bounded) measure on $\mathfrak{M}$. Also, $\mu \ll m$, because $g$ satisfies $(b)$. Thus
$$
d \mu=h d m
$$
for some $h \in L^1(m)$, by the Radon-Nikodym theorem.
If $E=[a, x]$, then $g(E)=[g(a), g(x)]$, and (5) gives
$$
g(x)-g(a)=m(g(E))=\mu(E)=\int_E h d m=\int_a^x h(t) d t .
$$

If we now use (3), we conclude that
$$
f(x)-f(a)=\int_a^x[h(t)-1] d t \quad(\alpha \leq x \leq b) .
$$

Thus $f^{\prime}(x)=h(x)-1$ a.e. $[m]$, by Theorem 7.11.
We have now proved that $(b)$ implies $(c)$.
The discussion that preceded Definition 7.17 showed that $(c)$ implies $(a)$.

7.19 Theorem Suppose $f: I \rightarrow R^1$ is $\mathrm{AC}, I=[a, b]$. Define
$$
F(x)=\sup \sum_{i=1}^N\left|f\left(t_i\right)-f\left(t_{i-1}\right)\right| \quad(a \leq x \leq b)
$$
where the supremum is taken over all $N$ and over all choices of $\left\{t_i\right\}$ such that
$$
a=t_0<t_1<\cdots<t_N=x .
$$

The functions $F, F+f, F-f$ are then nondecreasing and $\mathrm{AC}$ on $I$.

[ $F$ is called the total variation function of $f$. If $f$ is any (complex) function on $I$, $\mathrm{AC}$ or not, and $F(b)<\infty$, then $f$ is said to have bounded variation on $I$, and $F(b)$ is the total variation of $f$ on $I$. Exercise 13 is relevant to this.]
Proof If (2) holds and $x<y \leq b$, then
$$
F(y) \geq|f(y)-f(x)|+\sum_{i=1}^N\left|f\left(t_i\right)-f\left(t_{i-1}\right)\right| .
$$

Hence $F(y) \geq|f(y)-f(x)|+F(x)$. In particular
$$
F(y) \geq f(y)-f(x)+F(x) \text { and } F(y) \geq f(x)-f(y)+F(x) .
$$

This proves that $F, F+f, F-f$ are nondecreasing.
Since sums of two AC functions are obviously AC, it only remains to be proved that $F$ is $\mathrm{AC}$ on $I$.
If $(a, \beta) \subset I$ then
$$
F(\beta)-F(\alpha)=\sup \sum_1^n\left|f\left(t_i\right)-f\left(t_{i-1}\right)\right|,
$$
the supremum being taken over all $\left\{t_i\right\}$ that satisfy $\alpha=t_0<\cdots<t_n=\beta$.
Note that $\sum\left(t_i-t_{i-1}\right)=\beta-\alpha$.
Now pick $\epsilon>0$, associate $\delta>0$ to $f$ and $\epsilon$ as in Definition 7.17, choose disjoint segments $\left(\alpha_j, \beta_j\right) \subset I$ with $\sum\left(\beta_j-\alpha_j\right)<\delta$, and apply (5) to each $\left(\alpha_j, \beta_j\right)$. It follows that
$$
\sum_j\left(F\left(\beta_j\right)-F\left(\alpha_j\right)\right) \leq \epsilon
$$
by our choice of $\delta$. Thus $F$ is AC on $I$.

We have now reached our main objective:
7.20 Theorem If $f$ is a complex function that is $\mathrm{AC}$ on $I=[a, b]$, then $f$ is differentiable at almost all points of $I, f^{\prime} \in L^1(m)$, and
$$
f(x)-f(a)=\int_a^x f^{\prime}(t) d t \quad(a \leq x \leq b) .
$$

Proof It is of course enough to prove this for real $f$. Let $F$ be its total variation function, as in Theorem 7.19, define
$$
f_1=\frac{1}{2}(F+f), \quad f_2=\frac{1}{2}(F-f),
$$
and apply the implication $(a) \rightarrow(c)$ of Theorem 7.18 to $f_1$ and $f_2$. Since
$$
f=f_1-f_2
$$
this yields (1).


The next theorem derives (1) from a different set of hypotheses, by an entirely different method of proof.
7.21 Theorem If $f:[a, b] \rightarrow R^1$ is differentiable at every point of $[a, b]$ and $f^{\prime} \in L^1$ on $[a, b]$, then
$$
f(x)-f(a)=\int_a^x f^{\prime}(t) d t \quad(a \leq x \leq b) .
$$

Note that differentiability is assumed to hold at every point of $[a, b]$.
Proof It is clear that it is enough to prove this for $x=b$. Fix $\epsilon>0$. Theorem 2.25 ensures the existence of a lower semicontinuous function $g$ on $[a, b]$ such that $g>f^{\prime}$ and
$$
\int_a^b g(t) d t<\int_a^b f^{\prime}(t) d t+\epsilon
$$

Actually, Theorem 2.25 only gives $g \geq f^{\prime}$, but since $m([a, b])<\infty$, we can add a small constant to $g$ without affecting (2). For any $\eta>0$, define
$$
F_\eta(x)=\int_a^x g(t) d t-f(x)+f(a)+\eta(x-a) \quad(a \leq x \leq b) .
$$

Keep $\eta$ fixed for the moment. To each $x \in[a, b)$ there corresponds a $\delta_x>0$ such that
$$
g(t)>f^{\prime}(x) \text { and } \frac{f(t)-f(x)}{t-x}<f^{\prime}(x)+\eta
$$
for all $t \in\left(x, x+\delta_x\right)$, since $g$ is lower semicontinuous and $g(x)>f^{\prime}(x)$. For any such $t$ we therefore have
$$
\begin{aligned}
F_\eta(t)-F_\eta(x) & =\int_x^t g(s) d s-[f(t)-f(x)]+\eta(t-x) \\
& >(t-x) f^{\prime}(x)-(t-x)\left[f^{\prime}(x)+\eta\right]+\eta(t-x)=0 .
\end{aligned}
$$

Since $F_\eta(a)=0$ and $F_\eta$ is continuous, there is a last point $x \in[a, b]$ at which $F_\eta(x)=0$. If $x<b$, the preceding computation implies that $F_\eta(t)>0$ for $t \in(x, b]$. In any case, $F_\eta(b) \geq 0$. Since this holds for every $\eta>0$, (2) and (3) now give
$$
f(b)-f(a) \leq \int_a^b g(t) d t<\int_a^b f^{\prime}(t) d t+\epsilon,
$$
and since $\epsilon$ was arbitrary, we conclude that
$$
f(b)-f(a) \leq \int_a^b f^{\prime}(t) d t
$$

If $f$ satisfies the hypotheses of the theorem, so does $-f$; therefore (6) holds with $-f$ in place of $f$, and these two inequalities together give (1). ////

Differentiable Transformations
7.22 Definitions Suppose $V$ is an open set in $R^k, T$ maps $V$ into $R^k$, and $x \in V$. If there exists a linear operator $A$ on $R^k$ (i.e., a linear mapping of $R^k$ into $R^k$, as in Definition 2.1) such that
$$
\lim _{h \rightarrow 0} \frac{|T(x+h)-T(x)-A h|}{|h|}=0
$$
(where, of course, $h \in R^k$ ), then we say that $T$ is differentiable at $x$, and define
$$
T^{\prime}(x)=A \text {. }
$$

The linear operator $T^{\prime}(x)$ is called the derivative of $T$ at $x$. (One shows easily that there is at most one linear $A$ that satisfies the preceding requirements; thus it is legitimate to talk about the derivative of $T$.) The term differential is also often used for $T^{\prime}(x)$.

The point of (1) is of course that the difference $T(x+h)-T(x)$ is approximated by $T^{\prime}(x) h$, a linear function of $h$.

Since every real number $\alpha$ gives rise to a linear operator on $R^1$ (mapping $h$ to $\alpha h$ ), our definition of $T^{\prime}(x)$ coincides with the usual one when $k=1$.

When $A: R^k \rightarrow R^k$ is linear, Theorem $2.20(e)$ shows that there is a number $\Delta(A)$ such that
$$
m(A(E))=\Delta(A) m(E)
$$
for all measurable sets $E \subset R^k$. Since
$$
A^{\prime}(x)=A \quad\left(x \in R^k\right)
$$
and since every differentiable transformation $T$ can be locally approximated by a constant plus a linear transformation, one may conjecture that
$$
\frac{m(T(E))}{m(E)} \sim \Delta\left(T^{\prime}(x)\right)
$$
for suitable sets $E$ that are close to $x$. This will be proved in Theorem 7.24, and furnishes the motivation for Theorem 7.26.

Recall that $\Delta(A)=|\operatorname{det} A|$ was proved in Sec. 2.23. When $T$ is differentiable at $x$, the determinant of $T^{\prime}(x)$ is called the Jacobian of $T$ at $x$, and is denoted by $J_T(x)$. Thus
$$
\Delta\left(T^{\prime}(x)\right)=\left|J_T(x)\right| .
$$

The following lemma seems geometrically obvious. Its proof depends on the Brouwer fixed point theorem. One can avoid the use of this theorem by imposing stronger hypotheses on $F$, for example, by assuming that $F$ is an open mapping. But this would lead to unnecessarily strong assumptions in Theorem 7.26.
7.23 Lemma Let $S=\{x:|x|=1\}$ be the sphere in $R^k$ that is the boundary of the open unit ball $B=B(0,1)$.
If $F: \bar{B} \rightarrow R^k$ is continuous, $0<\epsilon<1$, and
$$
|F(x)-x|<\epsilon
$$
for all $x \in S$, then $F(B) \supset B(0,1-\epsilon)$.
ProOf Assume, to reach a contradiction, that some point $a \in B(0,1-\epsilon)$ is not in $F(B)$. By (1), $|F(x)|>1-\epsilon$ if $x \in S$. Thus $a$ is not in $F(S)$, and therefore $a \neq F(x)$, for every $x \in \bar{B}$. This enables us to define a continuous map $G: \bar{B} \rightarrow \bar{B}$ by
$$
G(x)=\frac{a-F(x)}{|a-F(x)|} .
$$

If $x \in S$, then $x \cdot x=|x|^2=1$, so that
$$
x \cdot(a-F(x))=x \cdot a+x \cdot(x-F(x))-1<|a|+\epsilon-1<0 .
$$

This shows that $x \cdot G(x)<0$, hence $x \neq G(x)$.
If $x \in B$, then obviously $x \neq G(x)$, simply because $G(x) \in S$.
Thus $G$ fixes no point of $\bar{B}$, contrary to Brouwer's theorem which states that every continuous map of $\bar{B}$ into $\bar{B}$ has at least one fixed point. 

A proof of Brouwer's theorem that is both elementary and simple may be found on pp. 38-40 of "Dimension Theory" by Hurewicz and Wallman, Princeton University Press, 1948.
7.24 Theorem If
(a) $V$ is open in $R^k$,
(b) $T: V \rightarrow R^k$ is continuous, and
(c) $T$ is differentiable at some point $x \in V$, then
$$
\lim _{r \rightarrow 0} \frac{m(T(B(x, r)))}{m(B(x, r))}=\Delta\left(T^{\prime}(x)\right)
$$

Note that $T(B(x, r))$ is Lebesgue measurable; in fact, it is $\sigma$-compact, because $B(x, r)$ is $\sigma$-compact and $T$ is continuous.
Proof Assume, without loss of generality, that $x=0$ and $T(x)=0$. Put $A=T^{\prime}(0)$.
The following elementary fact about linear operators on finitedimensional vector spaces will be used: $A$ linear operator $A$ on $R^k$ is one-to-one if and only if the range of $A$ is all of $R^k$. In that case, the inverse $A^{-1}$ of $A$ is also linear.
Accordingly, we split the proof into two cases.
CASE I $A$ is one-to-one. Define
$$
F(x)=A^{-1} T(x) \quad(x \in V) .
$$

Then $F^{\prime}(0)=A^{-1} T^{\prime}(0)=A^{-1} A=I$, the identity operator. We shall prove that
$$
\lim _{r \rightarrow 0} \frac{m(F(B(0, r)))}{m(B(0, r))}=1
$$

Since $T(x)=A F(x)$, we have
$$
m(T(B))=m(A(F(B)))=\Delta(A) m(F(B))
$$
for every ball $B$, by $7.22(3)$. Hence (3) will give the desired result.
Choose $\epsilon>0$. Since $F(0)=0$ and $F^{\prime}(0)=I$, there exists a $\delta>0$ such that $0<|x|<\delta$ implies
$$
|F(x)-x|<\epsilon|x|
$$

We claim that the inclusions
$$
B(0,(1-\epsilon) r) \subset F(B(0, r)) \subset B(0,(1+\epsilon) r)
$$
hold if $0<r<\delta$. The first of these follows from Lemma 7.23, applied to $B(0, r)$ in place of $B(0,1)$, because $|F(x)-x|<\epsilon r$ for all $x$ with $|x|=r$. The second follows directly from (5), since $|F(x)|<(1+\epsilon)|x|$. It is clear that (6) implies
$$
(1-\epsilon)^k \leq \frac{m(F(B(0, r)))}{m(B(0, r))} \leq(1+\epsilon)^k
$$
and this proves (3).
CASE II $A$ is not one-to-one. In this case, $A$ maps $R^k$ into a subspace of lower dimension, i.e., into a set of measure 0 . Given $\epsilon>0$, there is therefore an $\eta>0$ such that $m\left(E_\eta\right)<\epsilon$ if $E_\eta$ is the set of all points in $R^k$ whose distance from $A(B(0,1))$ is less than $\eta$. Since $A=T^{\prime}(0)$, there is a $\delta>0$ such that $|x|<\delta$ implies
$$
|T(x)-A x| \leq \eta|x| \text {. }
$$

If $r<\delta$, then $T(B(0, r))$ lies therefore in the set $E$ that consists of the points whose distance from $A(B(0, r))$ is less than $\eta r$. Our choice of $\eta$ shows that $m(E)<\epsilon r^k$. Hence
$$
m(T(B(0, r)))<\epsilon r^k \quad(0<r<\delta) .
$$

Since $r^k=m(B(0, r)) / m(B(0,1)),(9)$ implies that
$$
\lim _{r \rightarrow 0} \frac{m(T(B(0, r)))}{m(B(0, r))}=0 .
$$

This proves (1), since $\Delta\left(T^{\prime}(0)\right)=\Delta(A)=0$.
///
7.25 Lemma Suppose $E \subset R^k, m(E)=0, T$ maps $E$ into $R^k$, and
$$
\lim \sup \frac{|T(y)-T(x)|}{|y-x|}<\infty
$$
for every $x \in E$, as $y$ tends to $x$ within $E$.
Then $m(T(E))=0$.

ProOF Fix positive integers $n$ and $p$, let $F=F_{n, p}$ be the set of all $x \in E$ such that
$$
|T(y)-T(x)| \leq n|y-x|
$$
for all $y \in B(x, 1 / p) \cap E$, and choose $\epsilon>0$. Since $m(F)=0, F$ can be covered by balls $B_i=B\left(x_i, r_i\right)$, where $x_i \in F, r_i<1 / p$, in such a way that $\sum m\left(B_i\right)<\epsilon$. (To do this, cover $F$ by an open set $W$ of small measure, decompose $W$ into disjoint boxes of small diameter, as in Sec. 2.19, and cover each of those that intersect $F$ by a ball whose center lies in the box and in $F$.)
If $x \in F \cap B_i$ then $\left|x_i-x\right|<r_i<1 / p$ and $x_i \in F$. Hence
$$
\left|T\left(x_i\right)-T(x)\right| \leq n\left|x_i-x\right|<n r_i
$$
so that $T\left(F \cap B_i\right) \subset B\left(T\left(x_i\right), n r_i\right)$. Therefore
$$
T(F) \subset \bigcup_i B\left(T\left(x_i\right), n r_i\right)
$$

The measure of this union is at most
$$
\sum_i m\left(B\left(T\left(x_i\right), n r_i\right)=n^k \sum_i m\left(B_i\right)<n^k \epsilon .\right.
$$

Since Lebesgue measure is complete and $\epsilon$ was arbitrary, it follows that $T(F)$ is measurable and $m(T(F))=0$.

To complete the proof, note that $E$ is the union of the countable collection $\left\{F_{n, p}\right\}$.
//II

Here is a special case of the lemma:
If $V$ is open in $R^k$ and $T: V \rightarrow R^k$ is differentiable at every point of $V$, then $T$ maps sets of measure 0 to sets of measure 0 .
We now come to the change-of-variables theorem.
7.26 Theorem Suppose that
(i) $X \subset V \subset R^k, V$ is open, $T: V \rightarrow R^k$ is continuous;
(ii) $X$ is Lebesgue measurable, $T$ is one-to-one on $X$, and $T$ is differentiable at every point of $X$;
(iii) $m(T(V-X))=0$.
Then, setting $Y=T(X)$,
$$
\int_Y f d m=\int_X(f \circ T)\left|J_T\right| d m
$$
for every measurable $f: R^k \rightarrow[0, \infty]$.
The case $X=V$ is perhaps the most interesting one. As regards condition (iii), it holds, for instance, when $m(V-X)=0$ and $T$ satisfies the hypotheses of Lemma 7.25 on $V-X$.

The proof has some elements in common with that of the implication $(b) \rightarrow(c)$ in Theorem 7.18.

It will be important in this proof to distinguish between Borel sets and Lebesgue measurable sets. The $\sigma$-algebra consisting of the Lebesgue measurable subsets of $R^k$ will be denoted by $\mathfrak{M}$.
ProOF We break the proof into the following three steps:
(I) If $E \in \mathfrak{M}$ and $E \subset V$, then $T(E) \in \mathfrak{M}$.
(II) For every $E \in \mathfrak{M}$,
$$
m(T(E \cap X))=\int_X \chi_E\left|J_T\right| d m
$$
(III) For every $A \in \mathfrak{M}$,
$$
\int_Y \chi_A d m=\int_X\left(\chi_A \circ T\right)\left|J_T\right| d m
$$

If $E_0 \in \mathfrak{M}, E_0 \subset V$, and $m\left(E_0\right)=0$, then $m\left(T\left(E_0-X\right)\right)=0$ by (iii), and $m\left(T\left(E_0 \cap X\right)\right)=0$ by Lemma 7.25. Thus $m\left(T\left(E_0\right)\right)=0$.

If $E_1 \subset V$ is an $F_\sigma$, then $E_1$ is $\sigma$-compact, hence $T\left(E_1\right)$ is $\sigma$-compact, because $T$ is continuous. Thus $T\left(E_1\right) \in \mathfrak{M}$.

Since every $E \in \mathfrak{M}$ is the union of an $F_\sigma$ and a set of measure 0 (Theorem 2.20), (I) is proved.
To prove (II), let $n$ be a positive integer, and put
$$
V_n=\{x \in V:|T(x)|<n\}, \quad X_n=X \cap V_n .
$$

Because of (I), we can define
$$
\mu_n(E)=m\left(T\left(E \cap X_n\right)\right) \quad(E \in \mathfrak{M}) .
$$

Since $T$ is one-to-one on $X_n$, the countable additivity of $m$ shows that $\mu_n$ is a measure on $\mathfrak{M}$. Also, $\mu_n$ is bounded (this was the reason for replacing $X$ temporarily by $X_n$ ), and $\mu_n \ll m$, by another application of Lemma 7.25.

Theorem 7.8 tells us therefore that $\left(D \mu_n\right)(x)$ exists a.e. $[m]$, that $D \mu_n \in L^1(m)$, and that
$$
\mu_n(E)=\int_E\left(D \mu_n\right) d m \quad(E \in \mathfrak{M}) .
$$

We claim next that
$$
\left(D \mu_n\right)(x)=\left|J_T(x)\right| \quad\left(x \in X_n\right) .
$$

To see this, fix $x \in X_n$, and note that $B(x, r) \subset V_n$ for all sufficiently small $r>0$, because $V_n$ is open. Since $V_n-X_n \subset V-X$, hypothesis (iii) enables us to replace $X_n$ by $V_n$ in (3) without changing $\mu_n(E)$. Hence, for small $r>0$,
$$
\mu_n(B(x, r))=m(T(B(x, r))) .
$$

If we divide both sides of (6) by $m(B(x, r))$ and refer to Theorem 7.24 and formula 7.22(6), we obtain (5).

Since (3) implies that $\mu_n(E)=\mu_n\left(E \cap X_n\right)$, it follows from (3), (4), and (5) that
$$
m\left(T\left(E \cap X_n\right)\right)=\int_{X_n} \chi_E\left|J_T\right| d m \quad(E \in \mathfrak{M}) .
$$

If we apply the monotone convergence theorem to (7), letting $n \rightarrow \infty$, we obtain (II).
We begin the proof of (III) by letting $A$ be a Borel set in $R^k$. Put
$$
E=T^{-1}(A)=\{x \in V: T(x) \in A\} .
$$

Then $\chi_E=\chi_A \circ T$. Since $\chi_A$ is a Borel function and $T$ is continuous, $\chi_E$ is a Borel function (Theorem 1.12), hence $E \in \mathfrak{M}$. Also
$$
T(E \cap X)=A \cap Y
$$
which implies, by (II), that
$$
\int_Y \chi_A d m=m(T(E \cap X))=\int_X\left(\chi_A \circ T\right)\left|J_T\right| d m .
$$

Finally, if $N \in \mathfrak{M}$ and $m(N)=0$, there is a Borel set $A \supset N$ with $m(A)=0$. For this $A$, (10) shows that $\left(\chi_A \circ T\right)\left|J_T\right|=0$ a.e. $[m]$. Since $0 \leq$ $\chi_N \leq \chi_A$, it follows that both integrals in (10) are 0 if $A$ is replaced by $N$. Since every Lebesgue measurable set is the disjoint union of a Borel set and a set of measure $0,(10)$ holds for every $A \in \mathfrak{M}$. This proves (III).

Once we have (III), it is clear that (1) holds for every nonnegative Lebesgue measurable simple function $f$. Another application of the monotone convergence theorem completes the proof.
156 REAL AND COMPLEX ANALYSIS

Note that we did not prove that $f \circ T$ is Lebesgue measurable for all Lebesgue measurable $f$. It need not be; see Exercise 8. What the proof does establish is the Lebesgue measurability of the product $(f \circ T)\left|J_T\right|$.
Here is a special case of the theorem:
Suppose $\varphi:[a, b] \rightarrow[\alpha, \beta]$ is AC, monotonic, $\varphi(a)=\alpha, \varphi(b)=\beta$, and $f \geq 0$ is Lebesgue measurable. Then
$$
\int_\alpha^\beta f(t) d t=\int_a^b f(\varphi(x)) \varphi^{\prime}(x) d x
$$

To derive this from Theorem 7.26, put $V=(a, b), T=\varphi$, let $\Omega$ be the union of the maximal segments on which $\varphi$ is constant (if there are any) and let $X$ be the set of all $x \in V-\Omega$ where $\varphi^{\prime}(x)$ exists (and is finite).