\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{mathrsfs}

\begin{document}
\section{ELEMENTARY HILBERT SPACE THEORY}
\section{Inner Products and Linear Functionals}
4.1 Definition A complex vector space $H$ is called an inner product space (or unitary space) if to each ordered pair of vectors $x$ and $y \in H$ there is associated a complex number $(x, y)$, the so-called "inner product" (or "scalar product") of $x$ and $y$, such that the following rules hold:

(a) $(y, x)=(\overline{x, y)}$. (The bar denotes complex conjugation.)

(b) $(x+y, z)=(x, z)+(y, z)$ if $x, y$, and $z \in H$.

(c) $(\alpha x, y)=\alpha(x, y)$ if $x$ and $y \in H$ and $\alpha$ is a scalar.

(d) $(x, x) \geq 0$ for all $x \in H$.

(e) $(x, x)=0$ only if $x=0$.

Let us list some immediate consequences of these axioms:

(c) implies that $(0, y)=0$ for all $y \in H$.

(b) and (c) may be combined into the statement: For every $y \in H$, the mapping $x \rightarrow(x, y)$ is a linear functional on $H$.

$(a)$ and $(c)$ show that $(x, \alpha y)=\bar{\alpha}(x, y)$.

$(a)$ and $(b)$ imply the second distributive law:

$$
(z, x+y)=(z, x)+(z, y)
$$

By $(d)$, we may define $\|x\|$, the norm of the vector $x \in H$, to be the nonnegative square root of $(x, x)$. Thus

$$
\|x\|^{2}=(x, x) .
$$

4.2 The Schwarz Inequality The properties $4.1(a)$ to $(d)$ imply that

$$
|(x, y)| \leq\|x\|\|y\|
$$

for all $x$ and $y \in H$.

Proof Put $A=\|x\|^{2}, B=|(x, y)|$, and $C=\|y\|^{2}$. There is a complex number $\alpha$ such that $|\alpha|=1$ and $\alpha(y, x)=B$. For any real $r$, we then have

$$
(x-r \alpha y, x-r \alpha y)=(x, x)-r \alpha(y, x)-r \bar{\alpha}(x, y)+r^{2}(y, y) .
$$

The expression on the left is real and not negative. Hence

$$
A-2 B r+C r^{2} \geq 0
$$

for every real $r$. If $C=0$, we must have $B=0$; otherwise (2) is false for large positive $r$. If $C>0$, take $r=B / C$ in (2), and obtain $B^{2} \leq A C$.

4.3 The Triangle Inequality For $x$ and $y \in H$, we have

$$
\|x+y\| \leq\|x\|+\|y\| .
$$

ProOF By the Schwarz inequality,

$$
\begin{aligned}
\|x+y\|^{2} & =(x+y, x+y)=(x, x)+(x, y)+(y, x)+(y, y) \\
& \leq\|x\|^{2}+2\|x\|\|y\|+\|y\|^{2}=(\|x\|+\|y\|)^{2} .
\end{aligned}
$$

4.4 Definition It follows from the triangle inequality that

$$
\|x-z\| \leq\|x-y\|+\|y-z\| \quad(x, y, z \in H) .
$$

If we define the distance between $x$ and $y$ to be $\|x-y\|$, all the axioms for a metric space are satisfied; here, for the first time, we use part $(e)$ of Definition 4.1.

Thus $H$ is now a metric space. If this metric space is complete, i.e., if every Cauchy sequence converges in $H$, then $H$ is called a Hilbert space.

Throughout the rest of this chapter, the letter $H$ will denote a Hilbert space.

\subsection{Examples}
(a) For any fixed $n$, the set $C^{n}$ of all $n$-tuples

$$
x=\left(\xi_{1}, \ldots, \xi_{n}\right)
$$

where $\xi_{1}, \ldots, \xi_{n}$ are complex numbers, is a Hilbert space if addition and scalar multiplication are defined componentwise, as usual, and if

$$
(x, y)=\sum_{j=1}^{n} \xi_{j} \bar{\eta}_{j} \quad\left(y=\left(\eta_{1}, \ldots, \eta_{n}\right)\right)
$$

(b) If $\mu$ is any positive measure, $L^{2}(\mu)$ is a Hilbert space, with inner product

$$
(f, g)=\int_{X} f \bar{g} d \mu
$$

The integrand on the right is in $L^{1}(\mu)$, by Theorem 3.8 , so that $(f, g)$ is well defined. Note that

$$
\|f\|=(f, f)^{1 / 2}=\left\{\int_{X}|f|^{2} d \mu\right\}^{1 / 2}=\|f\|_{2}
$$

The completeness of $L^{2}(\mu)$ (Theorem 3.11) shows that $L^{2}(\mu)$ is indeed a Hilbert space. [We recall that $L^{2}(\mu)$ should be regarded as a space of equivalence classes of functions; compare the discussion in Sec. 3.10.]

For $H=L^{2}(\mu)$, the inequalities 4.2 and 4.3 turn out to be special cases of the inequalities of HÃ¶lder and Minkowski.

Note that Example $(a)$ is a special case of $(b)$. What is the measure in $(a)$ ?

(c) The vector space of all continuous compiex functions on $[0,1]$ is an inner product space if

$$
(f, g)=\int_{0}^{1} f(t) \overline{g(t)} d t
$$

but is not a Hilbert space.

4.6 Theorem For any fixed $y \in H$, the mappings

$$
x \rightarrow(x, y), \quad x \rightarrow(y, x), \quad x \rightarrow\|x\|
$$

are continuous functions on $H$.

Proof The Schwarz inequality implies that

$$
\left|\left(x_{1}, y\right)-\left(x_{2}, y\right)\right|=\left|\left(x_{1}-x_{2}, y\right)\right| \leq\left\|x_{1}-x_{2}\right\|\|y\|,
$$

which proves that $x \rightarrow(x, y)$ is, in fact, uniformly continuous, and the same is true for $x \rightarrow(y, x)$. The triangle inequality $\left\|x_{1}\right\| \leq\left\|x_{1}-x_{2}\right\|+\left\|x_{2}\right\|$ yields

$$
\left\|x_{1}\right\|-\left\|x_{2}\right\| \leq\left\|x_{1}-x_{2}\right\|,
$$

and if we interchange $x_{1}$ and $x_{2}$ we see that

$$
\left|\left\|x_{1}\right\|-\left\|x_{2}\right\|\right| \leq\left\|x_{1}-x_{2}\right\|
$$

for all $x_{1}$ and $x_{2} \in H$. Thus $x \rightarrow\|x\|$ is also uniformly continuous.

4.7 Subspaces A subset $M$ of a vector space $V$ is called a subspace of $V$ if $M$ is itself a vector space, relative to the addition and scalar multiplication which are defined in $V$. A necessary and sufficient condition for a set $M \subset V$ to be a subspace is that $x+y \in M$ and $\alpha x \in M$ whenever $x$ and $y \in M$ and $\alpha$ is a scalar.

In the vector space context, the word "subspace" will always have this meaning. Sometimes, for emphasis, we may use the term "linear subspace" in place of subspace.

For example, if $V$ is the vector space of all complex functions on a set $S$, the set of all bounded complex functions on $S$ is a subspace of $V$, but the set of all $f \in V$ with $|f(x)| \leq 1$ for all $x \in S$ is not. The real vector space $R^{3}$ has the following subspaces, and no others: $(a) R^{3},(b)$ all planes through the origin $0,(c)$ all straight lines through 0 , and $(d)\{0\}$.

A closed subspace of $H$ is a subspace that is a closed set relative to the topology induced by the metric of $H$.

Note that if $M$ is a subspace of $H$, so is its closure $\bar{M}$. To see this, pick $x$ and $y$ in $\bar{M}$ and let $\alpha$ be a scalar. There are sequences $\left\{x_{n}\right\}$ and $\left\{y_{n}\right\}$ in $M$ that converge to $x$ and $y$, respectively. It is then easy to verify that $x_{n}+y_{n}$ and $\alpha x_{n}$ converge to $x+y$ and $\alpha x$, respectively. Thus $x+y \in \bar{M}$ and $\alpha x \in \bar{M}$.

4.8 Convex Sets A set $E$ in a vector space $V$ is said to be convex if it has the following geometric property: Whenever $x \in E, y \in E$, and $0<t<1$, the point

$$
z_{t}=(1-t) x+t y
$$

also lies in $E$. As $t$ runs from 0 to 1 , one may visualize $z_{t}$ as describing a straight line segment in $V$, from $x$ to $y$. Convexity requires that $E$ contain the segments between any two of its points.

It is clear that every subspace of $V$ is convex.

Also, if $E$ is convex, so is each of its translates

$$
E+x=\{y+x: y \in E\} .
$$

4.9 Orthogonality If $(x, y)=0$ for some $x$ and $y \in H$, we say that $x$ is orthogonal to $y$, and sometimes write $x \perp y$. Since $(x, y)=0$ implies $(y, x)=0$, the relation $\perp$ is symmetric.

Let $x^{\perp}$ denote the set of all $y \in H$ which are orthogonal to $x$; and if $M$ is a subspace of $H$, let $M^{\perp}$ be the set of all $y \in H$ which are orthogonal to every $x \in M$.

Note that $x^{\perp}$ is a subspace of $H$, since $x \perp y$ and $x \perp y^{\prime}$ implies $x \perp\left(y+y^{\prime}\right)$ and $x \perp \alpha y$. Also, $x^{\perp}$ is precisely the set of points where the continuous function $y \rightarrow(x, y)$ is 0 . Hence $x^{\perp}$ is a closed subspace of $H$. Since

$$
M^{\perp}=\bigcap_{x \in M} x^{\perp}
$$

$M^{\perp}$ is an intersection of closed subspaces, and it follows that $M^{\perp}$ is a closed subspace of $H$.

4.10 Theorem Every nonempty, closed, convex set $E$ in a Hilbert space $H$ contains a unique element of smallest norm.

In other words, there is one and only one $x_{0} \in E$ such that $\left\|x_{0}\right\| \leq\|x\|$ for every $x \in E$.

Proof An easy computation, using only the properties listed in Definition 4.1, establishes the identity

$$
\|x+y\|^{2}+\|x-y\|^{2}=2\|x\|^{2}+2\|y\|^{2} \quad(x \text { and } y \in H)
$$

This is known as the parallelogram law: If we interpret $\|x\|$ to be the length of the vector $x$, (1) says that the sum of the squares of the diagonals of a parallelogram is equal to the sum of the squares of its sides, a familiar proposition in plane geometry.

Let $\delta=\inf \{\|x\|: x \in E\}$. For any $x$ and $y \in E$, we apply (1) to $\frac{1}{2} x$ and $\frac{1}{2} y$ and obtain

$$
\frac{1}{4}\|x-y\|^{2}=\frac{1}{2}\|x\|^{2}+\frac{1}{2}\|y\|^{2}-\left\|\frac{x+y}{2}\right\|^{2}
$$

Since $E$ is convex, $(x+y) / 2 \in E$. Hence

$$
\|x-y\|^{2} \leq 2\|x\|^{2}+2\|y\|^{2}-4 \delta^{2} \quad(x \text { and } y \in E)
$$

If also $\|x\|=\|y\|=\delta$, then (3) implies $x=y$, and we have proved the uniqueness assertion of the theorem.

The definition of $\delta$ shows that there is a sequence $\left\{y_{n}\right\}$ in $E$ so that $\left\|y_{n}\right\| \rightarrow \delta$ as $n \rightarrow \infty$. Replace $x$ and $y$ in (3) by $y_{n}$ and $y_{m}$. Then, as $n \rightarrow \infty$ and $m \rightarrow \infty$, the right side of (3) will tend to 0 . This shows that $\left\{y_{n}\right\}$ is a Cauchy sequence. Since $H$ is complete, there exists an $x_{0} \in H$ so that $y_{n} \rightarrow x_{0}$, i.e., $\left\|y_{n}-x_{0}\right\| \rightarrow 0$, as $n \rightarrow \infty$. Since $y_{n} \in E$ and $E$ is closed, $x_{0} \in E$. Since the norm is a continuous function on $H$ (Theorem 4.6), it follows that

$$
\left\|x_{0}\right\|=\lim _{n \rightarrow \infty}\left\|y_{n}\right\|=\delta
$$

4.11 Theorem Let $M$ be a closed subspace of a Hilbert space $H$.

(a) Every $x \in H$ has then a unique decomposition

$$
x=P x+Q x
$$

into a sum of $P x \in M$ and $Q x \in M^{\perp}$.

(b) $P x$ and $Q x$ are the nearest points to $x$ in $M$ and in $M^{\perp}$, respectively.

(c) The mappings $P: H \rightarrow M$ and $Q: H \rightarrow M^{\perp}$ are linear.

(d) $\|x\|^{2}=\|P x\|^{2}+\|Q x\|^{2}$.

Corollary If $M \neq H$, then there exists $y \in H, y \neq 0$, such that $y \perp M$.

$P$ and $Q$ are called the orthogonal projections of $H$ onto $M$ and $M^{\perp}$.

Proof As regards the uniqueness in $(a)$, suppose that $x^{\prime}+y^{\prime}=x^{\prime \prime}+y^{\prime \prime}$ for some vectors $x^{\prime}, x^{\prime \prime}$ in $M$ and $y^{\prime}, y^{\prime \prime}$ in $M^{\perp}$. Then

$$
x^{\prime}-x^{\prime \prime}=y^{\prime \prime}-y^{\prime}
$$

Since $x^{\prime}-x^{\prime \prime} \in M, y^{\prime \prime}-y^{\prime} \in M^{\perp}$, and $M \cap M^{\perp}=\{0\}$ [an immediate consequence of the fact that $(x, x)=0$ implies $x=0]$, we have $x^{\prime \prime}=x^{\prime}, y^{\prime \prime}=y^{\prime}$.

To prove the existence of the decomposition, note that the set

$$
x+M=\{x+y: y \in M\}
$$

is closed and convex. Define $Q x$ to be the element of smallest norm in $x+M$; this exists, by Theorem 4.10. Define $P x=x-Q x$.

Since $Q x \in x+M$, it is clear that $P x \in M$. Thus $P$ maps $H$ into $M$.

To prove that $Q$ maps $H$ into $M^{\perp}$ we show that $(Q x, y)=0$ for all $y \in M$. Assume $\|y\|=1$, without loss of generality, and put $z=Q x$. The minimizing property of $Q x$ shows that

$$
(z, z)=\|z\|^{2} \leq\|z-\alpha y\|^{2}=(z-\alpha y, z-\alpha y)
$$

for every scalar $\alpha$. This simplifies to

$$
0 \leq-\alpha(y, z)-\bar{\alpha}(z, y)+\alpha \bar{\alpha} .
$$

With $\alpha=(z, y)$, this gives $0 \leq-|(z, y)|^{2}$, so that $(z, y)=0$. Thus $Q x \in M^{\perp}$.

We have already seen that $P x \in M$. If $y \in M$, it follows that

$$
\|x-y\|^{2}=\|Q x+(P x-y)\|^{2}=\|Q x\|^{2}+\|P x-y\|^{2}
$$

which is obviously minimized when $y=P x$.

We have now proved $(a)$ and $(b)$. If we apply $(a)$ to $x$, to $y$, and to $\alpha x+\beta y$, we obtain

$$
P(\alpha x+\beta y)-\alpha P x-\beta P y=\alpha Q x+\beta Q y-Q(\alpha x+\beta y) .
$$

The left side is in $M$, the right side in $M^{\perp}$. Hence both are 0 , so $P$ and $Q$ are linear.

Since $P x \perp Q x,(d)$ follows from (a).

To prove the corollary, take $x \in H, x \notin M$, and put $y=Q x$. Since $P x \in M, x \neq P x$, hence $y=x-P x \neq 0$.

We have already observed that $x \rightarrow(x, y)$ is, for each $y \in H$, a continuous linear functional on $H$. It is a very important fact that all continuous linear functionals on $H$ are of this type.

4.12 Theorem If $L$ is a continuous linear functional on $H$, then there is a unique $y \in H$ such that

$$
L x=(x, y) \quad(x \in H)
$$

ProOF If $L x=0$ for all $x$, take $y=0$. Otherwise, define

$$
M=\{x: L x=0\} .
$$

The linearity of $L$ shows that $M$ is a subspace. The continuity of $L$ shows that $M$ is closed. Since $L x \neq 0$ for some $x \in H$, Theorem 4.11 shows that $M^{\perp}$ does not consist of 0 alone.

Hence there exists $z \in M^{\perp}$, with $\|z\|=1$. Put

$$
u=(L x) z-(L z) x
$$

Since $L u=(L x)(L z)-(L z)(L x)=0$, we have $u \in M$. Thus $(u, z)=0$. This gives

$$
L x=(L x)(z, z)=(L z)(x, z)
$$

Thus (1) holds with $y=\alpha z$, where $\bar{\alpha}=L z$.

The uniqueness of $y$ is easily proved, for if $(x, y)=\left(x, y^{\prime}\right)$ for all $x \in H$, set $z=y-y^{\prime}$; then $(x, z)=0$ for all $x \in H$; in particular, $(z, z)=0$, hence $z=0$.

\section{Orthonormal Sets}
4.13 Definitions If $V$ is a vector space, if $x_{1}, \ldots, x_{k} \in V$, and if $c_{1}, \ldots, c_{k}$ are scalars, then $c_{1} x_{1}+\cdots+c_{k} x_{k}$ is called a linear combination of $x_{1}, \ldots, x_{k}$. The set $\left\{x_{1}, \ldots, x_{k}\right\}$ is called independent if $c_{1} x_{1}+\cdots+c_{k} x_{k}=0$ implies that $c_{1}=\cdots=c_{k}=0$. A set $S \subset V$ is independent if every finite subset of $S$ is independent. The set $[S]$ of all linear combinations of all finite subsets of $S$ (also called the set of all finite linear combinations of members of $S$ ) is clearly a vector space; $[S]$ is the smallest subspace of $V$ which contains $S$; $[S]$ is called the span of $S$, or the space spanned by $S$.

A set of vectors $u_{\alpha}$ in a Hilbert space $H$, where $\alpha$ runs through some index set $A$, is called orthonormal if it satisfies the orthogonality relations $\left(u_{\alpha}, u_{\beta}\right)=0$ for all $\alpha \neq \beta, \alpha \in A$, and $\beta \in A$, and if it is normalized so that $\left\|u_{\alpha}\right\|=1$ for each $\alpha \in A$. In other words, $\left\{u_{\alpha}\right\}$ is orthonormal provided that

$$
\left(u_{\alpha}, u_{\beta}\right)= \begin{cases}1 & \text { if } \alpha=\beta \\ 0 & \text { if } \alpha \neq \beta\end{cases}
$$

If $\left\{u_{\alpha}: \alpha \in A\right\}$ is orthonormal, we associate with each $x \in H$ a complex function $\hat{x}$ on the index set $A$, defined by

$$
\hat{x}(\alpha)=\left(x, u_{\alpha}\right) \quad(\alpha \in A) .
$$

One sometimes calls the numbers $\hat{x}(\alpha)$ the Fourier coefficients of $x$, relative to the set $\left\{u_{\alpha}\right\}$.

We begin with some simple facts about finite orthonormal sets.

4.14 Theorem Suppose that $\left\{u_{\alpha}: \alpha \in A\right\}$ is an orthonormal set in $H$ and that $F$ is a finite subset of $A$. Let $M_{F}$ be the span of $\left\{u_{\alpha}: \alpha \in F\right\}$.

(a) If $\varphi$ is a complex function on $A$ that is 0 outside $F$, then there is a vector $y \in M_{F}$, namely

$$
y=\sum_{\alpha \in F} \varphi(\alpha) u_{\alpha}
$$

that has $\hat{y}(\alpha)=\varphi(\alpha)$ for every $\alpha \in A$. Also,

$$
\|y\|^{2}=\sum_{\alpha \in F}|\varphi(\alpha)|^{2}
$$

(b) If $x \in H$ and

$$
s_{F}(x)=\sum_{\alpha \in F} \hat{x}(\alpha) u_{\alpha}
$$

then

$$
\left\|x-s_{F}(x)\right\|<\|x-s\|
$$

for every $s \in M_{F}$, except for $s=s_{F}(x)$, and

$$
\sum_{\alpha \in F}|\hat{x}(\alpha)|^{2} \leq\|x\|^{2} .
$$

ProOf Part $(a)$ is an immediate consequence of the orthogonality relations 4.13(1).

In the proof of $(b)$, let us write $s_{F}$ in place of $s_{F}(x)$, and note that $\hat{s}_{F}(\alpha)=$ $\hat{x}(\alpha)$ for all $\alpha \in F$. This says that $\left(x-s_{F}\right) \perp u_{\alpha}$ if $\alpha \in F$, hence $\left(x-s_{F}\right) \perp$ $\left(s_{F}-s\right)$ for every $s \in M_{F}$, and therefore

$$
\|x-s\|^{2}=\left\|\left(x-s_{F}\right)+\left(s_{F}-s\right)\right\|^{2}=\left\|x-s_{F}\right\|^{2}+\left\|s_{F}-s\right\|^{2}
$$

This gives (4). With $s=0$, (6) gives $\left\|s_{F}\right\|^{2} \leq\|x\|^{2}$, which is the same as (5), because of (2).

The inequality (4) states that the "partial sum" $s_{F}(x)$ of the "Fourier series" $\sum \hat{x}(\alpha) u_{\alpha}$ of $x$ is the unique best approximation to $x$ in $M_{F}$, relative to the metric defined by the Hilbert space norm.

4.15 We want to drop the finiteness condition that appears in Theorem 4.14 (thus obtaining Theorems 4.17 and 4.18) without even restricting ourselves to sets that are necessarily countable. For this reason it seems advisable to clarify the meaning of the symbol $\sum_{\alpha \in \mathcal{A}} \varphi(\alpha)$ when $\alpha$ ranges over an arbitrary set $A$.

Assume $0 \leq \varphi(\alpha) \leq \infty$ for each $\alpha \in A$. Then

$$
\sum_{\alpha \in A} \varphi(\alpha)
$$

denotes the supremum of the set of all finite sums $\varphi\left(\alpha_{1}\right)+\cdots+\varphi\left(\alpha_{n}\right)$, where $\alpha_{1}, \ldots, \alpha_{n}$ are distinct members of $A$.

A moment's consideration will show that the sum (1) is thus precisely the Lebesgue integral of $\varphi$ relative to the counting measure $\mu$ on $A$.

In this context one usually writes $\ell^{p}(A)$ for $L^{p}(\mu)$. A complex function $\varphi$ with domain $A$ is thus in $\ell^{2}(A)$ if and only if

$$
\sum_{\alpha \in A}|\varphi(\alpha)|^{2}<\infty
$$

Example $4.5(b)$ shows that $\ell^{2}(A)$ is a Hilbert space, with inner product

$$
(\varphi, \psi)=\sum_{\alpha \in A} \varphi(\alpha) \overline{\psi(\alpha)}
$$

Here, again, the sum over $A$ stands for the integral of $\varphi \bar{\psi}$ with respect to the counting measure; note that $\varphi \bar{\psi} \in \ell^{1}(A)$ because $\varphi$ and $\psi$ are in $\ell^{2}(A)$.

Theorem 3.13 shows that the functions $\varphi$ that are zero except on some finite subset of $A$ are dense in $\ell^{2}(A)$.

Moreover, if $\varphi \in \ell^{2}(A)$, then $\{\alpha \in A: \varphi(\alpha) \neq 0\}$ is at most countable. For if $A_{n}$ is the set of all $\alpha$ where $|\varphi(\alpha)|>1 / n$, then the number of elements of $A$ is at most

$$
\sum_{\alpha \in A_{n}}|n \varphi(\alpha)|^{2} \leq n^{2} \sum_{\alpha \in A}|\varphi(\alpha)|^{2}
$$

Each $A_{n}(n=1,2,3, \ldots)$ is thus a finite set.

The following lemma about complete metric spaces will make it easy to pass from finite orthonormal sets to infinite ones.

\subsection{Lemma Suppose that}
(a) $X$ and $Y$ are metric spaces, $X$ is complete,

(b) $f: X \rightarrow Y$ is continuous,

(c) $X$ has a dense subset $X_{0}$ on which $f$ is an isometry, and

(d) $f\left(X_{0}\right)$ is dense in $Y$.

Then $f$ is an isometry of $X$ onto $Y$.

The most important part of the conclusion is that $f$ maps $X$ onto all of $Y$.

Recall that an isometry is simply a mapping that preserves distances. Thus, by assumption, the distance between $f\left(x_{1}\right)$ and $f\left(x_{2}\right)$ in $Y$ is equal to that between $x_{1}$ and $x_{2}$ in $X$, for all points $x_{1}, x_{2}$ in $X_{0}$.

Proof The fact that $f$ is an isometry on $X$ is an immediate consequence of the continuity of $f$, since $X_{0}$ is dense in $X$.

Pick $y \in Y$. Since $f\left(X_{0}\right)$ is dense in $Y$, there is a sequence $\left\{x_{n}\right\}$ in $X_{0}$ such that $f\left(x_{n}\right) \rightarrow y$ as $n \rightarrow \infty$. Thus $\left\{f\left(x_{n}\right)\right\}$ is a Cauchy sequence in $Y$. Since $f$ is an isometry on $X_{0}$, it follows that $\left\{x_{n}\right\}$ is also a Cauchy sequence. The completeness of $X$ implies now that $\left\{x_{n}\right\}$ converges to some $x \in X$, and the continuity of $f$ shows that $f(x)=\lim f\left(x_{n}\right)=y$.

4.17 Theorem Let $\left\{u_{\alpha}: \alpha \in A\right\}$ be an orthonormal set in $H$, and let $P$ be the space of all finite linear combinations of the vectors $u_{\alpha}$.

The inequality

$$
\sum_{\alpha \in A}|\hat{x}(\alpha)|^{2} \leq\|x\|^{2}
$$

holds then for every $x \in H$, and $x \rightarrow \hat{x}$ is a continuous linear mapping of $H$ onto $\ell^{2}(A)$ whose restriction to the closure $\bar{P}$ of $P$ is an isometry of $\bar{P}$ onto $\ell^{2}(A)$.

Proof Since the inequality 4.14(5) holds for every finite set $F \subset A$, we have (1), the so-called Bessel inequality.

Define $f$ on $H$ by $f(x)=\hat{x}$. Then (1) shows explicitly that $f$ maps $H$ into $\ell^{2}(A)$. The linearity of $f$ is obvious. If we apply (1) to $x-y$ we see that

$$
\|f(y)-f(x)\|_{2}=\|\hat{y}-\hat{x}\|_{2} \leq\|y-x\| .
$$

Thus $f$ is continuous. Theorem 4.14(a) shows that $f$ is an isometry of $P$ onto the dense subspace of $\ell^{2}(A)$ consisting of those functions whose support is a finite set $F \subset A$. The theorem follows therefore from Lemma 4.16, applied with $X=\bar{P}, X_{0}=P, Y=\ell^{2}(A)$; note that $\bar{P}$, being a closed subset of the complete metric space $H$, is itself complete.

The fact that the mapping $x \rightarrow \hat{x}$ carries $H$ onto $\ell^{2}(A)$ is known as the RieszFischer theorem.

4.18 Theorem Let $\left\{u_{\alpha}: \alpha \in A\right\}$ be an orthonormal set in $H$. Each of the following four conditions on $\left\{u_{\alpha}\right\}$ implies the other three:

(i) $\left\{u_{\alpha}\right\}$ is a maximal orthonormal set in $H$.

(ii) The set $P$ of all finite linear combinations of members of $\left\{u_{\alpha}\right\}$ is dense in $H$.

(iii) The equality

$$
\sum_{\alpha \in A}|\hat{x}(\alpha)|^{2}=\|x\|^{2}
$$

holds for every $x \in H$.

(iv) The equality

$$
\sum_{\alpha \in A} \hat{x}(\alpha) \overline{\hat{y}(\alpha)}=(x, y)
$$

holds for all $x \in H$ and $y \in H$.

The last formula is known as Parseval's identity. Observe that $\hat{x}$ and $\hat{y}$ are in $\ell^{2}(A)$, hence $\hat{x} \bar{y}$ is in $\ell^{1}(A)$, so that the sum in (iv) is well defined. Of course, (iii) is the special case $x=y$ of (iv).

Maximal orthonormal sets are often called complete orthonormal sets or orthonormal bases.

ProOF To say that $\left\{u_{\alpha}\right\}$ is maximal means simply that no vector of $H$ can be adjoined to $\left\{u_{\alpha}\right\}$ in such a way that the resulting set is still orthonormal. This happens precisely when there is no $x \neq 0$ in $H$ that is orthogonal to every $u_{\alpha}$.

We shall prove that (i) $\rightarrow$ (ii) $\rightarrow$ (iii) $\rightarrow$ (iv) $\rightarrow$ (i).

If $P$ is not dense in $H$, then its closure $\bar{P}$ is not all of $H$, and the corollary to Theorem 4.11 implies that $P^{\perp}$ contains a nonzero vector. Thus $\left\{u_{\alpha}\right\}$ is not maximal when $P$ is not dense, and (i) implies (ii).

If (ii) holds, so does (iii), by Theorem 4.17.

The implication (iii) $\rightarrow$ (iv) follows from the easily proved Hilbert space identity (sometimes called the "polarization identity")

$$
4(x, y)=\|x+y\|^{2}-\|x-y\|^{2}+i\|x+i y\|^{2}-i\|x-i y\|^{2}
$$

which expresses the inner product $(x, y)$ in terms of norms and which is equally valid with $\hat{x}, \hat{y}$ in place of $x, y$, simply because $\ell^{2}(A)$ is also a Hilbert space. (See Exercise 19 for other identities of this type.) Note that the sums in (iii) and (iv) are $\|\hat{x}\|_{2}^{2}$ and $(\hat{x}, \hat{y})$, respectively.

Finally, if (i) is false, there exists $u \neq 0$ in $H$ so that $\left(u, u_{\alpha}\right)=0$ for all $\alpha \in A$. If $x=y=u$, then $(x, y)=\|u\|^{2}>0$ but $\hat{x}(\alpha)=0$ for all $\alpha \in A$, hence (iv) fails. Thus (iv) implies (i), and the proof is complete.

4.19 Isomorphisms Speaking informally, two algebraic systems of the same nature are said to be isomorphic if there is a one-to-one mapping of one onto the other which preserves all relevant properties. For instance, we may ask whether two groups are isomorphic or whether two fields are isomorphic. Two vector spaces are isomorphic if there is a one-to-one linear mapping of one onto the other. The linear mappings are the ones which preserve the relevant concepts in a vector space, namely, addition and scalar multiplication.

In the same way, two Hilbert spaces $H_{1}$ and $H_{2}$ are isomorphic if there is a one-to-one linear mapping $\Lambda$ of $H_{1}$ onto $H_{2}$ which also preserves inner products: $(\Lambda x, \Lambda y)=(x, y)$ for all $x$ and $y \in H_{1}$. Such a $\Lambda$ is an isomorphism (or, more specifically, a Hilbert space isomorphism) of $H_{1}$ onto $H_{2}$. Using this terminology, Theorems 4.17 and 4.18 yield the following statement:

If $\left\{u_{\alpha}: \alpha \in A\right\}$ is a maximal orthonormal set in a Hilbert space $H$, and if $\hat{x}(\alpha)=$ $\left(x, u_{\alpha}\right)$, then the mapping $x \rightarrow \hat{x}$ is a Hilbert space isomorphism of $H$ onto $\ell^{2}(A)$.

One can prove (we shall omit this) that $\ell^{2}(A)$ and $\ell^{2}(B)$ are isomorphic if and only if the sets $A$ and $B$ have the same cardinal number. But we shall prove that every nontrivial Hilbert space (this means that the space does not consist of 0 alone) is isomorphic to some $\ell^{2}(A)$, by proving that every such space contains a maximal orthonormal set (Theorem 4.22). The proof will depend on a property of partially ordered sets which is equivalent to the axiom of choice.

4.20 Partially Ordered Sets A set $\mathscr{P}$ is said to be partially ordered by a binary relation $\leq$ if
(a) $a \leq b$ and $b \leq c$ implies $a \leq c$.

(b) $a \leq a$ for every $\alpha \in \mathscr{P}$.

(c) $a \leq b$ and $b \leq a$ implies $a=b$.

A subset $\mathscr{2}$ of a partially ordered set $\mathscr{P}$ is said to be totally ordered (or linearly ordered) if every pair $a, b \in 2$ satisfies either $\alpha \leq b$ or $b \leq a$.

For example, every collection of subsets of a given set is partially ordered by the inclusion relation $\subset$.

To give a more specific example, let $\mathscr{P}$ be the collection of all open subsets of the plane, partially ordered by set inclusion, and let 2 be the collection of all open circular discs with center at the origin. Then $\mathscr{Q} \subset \mathscr{P}, \mathscr{Q}$ is totally ordered by $\subset$, and 2 is a maximal totally ordered subset of $\mathscr{P}$. This means that if any member of $\mathscr{P}$ not in $\mathscr{2}$ is adjoined to 2 , the resulting collection of sets is no longer totally ordered by $\subset$.

4.21 The Hausdorff Maximality Theorem Every nonempty partially ordered set contains a maximal totally ordered subset.

This is a consequence of the axiom of choice and is, in fact, equivalent to it; another (very similar) form of it is known as Zorn's lemma. We give the proof in the Appendix.

If now $H$ is a nontrivial Hilbert space, then there exists a $u \in H$ with $\|u\|=1$, so that there is a nonempty orthonormal set in $H$. The existence of a maximal orthonormal set is therefore a consequence of the following theorem:

4.22 Theorem Every orthonormal set $B$ in a Hilbert space $H$ is contained in a maximal orthonormal set in $H$.

ProOF Let $\mathscr{P}$ be the class of all orthonormal sets in $H$ which contain the given set $B$. Partially order $\mathscr{P}$ by set inclusion. Since $B \in \mathscr{P}, \mathscr{P} \neq \varnothing$. Hence $\mathscr{P}$ contains a maximal totally ordered class $\Omega$. Let $S$ be the union of all members of $\Omega$. It is clear that $B \subset S$. We claim that $S$ is a maximal orthonormal set:

If $u_{1}$ and $u_{2} \in S$, then $u_{1} \in A_{1}$ and $u_{2} \in A_{2}$ for some $A_{1}$ and $A_{2} \in \Omega$. Since $\Omega$ is total ordered, $A_{1} \subset A_{2}$ (or $A_{2} \subset A_{1}$ ), so that $u_{1} \in A_{2}$ and $u_{2} \in A_{2}$. Since $A_{2}$ is orthonormal, $\left(u_{1}, u_{2}\right)=0$ if $u_{1} \neq u_{2},\left(u_{1}, u_{2}\right)=1$ if $u_{1}=u_{2}$. Thus $S$ is an orthonormal set.

Suppose $S$ is not maximal. Then $S$ is a proper subset of an orthonormal set $S^{*}$. Clearly, $S^{*} \notin \Omega$, and $S^{*}$ contains every member of $\Omega$. Hence we may adjoin $S^{*}$ to $\Omega$ and still have a total order. This contradicts the maximality of $\Omega$.

\section{Trigonometric Series}
4.23 Definitions Let $T$ be the unit circle in the complex plane, i.e., the set of all complex numbers of absolute value 1 . If $F$ is any function on $T$ and if $f$ is defined on $R^{1}$ by

$$
f(t)=F\left(e^{i t}\right)
$$

then $f$ is a periodic function of period $2 \pi$. This means that $f(t+2 \pi)=f(t)$ for all real $t$. Conversely, if $f$ is a function on $R^{1}$, with period $2 \pi$, then there is a function $F$ on $T$ such that (1) holds. Thus we may identify functions on $T$ with $2 \pi$-periodic functions on $R^{1}$; and, for simplicity of notation, we shall sometimes write $f(t)$ rather than $f\left(e^{i t}\right)$, even if we think of $f$ as being defined on $T$.

With these conventions in mind, we define $L^{p}(T)$, for $1 \leq p<\infty$, to be the class of all complex, Lebesgue measurable, $2 \pi$-periodic functions on $R^{1}$ for which the norm

$$
\|f\|_{p}=\left\{\frac{1}{2 \pi} \int_{-\pi}^{\pi}|f(t)|^{p} d t\right\}^{1 / p}
$$

is finite.

In other words, we are looking at $L^{p}(\mu)$, where $\mu$ is Lebesgue measure on $[0,2 \pi]$ (or on $T$ ), divided by $2 \pi$. $L^{\infty}(T)$ will be the class of all $2 \pi$-periodic members of $L^{\infty}\left(R^{1}\right)$, with the essential supremum norm, and $C(T)$ consists of all continuous complex functions on $T$ (or, equivalently, of all continuous, complex, $2 \pi$-periodic functions on $R^{1}$ ), with norm

$$
\|f\|_{\infty}=\sup |f(t)|,
$$

The factor $1 /(2 \pi)$ in (2) simplifies the formalism we are about to develop. For instance, the $L^{p}$-norm of the constant function 1 is 1.

A trigonometric polynomial is a finite sum of the form

$$
f(t)=a_{0}+\sum_{n=1}^{N}\left(a_{n} \cos n t+b_{n} \sin n t\right) \quad\left(t \in R^{1}\right)
$$

where $a_{0}, a_{1}, \ldots, a_{N}$ and $b_{1}, \ldots, b_{N}$ are complex numbers. On account of the Euler identities, (4) can also be written in the form

$$
f(t)=\sum_{n=-N}^{N} c_{n} e^{i n t}
$$

which is more convenient for most purposes. It is clear that every trigonometric polynomial has period $2 \pi$.

We shall denote the set of all integers (positive, zero, and negative) by $Z$, and put

$$
u_{n}(t)=e^{i n t} \quad(n \in Z)
$$

If we define the inner product in $L^{2}(T)$ by

$$
(f, g)=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t) \overline{g(t)} d t
$$

[note that this is in agreement with (2)], an easy computation shows that

$$
\left(u_{n}, u_{m}\right)=\frac{1}{2 \pi} \int_{-\pi}^{\pi} e^{i(n-m) t} d t= \begin{cases}1 & \text { if } n=m \\ 0 & \text { if } n \neq m\end{cases}
$$

Thus $\left\{u_{n}: n \in Z\right\}$ is an orthonormal set in $L^{2}(T)$, usually called the trigonometric system. We shall now prove that this system is maximal, and shall then derive concrete versions of the abstract theorems previously obtained in the Hilbert space context.

4.24 The Completeness of the Trigonometric System Theorem 4.18 shows that the maximality (or completeness) of the trigonometric system will be proved as soon as we can show that the set of all trigonometric polynomials is dense in $L^{2}(T)$. Since $C(T)$ is dense in $L^{2}(T)$, by Theorem 3.14 (note that $T$ is compact), it suffices to show that to every $f \in C(T)$ and to every $\epsilon>0$ there is a trigonometric polynomial $P$ such that $\|f-P\|_{2}<\epsilon$. Since $\|g\|_{2} \leq\|g\|_{\infty}$ for every $g \in C(T)$, the estimate $\|f-P\|_{2}<\epsilon$ will follow from $\|f-P\|_{\infty}<\epsilon$, and it is this estimate which we shall prove.

Suppose we had trigonometric polynomials $Q_{1}, Q_{2}, Q_{3}, \ldots$, with the following properties:

$$
Q_{k}(t) \geq 0 \text { for } t \in R^{1} \text {. }
$$

$$
\frac{1}{2 \pi} \int_{-\pi}^{\pi} Q_{k}(t) d t=1
$$

(c) If $\eta_{k}(\delta)=\sup \left\{Q_{k}(t): \delta \leq|t| \leq \pi\right\}$, then

$$
\lim _{k \rightarrow \infty} \eta_{k}(\delta)=0
$$

for every $\delta>0$.

Another way of stating $(c)$ is to say: for every $\delta>0, Q_{k}(t) \rightarrow 0$ uniformly on $[-\pi,-\delta] \cup[\delta, \pi]$.

To each $f \in C(T)$ we associate the functions $P_{k}$ defined by

$$
P_{k}(t)=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t-s) Q_{k}(s) d s \quad(k=1,2,3, \ldots)
$$

If we replace $s$ by $-s$ (using Theorem 2.20(e)) and then by $s-t$, the periodicity of $f$ and $Q_{k}$ shows that the value of the integral is not affected. Hence

$$
P_{k}(t)=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(s) Q_{k}(t-s) d s \quad(k=1,2,3, \ldots)
$$

Since each $Q_{k}$ is a trigonometric polynomial, $Q_{k}$ is of the form

$$
Q_{k}(t)=\sum_{n=-N_{k}}^{N_{k}} a_{n, k} e^{i n t}
$$

and if we replace $t$ by $t-s$ in (3) and substitute the result in (2), we see that each $\boldsymbol{P}_{\boldsymbol{k}}$ is a trigonometric polynomial.

Let $\epsilon>0$ be given. Since $f$ is uniformly continuous on $T$, there exists a $\delta>0$ such that $|f(t)-f(s)|<\epsilon$ whenever $|t-s|<\delta$. By $(b)$, we have

$$
P_{k}(t)-f(t)=\frac{1}{2 \pi} \int_{-\pi}^{\pi}\{f(t-s)-f(t)\} Q_{k}(s) d s,
$$

and (a) implies, for all $t$, that

$$
\left|P_{k}(t)-f(t)\right| \leq \frac{1}{2 \pi} \int_{-\pi}^{\pi}|f(t-s)-f(t)| Q_{k}(s) d s=A_{1}+A_{2}
$$

where $A_{1}$ is the integral over $[-\delta, \delta]$ and $A_{2}$ is the integral over $[-\pi,-\delta] \cup$ $[\delta, \pi]$. In $A_{1}$, the integrand is less than $\epsilon Q_{k}(s)$, so $A_{1}<\epsilon$, by $(b)$. In $A_{2}$, we have $Q_{k}(s) \leq \eta_{k}(\delta)$, hence

$$
A_{2} \leq 2\|f\|_{\infty} \cdot \eta_{k}(\delta)<\epsilon
$$

for sufficiently large $k$, by $(c)$. Since these estimates are independent of $t$, we have proved that

$$
\lim _{k \rightarrow \infty}\left\|f-P_{k}\right\|_{\infty}=0
$$

It remains to construct the $Q_{k}$. This can be done in many ways. Here is a simple one. Put

$$
Q_{k}(t)=c_{k}\left\{\frac{1+\cos t}{2}\right\}^{k}
$$

where $c_{k}$ is chosen so that $(b)$ holds. Since $(a)$ is clear, we only need to show $(c)$. Since $Q_{k}$ is even, $(b)$ shows that

$$
1=\frac{c_{k}}{\pi} \int_{0}^{\pi}\left\{\frac{1+\cos t}{2}\right\}^{k} d t>\frac{c_{k}}{\pi} \int_{0}^{\pi}\left\{\frac{1+\cos t}{2}\right\}^{k} \sin t d t=\frac{2 c_{k}}{\pi(k+1)} .
$$

Since $Q_{k}$ is decreasing on $[0, \pi]$, it follows that

$$
Q_{k}(t) \leq Q_{k}(\delta) \leq \frac{\pi(k+1)}{2}\left(\frac{1+\cos \delta}{2}\right)^{k} \quad(0<\delta \leq|t| \leq \pi)
$$

This implies $(c)$, since $1+\cos \delta<2$ if $0<\delta \leq \pi$.

We have proved the following important result:

4.25 Theorem If $f \in C(T)$ and $\epsilon>0$, there is a trigonometric polynomial $P$ such that

$$
|f(t)-P(t)|<\epsilon
$$

for every real $t$.

A more precise result was proved by FejÃ©r (1904): The arithmetic means of the partial sums of the Fourier series of any $f \in C(T)$ converge uniformly to $f$. For a proof (quite similar to the above) see Theorem 3.1 of [45], or p. 89 of [36], vol. I.

4.26 Fourier Series For any $f \in L^{1}(T)$, we define the Fourier coefficients of $f$ by the formula

$$
\hat{f}(n)=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t) e^{-i n t} d t \quad(n \in Z)
$$

where, we recall, $Z$ is the set of all integers. We thus associate with each $f \in L^{1}(T)$ a function $\hat{f}$ on $Z$. The Fourier series of $f$ is

$$
\sum_{-\infty}^{\infty} \hat{f}(n) e^{i n t}
$$

and its partial sums are

$$
s_{N}(t)=\sum_{-N}^{N} \hat{f}(n) e^{i n t} \quad(N=0,1,2, \ldots)
$$

Since $L^{2}(T) \subset L^{1}(T)$, (1) can be applied to every $f \in L^{2}(T)$. Comparing the definitions made in Secs. 4.23 and 4.13, we can now restate Theorems 4.17 and 4.18 in concrete terms:

The Riesz-Fischer theorem asserts that if $\left\{c_{n}\right\}$ is a sequence of complex numbers such that

$$
\sum_{n=-\infty}^{\infty}\left|c_{n}\right|^{2}<\infty
$$

then there exists an $f \in L^{2}(T)$ such that

$$
c_{n}=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t) e^{-i n t} d t \quad(n \in Z)
$$

The Parseval theorem asserts that

$$
\sum_{n=-\infty}^{\infty} \hat{f}(n) \overline{\hat{g}(n)}=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t) \overline{g(t)} d t
$$

whenever $f \in L^{2}(T)$ and $g \in L^{2}(T)$; the series on the left of (6) converges absolutely; and if $s_{N}$ is as in (3), then

$$
\lim _{N \rightarrow \infty}\left\|f-s_{N}\right\|_{2}=0
$$

since a special case of (6) yields

$$
\left\|f-s_{N}\right\|_{2}^{2}=\sum_{|n|>N}|\hat{f}(n)|^{2}
$$

Note that (7) says that every $f \in L^{2}(T)$ is the $L^{2}$-limit of the partial sums of its Fourier series; i.e., the Fourier series of $f$ converges to $f$, in the $L^{2}$-sense. Pointwise convergence presents a more delicate problem, as we shall see in Chap. 5.

The Riesz-Fischer theorem and the Parseval theorem may be summarized by saying that the mapping $f \leftrightarrow \hat{f}$ is a Hilbert space isomorphism of $L^{2}(T)$ onto $\ell^{2}(Z)$.

The theory of Fourier series in other function spaces, for instance in $L^{1}(T)$, is much more difficult than in $L^{2}(T)$, and we shall touch only a few aspects of it.

Observe that the crucial ingredient in the proof of the Riesz-Fischer theorem is the fact that $L^{2}$ is complete. This is so well recognized that the name "RieszFischer theorem" is sometimes given to the theorem which asserts the completeness of $L^{2}$, or even of any $L^{p}$.

\section{Exercises}
In this set of exercises, $H$ always denotes a Hilbert space.

1 If $M$ is a closed subspace of $H$, prove that $M=\left(M^{\perp}\right)^{\perp}$. Is there a similar true statement for subspaces $M$ which are not necessarily closed?

2 Let $\left\{x_{n}: n=1,2,3, \ldots\right\}$ be a linearly independent set of vectors in $H$. Show that the following construction yields an orthonormal set $\left\{u_{n}\right\}$ such that $\left\{x_{1}, \ldots, x_{N}\right\}$ and $\left\{u_{1}, \ldots, u_{N}\right\}$ have the same span for all $N$.

Put $u_{1}=x_{1} /\left\|x_{1}\right\|$. Having $u_{1}, \ldots, u_{n-1}$ define

$$
v_{n}=x_{n}-\sum_{i=1}^{n-1}\left(x_{n}, u_{i}\right) u_{i}, \quad u_{n}=v_{n} /\left\|v_{n}\right\|
$$

Note that this leads to a proof of the existence of a maximal orthonormal set in separable Hilbert spaces which makes no appeal to the Hausdorff maximality principle. (A space is separable if it contains a countable dense subset.)

3 Show that $L^{p}(T)$ is separable if $1 \leq p<\infty$, but that $L^{\infty}(T)$ is not separable.

4 Show that $H$ is separable if and only if $H$ contains a maximal orthonormal system which is at most countable.

5 If $M=\{x: L x=0\}$, where $L$ is a continuous linear functional on $H$, prove that $M^{\perp}$ is a vector space of dimension 1 (unless $M=H$ ).

6 Let $\left\{u_{n}\right\}(n=1,2,3, \ldots)$ be an orthonormal set in $H$. Show that this gives an example of a closed and bounded set which is not compact. Let $Q$ be the set of all $x \in H$ of the form

$$
x=\sum_{1}^{\infty} c_{n} u_{n} \quad\left(\text { where }\left|c_{n}\right| \leq \frac{1}{n}\right)
$$

Prove that $Q$ is compact. ( $Q$ is called the Hilbert cube.)


\end{document}