\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}

\begin{document}
\section{5}
\section{DIFFERENTIATION}
In this chapter we shall (except in the final section) confine our attention to real functions defined on intervals or segments. This is not just a matter of convenience, since genuine differences appear when we pass from real functions to vector-valued ones. Differentiation of functions defined on $R^{k}$ will be discussed in Chap. 9.

\section{THE DERIVATIVE OF A REAL FUNCTION}
5.1 Definition Let $f$ be defined (and real-valued) on $[a, b]$. For any $x \in[a, b]$ form the quotient

$$
\phi(t)=\frac{f(t)-f(x)}{t-x} \quad(a<t<b, t \neq x)
$$

and define

$$
f^{\prime}(x)=\lim _{t \rightarrow x} \phi(t)
$$

provided this limit exists in accordance with Definition 4.1.

We thus associate with the function $f$ a function $f^{\prime}$ whose domain is the set of points $x$ at which the limit (2) exists; $f^{\prime}$ is called the derivative of $f$.

If $f^{\prime}$ is defined at a point $x$, we say that $f$ is differentiable at $x$. If $f^{\prime}$ is defined at every point of a set $E \subset[a, b]$, we say that $f$ is differentiable on $E$.

It is possible to consider right-hand and left-hand limits in (2); this leads to the definition of right-hand and left-hand derivatives. In particular, at the endpoints $a$ and $b$, the derivative, if it exists, is a right-hand or left-hand derivative, respectively. We shall not, however, discuss one-sided derivatives in any detail.

If $f$ is defined on a segment $(a, b)$ and if $a<x<b$, then $f^{\prime}(x)$ is defined by (1) and (2), as above. But $f^{\prime}(a)$ and $f^{\prime}(b)$ are not defined in this case.

5.2 Theorem Let $f$ be defined on $[a, b]$. If $f$ is differentiable at a point $x \in[a, b]$, then $f$ is continuous at $x$.

Proof As $t \rightarrow x$, we have, by Theorem 4.4,

$$
f(t)-f(x)=\frac{f(t)-f(x)}{t-x} \cdot(t-x) \rightarrow f^{\prime}(x) \cdot 0=0 .
$$

The converse of this theorem is not true. It is easy to construct continuous functions which fail to be differentiable at isolated points. In Chap. 7 we shall even become acquainted with a function which is continuous on the whole line without being differentiable at any point!

5.3 Theorem Suppose $f$ and $g$ are defined on $[a, b]$ and are differentiable at $a$ point $x \in[a, b]$. Then $f+g, f g$, and $f / g$ are differentiable at $x$, and

(a) $(f+g)^{\prime}(x)=f^{\prime}(x)+g^{\prime}(x)$;

(b) $(f g)^{\prime}(x)=f^{\prime}(x) g(x)+f(x) g^{\prime}(x)$;

(c) $\left(\frac{f}{g}\right)^{\prime}(x)=\frac{g(x) f^{\prime}(x)-g^{\prime}(x) f(x)}{g^{2}(x)}$.

In $(c)$, we assume of course that $g(x) \neq 0$.

Proof (a) is clear, by Theorem 4.4. Let $h=f g$. Then

$$
h(t)-h(x)=f(t)[g(t)-g(x)]+g(x)[f(t)-f(x)]
$$

If we divide this by $t-x$ and note that $f(t) \rightarrow f(x)$ as $t \rightarrow x$ (Theorem 5.2), (b) follows. Next, let $h=f / g$. Then

$$
\frac{h(t)-h(x)}{t-x}=\frac{1}{g(t) g(x)}\left[g(x) \frac{f(t)-f(x)}{t-x}-f(x) \frac{g(t)-g(x)}{t-x}\right]
$$

Letting $t \rightarrow x$, and applying Theorems 4.4 and 5.2, we obtain (c).

5.4 Examples The derivative of any constant is clearly zero. If $f$ is defined by $f(x)=x$, then $f^{\prime}(x)=1$. Repeated application of $(b)$ and $(c)$ then shows that $x^{n}$ is differentiable, and that its derivative is $n x^{n-1}$, for any integer $n$ (if $n<0$, we have to restrict ourselves to $x \neq 0$ ). Thus every polynomial is differentiable, and so is every rational function, except at the points where the denominator is zero.

The following theorem is known as the "chain rule" for differentiation. It deals with differentiation of composite functions and is probably the most important theorem about derivatives. We shall meet more general versions of it in Chap. 9.

5.5 Theorem Suppose $f$ is continuous on $[a, b], f^{\prime}(x)$ exists at some point $x \in[a, b], g$ is defined on an interval $I$ which contains the range of $f$, and $g$ is differentiable at the point $f(x)$. If

$$
h(t)=g(f(t)) \quad(a \leq t \leq b)
$$

then $h$ is differentiable at $x$, and

$$
h^{\prime}(x)=g^{\prime}(f(x)) f^{\prime}(x)
$$

Proof Let $y=f(x)$. By the definition of the derivative, we have

$$
\begin{aligned}
f(t)-f(x) & =(t-x)\left[f^{\prime}(x)+u(t)\right], \\
g(s)-g(y) & =(s-y)\left[g^{\prime}(y)+v(s)\right]
\end{aligned}
$$

where $t \in[a, b], s \in I$, and $u(t) \rightarrow 0$ as $t \rightarrow x, v(s) \rightarrow 0$ as $s \rightarrow y$. Let $s=f(t)$.

Using first (5) and then (4), we obtain

or, if $t \neq x$,

$$
\begin{aligned}
h(t)-h(x) & =g(f(t))-g(f(x)) \\
& =[f(t)-f(x)] \cdot\left[g^{\prime}(y)+v(s)\right] \\
& =(t-x) \cdot\left[f^{\prime}(x)+u(t)\right] \cdot\left[g^{\prime}(y)+v(s)\right]
\end{aligned}
$$

$$
\frac{h(t)-h(x)}{t-x}=\left[g^{\prime}(y)+v(s)\right] \cdot\left[f^{\prime}(x)+u(t)\right]
$$

Letting $t \rightarrow x$, we see that $s \rightarrow y$, by the continuity of $f$, so that the right side of (6) tends to $g^{\prime}(y) f^{\prime}(x)$, which gives (3).

\subsection{Examples}
(a) Let $f$ be defined by

$$
f(x)= \begin{cases}x \sin \frac{1}{x} & (x \neq 0) \\ 0 & (x=0)\end{cases}
$$

Taking for granted that the derivative of $\sin x$ is $\cos x$ (we shall discuss the trigonometric functions in Chap. 8), we can apply Theorems 5.3 and 5.5 whenever $x \neq 0$, and obtain

$$
f^{\prime}(x)=\sin \frac{1}{x}-\frac{1}{x} \cos \frac{1}{x} \quad(x \neq 0) .
$$

At $x=0$, these theorems do not apply any longer, since $1 / x$ is not defined there, and we appeal directly to the definition: for $t \neq 0$,

$$
\frac{f(t)-f(0)}{t-0}=\sin \frac{1}{t}
$$

As $t \rightarrow 0$, this does not tend to any limit, so that $f^{\prime}(0)$ does not exist.

(b) Let $f$ be defined by

$$
f(x)= \begin{cases}x^{2} \sin \frac{1}{x} & (x \neq 0) \\ 0 & (x=0)\end{cases}
$$

As above, we obtain

$$
f^{\prime}(x)=2 x \sin \frac{1}{x}-\cos \frac{1}{x} \quad(x \neq 0)
$$

At $x=0$, we appeal to the definition, and obtain

$$
\left|\frac{f(t)-f(0)}{t-0}\right|=\left|t \sin \frac{1}{t}\right| \leq|t| \quad(t \neq 0)
$$

letting $t \rightarrow 0$, we see that

$$
f^{\prime}(0)=0 \text {. }
$$

Thus $f$ is differentiable at all points $x$, but $f^{\prime}$ is not a continuous function, since $\cos (1 / x)$ in $(10)$ does not tend to a limit as $x \rightarrow 0$.

\section{MEAN VALUE THEOREMS}
5.7 Definition Let $f$ be a real function defined on a metric space $X$. We say that $f$ has a local maximum at a point $p \in X$ if there exists $\delta>0$ such that $f(q) \leq$ $f(p)$ for all $q \in X$ with $d(p, q)<\delta$.

Local minima are defined likewise.

Our next theorem is the basis of many applications of differentiation.

5.8 Theorem Let $f$ be defined on $[a, b]$; if $f$ has a local maximum at a point $x \in(a, b)$, and if $f^{\prime}(x)$ exists, then $f^{\prime}(x)=0$.

The analogous statement for local minima is of course also true.

Proof Choose $\delta$ in accordance with Definition 5.7, so that

$$
a<x-\delta<x<x+\delta<b .
$$

If $x-\delta<t<x$, then

$$
\frac{f(t)-f(x)}{t-x} \geq 0
$$

Letting $t \rightarrow x$, we see that $f^{\prime}(x) \geq 0$.

If $x<t<x+\delta$, then

$$
\frac{f(t)-f(x)}{t-x} \leq 0
$$

which shows that $f^{\prime}(x) \leq 0$. Hence $f^{\prime}(x)=0$.

5.9 Theorem If $f$ and $g$ are continuous real functions on $[a, b]$ which are differentiable in $(a, b)$, then there is a point $x \in(a, b)$ at which

$$
[f(b)-f(a)] g^{\prime}(x)=[g(b)-g(a)] f^{\prime}(x)
$$

Note that differentiability is not required at the endpoints.

Proof Put

$$
h(t)=[f(b)-f(a)] g(t)-[g(b)-g(a)] f(t) \quad(a \leq t \leq b)
$$

Then $h$ is continuous on $[a, b], h$ is differentiable in $(a, b)$, and

$$
h(a)=f(b) g(a)-f(a) g(b)=h(b)
$$

To prove the theorem, we have to show that $h^{\prime}(x)=0$ for some $x \in(a, b)$. If $h$ is constant, this holds for every $x \in(a, b)$. If $h(t)>h(a)$ for some $t \in(a, b)$, let $x$ be a point on $[a, b]$ at which $h$ attains its maximum

(Theorem 4.16). By (12), $x \in(a, b)$, and Theorem 5.8 shows that $h^{\prime}(x)=0$. If $h(t)<h(a)$ for some $t \in(a, b)$, the same argument applies if we choose for $x$ a point on $[a, b]$ where $h$ attains its minimum.

This theorem is often called a generalized mean value theorem; the following special case is usually referred to as "the" mean value theorem:

5.10 Theorem If $f$ is a real continuous function on $[a, b]$ which is differentiable in $(a, b)$, then there is a point $x \in(a, b)$ at which

$$
f(b)-f(a)=(b-a) f^{\prime}(x)
$$

Proof Take $g(x)=x$ in Theorem 5.9.

5.11 Theorem Suppose $f$ is differentiable in $(a, b)$.

(a) If $f^{\prime}(x) \geq 0$ for all $x \in(a, b)$, then $f$ is monotonically increasing.

(b) If $f^{\prime}(x)=0$ for all $x \in(a, b)$, then $f$ is constant.

(c) If $f^{\prime}(x) \leq 0$ for all $x \in(a, b)$, then $f$ is monotonically decreasing.

Proof All conclusions can be read off from the equation

$$
f\left(x_{2}\right)-f\left(x_{1}\right)=\left(x_{2}-x_{1}\right) f^{\prime}(x)
$$

which is valid, for each pair of numbers $x_{1}, x_{2}$ in $(a, b)$, for some $x$ between $x_{1}$ and $x_{2}$.

\section{THE CONTINUITY OF DERIYATIVES}
We have already seen [Example 5.6(b)] that a function $f$ may have a derivative $f^{\prime}$ which exists at every point, but is discontinuous at some point. However, not every function is a derivative. In particular, derivatives which exist at every point of an interval have one important property in common with functions which are continuous on an interval: Intermediate values are assumed (compare Theorem 4.23). The precise statement follows.

5.12 Theorem Suppose $f$ is a real differentiable function on $[a, b]$ and suppose $f^{\prime}(a)<\lambda<f^{\prime}(b)$. Then there is a point $x \in(a, b)$ such that $f^{\prime}(x)=\lambda$.

A similar result holds of course if $f^{\prime}(a)>f^{\prime}(b)$.

Proof Put $g(t)=f(t)-\lambda t$. Then $g^{\prime}(a)<0$, so that $g\left(t_{1}\right)<g(a)$ for some $t_{1} \in(a, b)$, and $g^{\prime}(b)>0$, so that $g\left(t_{2}\right)<g(b)$ for some $t_{2} \in(a, b)$. Hence $g$ attains its minimum on $[a, b]$ (Theorem 4.16) at some point $x$ such that $a<x<b$. By Theorem 5.8, $g^{\prime}(x)=0$. Hence $f^{\prime}(x)=\lambda$.

Corollary If $f$ is differentiable on $[a, b]$, then $f^{\prime}$ cannot have any simple discontinuities on $[a, b]$.

But $f^{\prime}$ may very well have discontinuities of the second kind.

\section{L'HOSPITAL'S RULE}
The following theorem is frequently useful in the evaluation of limits.

5.13 Theorem Suppose $f$ and $g$ are real and differentiable in $(a, b)$, and $g^{\prime}(x) \neq 0$ for all $x \in(a, b)$, where $-\infty \leq a<b \leq+\infty$. Suppose

$$
\frac{f^{\prime}(x)}{g^{\prime}(x)} \rightarrow A \text { as } x \rightarrow a
$$

If

$$
f(x) \rightarrow 0 \text { and } g(x) \rightarrow 0 \text { as } x \rightarrow a \text {, }
$$

or if

$$
g(x) \rightarrow+\infty \text { as } x \rightarrow a
$$

then

$$
\frac{f(x)}{g(x)} \rightarrow A \text { as } x \rightarrow a
$$

The analogous statement is of course also true if $x \rightarrow b$, or if $g(x) \rightarrow-\infty$ in (15). Let us note that we now use the limit concept in the extended sense of Definition 4.33.

Proof We first consider the case in which $-\infty \leq A<+\infty$. Choose a real number $q$ such that $A<q$, and then choose $r$ such that $A<r<q$. By (13) there is a point $c \in(a, b)$ such that $a<x<c$ implies

$$
\frac{f^{\prime}(x)}{g^{\prime}(x)}<r
$$

If $a<x<y<c$, then Theorem 5.9 shows that there is a point $t \in(x, y)$ such that

$$
\frac{f(x)-f(y)}{g(x)-g(y)}=\frac{f^{\prime}(t)}{g^{\prime}(t)}<r
$$

Suppose (14) holds. Letting $x \rightarrow a$ in (18), we see that

$$
\frac{f(y)}{g(y)} \leq r<q \quad(a<y<c)
$$

Next, suppose (15) holds. Keeping $y$ fixed in (18), we can choose a point $c_{1} \in(a, y)$ such that $g(x)>g(y)$ and $g(x)>0$ if $a<x<c_{1}$. Multiplying (18) by $[g(x)-g(y)] / g(x)$, we obtain

$$
\frac{f(x)}{g(x)}<r-r \frac{g(y)}{g(x)}+\frac{f(y)}{g(x)} \quad\left(a<x<c_{1}\right)
$$

If we let $x \rightarrow a$ in (20), (15) shows that there is a point $c_{2} \in\left(a, c_{1}\right)$ such that

$$
\frac{f(x)}{g(x)}<q \quad\left(a<x<c_{2}\right)
$$

Summing up, (19) and (21) show that for any $q$, subject only to the condition $A<q$, there is a point $c_{2}$ such that $f(x) / g(x)<q$ if $a<x<c_{2}$.

In the same manner, if $-\infty<A \leq+\infty$, and $p$ is chosen so that $p<A$, we can find a point $c_{3}$ such that

$$
p<\frac{f(x)}{g(x)} \quad\left(a<x<c_{3}\right)
$$

and (16) follows from these two statements.

\section{DERIVATIVES OF HIGHER ORDER}
5.14 Definition If $f$ has a derivative $f^{\prime}$ on an interval, and if $f^{\prime}$ is itself differentiable, we denote the derivative of $f^{\prime}$ by $f^{\prime \prime}$ and call $f^{\prime \prime}$ the second derivative of $f$. Continuing in this manner, we obtain functions

$$
f, f^{\prime}, f^{\prime \prime}, f^{(3)}, \ldots, f^{(n)}
$$

each of which is the derivative of the preceding one. $f^{(n)}$ is called the $n$th derivative, or the derivative of order $n$, of $f$.

In order for $f^{(n)}(x)$ to exist at a point $x, f^{(n-1)}(t)$ must exist in a neighborhood of $x$ (or in a one-sided neighborhood, if $x$ is an endpoint of the interval on which $f$ is defined), and $f^{(n-1)}$ must be differentiable at $x$. Since $f^{(n-1)}$ must exist in a neighborhood of $x, f^{(n-2)}$ must be differentiable in that neighborhood.

\section{TAYLOR'S THEOREM}
5.15 Theorem Suppose $f$ is a real function on $[a, b], n$ is a positive integer, $f^{(n-1)}$ is continuous on $[a, b], f^{(n)}(t)$ exists for every $t \in(a, b)$. Let $\alpha, \beta$ be distinct points of $[a, b]$, and define

$$
P(t)=\sum_{k=0}^{n-1} \frac{f^{(k)}(\alpha)}{k !}(t-\alpha)^{k}
$$

Then there exists a point $x$ between $\alpha$ and $\beta$ such that

$$
f(\beta)=P(\beta)+\frac{f^{(n)}(x)}{n !}(\beta-\alpha)^{n}
$$

For $n=1$, this is just the mean value theorem. In general, the theorem shows that $f$ can be approximated by a polynomial of degree $n-1$, and that (24) allows us to estimate the error, if we know bounds on $\left|f^{(n)}(x)\right|$.

Proof Let $M$ be the number defined by

$$
f(\beta)=P(\beta)+M(\beta-\alpha)^{n}
$$

and put

$$
g(t)=f(t)-P(t)-M(t-\alpha)^{n} \quad(a \leq t \leq b)
$$

We have to show that $n ! M=f^{(n)}(x)$ for some $x$ between $\alpha$ and $\beta$. By $(23)$ and (26),

$$
g^{(n)}(t)=f^{(n)}(t)-n ! M \quad(a<t<b) .
$$

Hence the proof will be complete if we can show that $g^{(n)}(x)=0$ for some $x$ between $\alpha$ and $\beta$.

Since $P^{(k)}(\alpha)=f^{(k)}(\alpha)$ for $k=0, \ldots, n-1$, we have

$$
g(\alpha)=g^{\prime}(\alpha)=\cdots=g^{(n-1)}(\alpha)=0
$$

Our choice of $M$ shows that $g(\beta)=0$, so that $g^{\prime}\left(x_{1}\right)=0$ for some $x_{1}$ between $\alpha$ and $\beta$, by the mean value theorem. Since $g^{\prime}(\alpha)=0$, we conclude similarly that $g^{\prime \prime}\left(x_{2}\right)=0$ for some $x_{2}$ between $\alpha$ and $x_{1}$. After $n$ steps we arrive at the conclusion that $g^{(n)}\left(x_{n}\right)=0$ for some $x_{n}$ between $\alpha$ and $x_{n-1}$, that is, between $\alpha$ and $\beta$.

\section{DIFFERENTIATION OF VECTOR-VALUED FUNCTIONS}
5.16 Remarks Definition 5.1 applies without any change to complex functions $f$ defined on $[a, b]$, and Theorems 5.2 and 5.3 , as well as their proofs, remain valid. If $f_{1}$ and $f_{2}$ are the real and imaginary parts of $f$, that is, if

$$
f(t)=f_{1}(t)+i f_{2}(t)
$$

for $a \leq t \leq b$, where $f_{1}(t)$ and $f_{2}(t)$ are real, then we clearly have

$$
f^{\prime}(x)=f_{1}^{\prime}(x)+i f_{2}^{\prime}(x)
$$

also, $f$ is differentiable at $x$ if and only if both $f_{1}$ and $f_{2}$ are differentiable at $x$.

Passing to vector-valued functions in general, i.e., to functions $\mathbf{f}$ which map $[a, b]$ into some $R^{k}$, we may still apply Definition 5.1 to define $f^{\prime}(x)$. The term $\phi(t)$ in (1) is now, for each $t$, a point in $R^{k}$, and the limit in (2) is taken with respect to the norm of $R^{k}$. In other words, $\mathbf{f}^{\prime}(x)$ is that point of $R^{k}$ (if there is one) for which

$$
\lim _{t \rightarrow x}\left|\frac{\mathbf{f}(t)-\mathbf{f}(x)}{t-x}-\mathbf{f}^{\prime}(x)\right|=0
$$

and $\mathbf{f}^{\prime}$ is again a function with values in $R^{k}$.

If $f_{1}, \ldots, f_{k}$ are the components of $\mathrm{f}$, as defined in Theorem 4.10 , then

$$
\mathbf{f}^{\prime}=\left(f_{1}^{\prime}, \ldots, f_{k}^{\prime}\right)
$$

and $\mathbf{f}$ is differentiable at a point $x$ if and only if each of the functions $f_{1}, \ldots, f_{k}$ is differentiable at $x$.

Theorem 5.2 is true in this context as well, and so is Theorem 5.3 $(a)$ and (b), if $f g$ is replaced by the inner product $\mathbf{f} \cdot \mathbf{g}$ (see Definition 4.3).

When we turn to the mean value theorem, however, and to one of its consequences, namely, L'Hospital's rule, the situation changes. The next two examples will show that each of these results fails to be true for complex-valued functions.

5.17 Example Define, for real $x$,

$$
f(x)=e^{i x}=\cos x+i \sin x
$$

(The last expression may be taken as the definition of the complex exponential $e^{i x}$; see Chap. 8 for a full discussion of these functions.) Then

$$
f(2 \pi)-f(0)=1-1=0
$$

but

$$
f^{\prime}(x)=i e^{i x}
$$

so that $\left|f^{\prime}(x)\right|=1$ for all real $x$.

Thus Theorem 5.10 fails to hold in this case.

5.18 Example On the segment $(0,1)$, define $f(x)=x$ and

$$
g(x)=x+x^{2} e^{i / x^{2}}
$$

Since $\left|e^{i t}\right|=1$ for all real $t$, we see that

$$
\lim _{x \rightarrow 0} \frac{f(x)}{g(x)}=1
$$

Next,

$$
g^{\prime}(x)=1+\left\{2 x-\frac{2 i}{x}\right\} e^{i / x^{2}} \quad(0<x<1)
$$

so that

$$
\left|g^{\prime}(x)\right| \geq\left|2 x-\frac{2 i}{x}\right|-1 \geq \frac{2}{x}-1
$$

Hence

and so

$$
\left|\frac{f^{\prime}(x)}{g^{\prime}(x)}\right|=\frac{1}{\left|g^{\prime}(x)\right|} \leq \frac{x}{2-x}
$$

$$
\lim _{x \rightarrow 0} \frac{f^{\prime}(x)}{g^{\prime}(x)}=0
$$

By (36) and (40), L'Hospital's rule fails in this case. Note also that $g^{\prime}(x) \neq 0$ on $(0,1)$, by $(38)$.

However, there is a consequence of the mean value theorem which, for purposes of applications, is almost as useful as Theorem 5.10, and which remains true for vector-valued functions: From Theorem 5.10 it follows that

$$
|f(b)-f(a)| \leq(b-a) \sup _{a<x<b}\left|f^{\prime}(x)\right| .
$$

5.19 Theorem Suppose $\mathrm{f}$ is a continuous mapping of $[a, b]$ into $R^{k}$ and $\mathbf{f}$ is differentiable in $(a, b)$. Then there exists $x \in(a, b)$ such that

$$
|\mathbf{f}(b)-\mathbf{f}(a)| \leq(b-a)\left|\mathbf{f}^{\prime}(x)\right|
$$

Proof $^{1} \quad$ Put $\mathbf{z}=\mathbf{f}(b)-\mathbf{f}(a)$, and define

$$
\varphi(t)=\mathbf{z} \cdot \mathbf{f}(t) \quad(a \leq t \leq b)
$$

Then $\varphi$ is a real-valued continuous function on $[a, b]$ which is differentiable in $(a, b)$. The mean value theorem shows therefore that

$$
\varphi(b)-\varphi(a)=(b-a) \varphi^{\prime}(x)=(b-a) \mathbf{z} \cdot \mathbf{f}^{\prime}(x)
$$

for some $x \in(a, b)$. On the other hand,

$$
\varphi(b)-\varphi(a)=\mathbf{z} \cdot \mathbf{f}(b)-\mathbf{z} \cdot \mathbf{f}(a)=\mathbf{z} \cdot \mathbf{z}=|\mathbf{z}|^{2}
$$

The Schwarz inequality now gives

$$
|\mathbf{z}|^{2}=(b-a)\left|\mathbf{z} \cdot \mathbf{f}^{\prime}(x)\right| \leq(b-a)|\mathbf{z}|\left|\mathbf{f}^{\prime}(x)\right|
$$

Hence $|\mathbf{z}| \leq(b-a)\left|\mathbf{f}^{\prime}(x)\right|$, which is the desired conclusion.

1 V. P. Havin translated the second edition of this book into Russian and added this proof to the original one.

\section{EXERCISES}
\begin{enumerate}
  \item Let $f$ be defined for all real $x$, and suppose that
\end{enumerate}

$$
|f(x)-f(y)| \leq(x-y)^{2}
$$

for all real $x$ and $y$. Prove that $f$ is constant.

\begin{enumerate}
  \setcounter{enumi}{1}
  \item Suppose $f^{\prime}(x)>0$ in $(a, b)$. Prove that $f$ is strictly increasing in $(a, b)$, and let $g$ be its inverse function. Prove that $g$ is differentiable, and that
\end{enumerate}

$$
g^{\prime}(f(x))=\frac{1}{f^{\prime}(x)} \quad(a<x<b)
$$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item Suppose $g$ is a real function on $R^{1}$, with bounded derivative (say $\left|g^{\prime}\right| \leq M$ ). Fix $\varepsilon>0$, and define $f(x)=x+\varepsilon g(x)$. Prove that $f$ is one-to-one if $\varepsilon$ is small enough. (A set of admissible values of $\varepsilon$ can be determined which depends only on $M$.)

  \item If

\end{enumerate}

$$
C_{0}+\frac{C_{1}}{2}+\cdots+\frac{C_{n-1}}{n}+\frac{C_{n}}{n+1}=0
$$

where $C_{0}, \ldots, C_{n}$ are real constants, prove that the equation

$$
C_{0}+C_{1} x+\cdots+C_{n-1} x^{n-1}+C_{n} x^{n}=0
$$

has at least one real root between 0 and 1 .

\begin{enumerate}
  \setcounter{enumi}{4}
  \item Suppose $f$ is defined and differentiable for every $x>0$, and $f^{\prime}(x) \rightarrow 0$ as $x \rightarrow+\infty$. Put $g(x)=f(x+1)-f(x)$. Prove that $g(x) \rightarrow 0$ as $x \rightarrow+\infty$.

  \item Suppose

\end{enumerate}

(a) $f$ is continuous for $x \geq 0$,

(b) $f^{\prime}(x)$ exists for $x>0$,

(c) $f(0)=0$,

(d) $f^{\prime}$ is monotonically increasing.

Put

$$
g(x)=\frac{f(x)}{x} \quad(x>0)
$$

and prove that $g$ is monotonically increasing.

\begin{enumerate}
  \setcounter{enumi}{6}
  \item Suppose $f^{\prime}(x), g^{\prime}(x)$ exist, $g^{\prime}(x) \neq 0$, and $f(x)=g(x)=0$. Prove that
\end{enumerate}

$$
\lim _{t \rightarrow x} \frac{f(t)}{g(t)}=\frac{f^{\prime}(x)}{g^{\prime}(x)}
$$

(This holds also for complex functions.)

\begin{enumerate}
  \setcounter{enumi}{7}
  \item Suppose $f^{\prime}$ is continuous on $[a, b]$ and $\varepsilon>0$. Prove that there exists $\delta>0$ such that
\end{enumerate}

$$
\left|\frac{f(t)-f(x)}{t-x}-f^{\prime}(x)\right|<\varepsilon
$$

whenever $0<|t-x|<\delta, a \leq x \leq b, a \leq t \leq b$. (This could be expressed by saying that $f$ is uniformly differentiable on $[a, b]$ if $f^{\prime}$ is continuous on $[a, b]$.) Does this hold for vector-valued functions too?

\begin{enumerate}
  \setcounter{enumi}{8}
  \item Let $f$ be a continuous real function on $R^{1}$, of which it is known that $f^{\prime}(x)$ exists for all $x \neq 0$ and that $f^{\prime}(x) \rightarrow 3$ as $x \rightarrow 0$. Does it follow that $f^{\prime}(0)$ exists ?

  \item Suppose $f$ and $g$ are complex differentiable functions on $(0,1), f(x) \rightarrow 0, g(x) \rightarrow 0$, $f^{\prime}(x) \rightarrow A, g^{\prime}(x) \rightarrow B$ as $x \rightarrow 0$, where $A$ and $B$ are complex numbers, $B \neq 0$. Prove that

\end{enumerate}

$$
\lim _{x \rightarrow 0} \frac{f(x)}{g(x)}=\frac{A}{B}
$$

Compare with Example 5.18. Hint:

$$
\frac{f(x)}{g(x)}=\left\{\frac{f(x)}{x}-A\right\} \cdot \frac{x}{g(x)}+A \cdot \frac{x}{g(x)} .
$$

Apply Theorem 5.13 to the real and imaginary parts of $f(x) / x$ and $g(x) / x$.

\begin{enumerate}
  \setcounter{enumi}{10}
  \item Suppose $f$ is defined in a neighborhood of $x$, and suppose $f^{\prime \prime}(x)$ exists. Show that
\end{enumerate}

$$
\lim _{h \rightarrow 0} \frac{f(x+h)+f(x-h)-2 f(x)}{h^{2}}=f^{\prime \prime}(x) .
$$

Show by an example that the limit may exist even if $f^{\prime \prime}(x)$ does not.

Hint: Use Theorem 5.13.

\begin{enumerate}
  \setcounter{enumi}{11}
  \item If $f(x)=|x|^{3}$, compute $f^{\prime}(x), f^{\prime \prime}(x)$ for all real $x$, and show that $f^{(3)}(0)$ does not exist.

  \item Suppose $a$ and $c$ are real numbers, $c>0$, and $f$ is defined on $[-1,1]$ by

\end{enumerate}

$$
f(x)= \begin{cases}x^{a} \sin \left(|x|^{-c}\right) & (\text { if } x \neq 0) \\ 0 & (\text { if } x=0)\end{cases}
$$

Prove the following statements:

(a) $f$ is continuous if and only if $a>0$.

(b) $f^{\prime}(0)$ exists if and only if $a>1$.

(c) $f^{\prime}$ is bounded if and only if $a \geq 1+c$.

(d) $f^{\prime}$ is continuous if and only if $a>1+c$.

(e) $f^{\prime \prime}(0)$ exists if and only if $a>2+c$.

$(f) f^{\prime \prime}$ is bounded if and only if $a \geq 2+2 c$.

(g) $f^{\prime \prime}$ is continuous if and only if $a>2+2 c$.

\begin{enumerate}
  \setcounter{enumi}{13}
  \item Let $f$ be a differentiable real function defined in $(a, b)$. Prove that $f$ is convex if and only if $f^{\prime}$ is monotonically increasing. Assume next that $f^{\prime \prime}(x)$ exists for every $x \in(a, b)$, and prove that $f$ is convex if and only if $f^{\prime \prime}(x) \geq 0$ for all $x \in(a, b)$.

  \item Suppose $a \in R^{1}, f$ is a twice-differentiable real function on $(a, \infty)$, and $M_{0}, M_{1}, M_{2}$ are the least upper bounds of $|f(x)|,\left|f^{\prime}(x)\right|,\left|f^{\prime \prime}(x)\right|$, respectively, on $(a, \infty)$. Prove that

\end{enumerate}

$$
M_{1}^{2} \leq 4 M_{0} M_{2} \text {. }
$$

Hint: If $h>0$, Taylor's theorem shows that

$$
f^{\prime}(x)=\frac{1}{2 h}[f(x+2 h)-f(x)]-h f^{\prime \prime}(\xi)
$$

for some $\xi \in(x, x+2 h)$. Hence

$$
\left|f^{\prime}(x)\right| \leq h M_{2}+\frac{M_{0}}{h}
$$

To show that $M_{1}^{2}=4 M_{0} M_{2}$ can actually happen, take $a=-1$, define

$$
f(x)= \begin{cases}2 x^{2}-1 & (-1<x<0) \\ \frac{x^{2}-1}{x^{2}+1} & (0 \leq x<\infty)\end{cases}
$$

and show that $M_{0}=1, M_{1}=4, M_{2}=4$.

Does $M_{1}^{2} \leq 4 M_{0} M_{2}$ hold for vector-valued functions too?

\begin{enumerate}
  \setcounter{enumi}{15}
  \item Suppose $f$ is twice-differentiable on $(0, \infty), f^{\prime \prime}$ is bounded on $(0, \infty)$, and $f(x) \rightarrow 0$ as $x \rightarrow \infty$. Prove that $f^{\prime}(x) \rightarrow 0$ as $x \rightarrow \infty$.
\end{enumerate}

Hint: Let $a \rightarrow \infty$ in Exercise 15.

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Suppose $f$ is a real, three times differentiable function on $[-1,1]$, such that
\end{enumerate}

$$
f(-1)=0, \quad f(0)=0, \quad f(1)=1, \quad f^{\prime}(0)=0 .
$$

Prove that $f^{(3)}(x) \geq 3$ for some $x \in(-1,1)$.

Note that equality holds for $\frac{1}{2}\left(x^{3}+x^{2}\right)$.

Hint: Use Theorem 5.15, with $\alpha=0$ and $\beta= \pm 1$, to show that there exist $s \in(0,1)$ and $t \in(-1,0)$ such that

$$
f^{(3)}(s)+f^{(3)}(t)=6 \text {. }
$$

\begin{enumerate}
  \setcounter{enumi}{17}
  \item Suppose $f$ is a real function on $[a, b], n$ is a positive integer, and $f^{(n-1)}$ exists for every $t \in[a, b]$. Let $\alpha, \beta$, and $\boldsymbol{P}$ be as in Taylor's theorem (5.15). Define
\end{enumerate}

$$
Q(t)=\frac{f(t)-f(\beta)}{t-\beta}
$$

for $t \in[a, b], t \neq \beta$, differentiate

$$
f(t)-f(\beta)=(t-\beta) Q(t)
$$

$n-1$ times at $t=\alpha$, and derive the following version of Taylor's theorem:

$$
f(\beta)=P(\beta)+\frac{Q^{(n-1)}(\alpha)}{(n-1) !}(\beta-\alpha)^{n}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item Suppose $f$ is defined in $(-1,1)$ and $f^{\prime}(0)$ exists. Suppose $-1<\alpha_{n}<\beta_{n}<1$, $\alpha_{n} \rightarrow 0$, and $\beta_{n} \rightarrow 0$ as $n \rightarrow \infty$. Define the difference quotients
\end{enumerate}

$$
D_{n}=\frac{f\left(\beta_{n}\right)-f\left(\alpha_{n}\right)}{\beta_{n}-\alpha_{n}} \text {. }
$$

Prove the following statements:

(a) If $\alpha_{n}<0<\beta_{n}$, then $\lim D_{n}=f^{\prime}(0)$.

(b) If $0<\alpha_{n}<\beta_{n}$ and $\left\{\beta_{n} /\left(\beta_{n}-\alpha_{n}\right)\right\}$ is bounded, then $\lim D_{n}=f^{\prime}(0)$.

(c) If $f^{\prime}$ is continuous in $(-1,1)$, then $\lim D_{n}=f^{\prime}(0)$.

Give an example in which $f$ is differentiable in $(-1,1)$ (but $f^{\prime}$ is not continuous at 0 ) and in which $\alpha_{n}, \beta_{n}$ tend to 0 in such a way that $\lim D_{n}$ exists but is different from $f^{\prime}(0)$.

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Formulate and prove an inequality which follows from Taylor's theorem and which remains valid for vector-valued functions.

  \item Let $E$ be a closed subset of $R^{1}$. We saw in Exercise 22, Chap. 4, that there is a real continuous function $f$ on $R^{1}$ whose zero set is $E$. Is it possible, for each closed set $E$, to find such an $f$ which is differentiable on $R^{1}$, or one which is $n$ times differentiable, or even one which has derivatives of all orders on $R^{1}$ ?

  \item Suppose $f$ is a real function on $(-\infty, \infty)$. Call $x$ a fixed point of $f$ if $f(x)=x$. (a) If $f$ is differentiable and $f^{\prime}(t) \neq 1$ for every real $t$, prove that $f$ has at most one fixed point.

\end{enumerate}

(b) Show that the function $f$ defined by

$$
f(t)=t+\left(1+e^{t}\right)^{-1}
$$

has no fixed point, although $0<f^{\prime}(t)<1$ for all real $t$.

(c) However, if there is a constant $A<1$ such that $\left|f^{\prime}(t)\right| \leq A$ for all real $t$, prove that a fixed point $x$ of $f$ exists, and that $x=\lim x_{n}$, where $x_{1}$ is an arbitrary real number and

$$
x_{n+1}=f\left(x_{n}\right)
$$

for $n=1,2,3, \ldots$.

(d) Show that the process described in (c) can be visualized by the zig-zag path

$$
\left(x_{1}, x_{2}\right) \rightarrow\left(x_{2}, x_{2}\right) \rightarrow\left(x_{2}, x_{3}\right) \rightarrow\left(x_{3}, x_{3}\right) \rightarrow\left(x_{3}, x_{4}\right) \rightarrow \cdots .
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item The function $f$ defined by
\end{enumerate}

$$
f(x)=\frac{x^{3}+1}{3}
$$

has three fixed points, say $\alpha, \beta, \gamma$, where

$$
-2<\alpha<-1, \quad 0<\beta<1, \quad 1<\gamma<2 .
$$

For arbitrarily chosen $x_{1}$, define $\left\{x_{n}\right\}$ by setting $x_{n+1}=f\left(x_{n}\right)$.

(a) If $x_{1}<\alpha$, prove that $x_{n} \rightarrow-\infty$ as $n \rightarrow \infty$.

(b) If $\alpha<x_{1}<\gamma$, prove that $x_{n} \rightarrow \beta$ as $n \rightarrow \infty$.

(c) If $\gamma<x_{1}$, prove that $x_{n} \rightarrow+\infty$ as $n \rightarrow \infty$.

Thus $\beta$ can be located by this method, but $\alpha$ and $\gamma$ cannot.

\begin{enumerate}
  \setcounter{enumi}{23}
  \item The process described in part $(c)$ of Exercise 22 can of course also be applied to functions that map $(0, \infty)$ to $(0, \infty)$.
\end{enumerate}

Fix some $\alpha>1$, and put

$$
f(x)=\frac{1}{2}\left(x+\frac{\alpha}{x}\right), \quad g(x)=\frac{\alpha+x}{1+x} .
$$

Both $f$ and $g$ have $\sqrt{\alpha}$ as their only fixed point in $(0, \infty)$. Try to explain, on the basis of properties of $f$ and $g$, why the convergence in Exercise 16, Chap. 3, is so much more rapid than it is in Exercise 17. (Compare $f^{\prime}$ and $g^{\prime}$, draw the zig-zags suggested in Exercise 22.)

Do the same when $0<\alpha<1$.

\begin{enumerate}
  \setcounter{enumi}{24}
  \item Suppose $f$ is twice differentiable on $[a, b], f(a)<0, f(b)>0, f^{\prime}(x) \geq \delta>0$, and $0 \leq f^{\prime \prime}(x) \leq M$ for all $x \in[a, b]$. Let $\xi$ be the unique point in $(a, b)$ at which $f(\xi)=0$.
\end{enumerate}

Complete the details in the following outline of Newton's method for computing $\xi$.

(a) Choose $x_{1} \in(\xi, b)$, and define $\left\{x_{n}\right\}$ by

$$
x_{n+1}=x_{n}-\frac{f\left(x_{n}\right)}{f^{\prime}\left(x_{n}\right)}
$$

Interpret this geometrically, in terms of a tangent to the graph of $f$.

(b) Prove that $x_{n+1}<x_{n}$ and that

$$
\lim _{n \rightarrow \infty} x_{n}=\xi
$$

(c) Use Taylor's theorem to show that

$$
x_{n+1}-\xi=\frac{f^{\prime \prime}\left(t_{n}\right)}{2 f^{\prime}\left(x_{n}\right)}\left(x_{n}-\xi\right)^{2}
$$

for some $t_{n} \in\left(\xi, x_{n}\right)$.

(d) If $A=M / 2 \delta$, deduce that

$$
0 \leq x_{n+1}-\xi \leq \frac{1}{A}\left[A\left(x_{1}-\xi\right)\right]^{2 n}
$$

(Compare with Exercises 16 and 18, Chap. 3.)

(e) Show that Newton's method amounts to finding a fixed point of the function $g$ defined by

$$
g(x)=x-\frac{f(x)}{f^{\prime}(x)}
$$

How does $g^{\prime}(x)$ behave for $x$ near $\xi$ ?

(f) Put $f(x)=x^{1 / 3}$ on $(-\infty, \infty)$ and try Newton's method. What happens?

\begin{enumerate}
  \setcounter{enumi}{25}
  \item Suppose $f$ is differentiable on $[a, b], f(a)=0$, and there is a real number $A$ such that $\left|f^{\prime}(x)\right| \leq A|f(x)|$ on $[a, b]$. Prove that $f(x)=0$ for all $x \in[a, b]$. Hint: Fix $x_{0} \in[a, b]$, let
\end{enumerate}

$$
M_{0}=\sup |f(x)|, \quad M_{1}=\sup \left|f^{\prime}(x)\right|
$$

for $a \leq x \leq x_{0}$. For any such $x$,

$$
|f(x)| \leq M_{1}\left(x_{0}-a\right) \leq A\left(x_{0}-a\right) M_{0} .
$$

Hence $M_{0}=0$ if $A\left(x_{0}-a\right)<1$. That is, $f=0$ on $\left[a, x_{0}\right]$. Proceed.

\begin{enumerate}
  \setcounter{enumi}{26}
  \item Let $\phi$ be a real function defined on a rectangle $R$ in the plane, given by $a \leq x \leq b$, $\alpha \leq y \leq \beta$. A solution of the initial-value problem
\end{enumerate}

$$
y^{\prime}=\phi(x, y), \quad y(a)=c \quad(\alpha \leq c \leq \beta)
$$

is, by definition, a differentiable function $f$ on $[a, b]$ such that $f(a)=c, \alpha \leq f(x) \leq \beta$, and

$$
f^{\prime}(x)=\phi(x, f(x)) \quad(a \leq x \leq b)
$$

Prove that such a problem has at most one solution if there is a constant $A$ such that

$$
\left|\phi\left(x, y_{2}\right)-\phi\left(x, y_{1}\right)\right| \leq A\left|y_{2}-y_{1}\right|
$$

whenever $\left(x, y_{1}\right) \in R$ and $\left(x, y_{2}\right) \in R$.

Hint: Apply Exercise 26 to the difference of two solutions. Note that this uniqueness theorem does not hold for the initial-value problem

$$
y^{\prime}=y^{1 / 2}, \quad y(0)=0
$$

which has two solutions: $f(x)=0$ and $f(x)=x^{2} / 4$. Find all other solutions.

\begin{enumerate}
  \setcounter{enumi}{27}
  \item Formulate and prove an analogous uniqueness theorem for systems of differential equations of the form
\end{enumerate}

$$
y_{\jmath}^{\prime}=\phi_{\jmath}\left(x, y_{1}, \ldots, y_{k}\right), \quad y_{\jmath}(a)=c_{\jmath} \quad(j=1, \ldots, k)
$$

Note that this can be rewritten in the form

$$
\mathbf{y}^{\prime}=\boldsymbol{\phi}(x, \mathbf{y}), \quad \mathbf{y}(a)=\mathbf{c}
$$

where $\mathbf{y}=\left(y_{1}, \ldots, y_{k}\right)$ ranges over a $k$-cell, $\boldsymbol{\phi}$ is the mapping of a $(k+1)$-cell into the Euclidean $k$-space whose components are the functions $\phi_{1}, \ldots, \phi_{k}$, and $\mathrm{c}$ is the vector $\left(c_{1}, \ldots, c_{k}\right)$. Use Exercise 26 , for vector-valued functions.

\begin{enumerate}
  \setcounter{enumi}{28}
  \item Specialize Exercise 28 by considering the system
\end{enumerate}

$$
\begin{aligned}
y_{j}^{\prime} & =y_{j+1} \quad(j=1, \ldots, k-1) \\
y_{k}^{\prime} & =f(x)-\sum_{j=1}^{k} g_{J}(x) y_{j}
\end{aligned}
$$

where $f, g_{1}, \ldots, g_{k}$ are continuous real functions on $[a, b]$, and derive a uniqueness theorem for solutions of the equation

$$
y^{(k)}+g_{k}(x) y^{(k-1)}+\cdots+g_{2}(x) y^{\prime}+g_{1}(x) y=f(x),
$$

subject to initial conditions

$$
y(a)=c_{1}, \quad y^{\prime}(a)=c_{2}, \quad \ldots, \quad y^{(k-1)}(a)=c_{k}
$$


\end{document}