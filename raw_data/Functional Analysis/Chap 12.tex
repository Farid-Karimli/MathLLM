\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{bbold}
\usepackage{mathrsfs}

\begin{document}
\section{BOUNDED OPERATORS ON A HILBERT SPACE}
\section{Basic Facts}
12.1 Definitions A complex vector space $H$ is called an inner product space (or unitary space) if to each ordered pair of vectors $x$ and $y$ in $H$ is associated a complex number $(x, y)$, called the inner product or scalar product of $x$ and $y$, such that the following rules hold:

(a) $(y, x)=\overline{(x, y)}$. (The bar denotes complex conjugation.)

(b) $(x+y, z)=(x, z)+(y, z)$.

(c) $(\alpha x, y)=\alpha(x, y)$ if $x \in H, y \in H, \alpha \in C$.

(d) $(x, x) \geq 0$ for all $x \in H$.

(e) $(x, x)=0$ only if $x=0$.

For fixed $y,(x, y)$ is therefore a linear function of $x$. For fixed $x$, it is a conjugatelinear function of $y$. Such functions of two variables are sometimes called sesquilinear.

If $(x, y)=0, x$ is said to be orthogonal to $y$, and the notation $x \perp y$ is sometimes used. Since $(x, y)=0$ implies $(y, x)=0$, the relation $\perp$ is symmetric. If $E \subset H$ and $F \subset \underline{H}$, the notation $E \perp F$ means that $x \perp y$ whenever $x \in E$ and $y \in F$. Also, $E^{\perp}$ is the set of all $y \in H$ that are orthogonal to every $x \in E$.

Every inner product space can be normed by defining

$$
\|x\|=(x, x)^{1 / 2} .
$$

Theorem 12.2 implies this. If the resulting normed space is complete, it is called a Hilbert space.

12.2 Theorem If $x \in H$ and $y \in H$, where $H$ is an inner product space, then

$$
|(x, y)| \leq\|x\|\|y\|
$$

and

(2)

$$
\|x+y\| \leq\|x\|+\|y\| .
$$

Moreover

$$
\|y\| \leq\|\dot{\lambda} x+y\| \quad \text { for every } \lambda \in \mathbb{C}
$$

if and only if $x \perp y$.

PROOF Put $\alpha=(x, y)$. A simple computation gives

$$
0 \leq\|\lambda x+y\|^{2}=|\lambda|^{2}\|x\|^{2}+2 \operatorname{Re}(\alpha \lambda)+\|y\|^{2} .
$$

Hence (3) holds if $\alpha=0$. If $x=0$, (1) and (3) are obvious. If $x \neq 0$, take $\lambda=-\bar{\alpha} /\|x\|^{2}$. With this $\lambda$, (4) becomes

$$
0 \leq\|\lambda x+y\|^{2}=\|y\|^{2}-\frac{|\alpha|^{2}}{\|x\|^{2}}
$$

This proves (1) and shows that (3) is false when $\alpha \neq 0$. By squaring both sides of (2), one sees that (2) is a consequence of (1).

Note: Unless the contrary is explicitly stated, the letter $H$ will from now on denote a Hilbert space.

12.3 Theorem Every nonempty closed convex set $E \subset H$ contains a unique $x$ of minimal norm.

PROOF The parallelogram law

$$
\|x+y\|^{2}+\|x-y\|^{2}=2\|x\|^{2}+2\|y\|^{2} \quad(x \in H, y \in H)
$$

follows directly from the definition $\|x\|^{2}=(x, x)$. Put

$$
d=\inf \{\|x\|: x \in E\}
$$

Choose $x_{n} \in E$ so that $\left\|x_{n}\right\| \rightarrow d$. Since $\frac{1}{2}\left(x_{n}+x_{m}\right) \in E,\left\|x_{n}+x_{m}\right\|^{2} \geq 4 d^{2}$. If $x$ and $y$ are replaced by $x_{n}$ and $x_{m}$ in (1), the right side of (1) tends to $4 d^{2}$. Hence

(1) implies that $\left\{x_{n}\right\}$ is a Cauchy sequence in $H$, which therefore converges to some $x \in E$, with $\|x\|=d$.

If $y \in E$ and $\|y\|=d$, the sequence $\{x, y, x, y, \ldots\}$ must converge, as we just saw. Hence $y=x$.

12.4 Theorem If $M$ is a closed subspace of $H$, then

$$
H=M \oplus M^{\perp}
$$

The conclusion is, more explicitly, that $M$ and $M^{\perp}$ are closed subspaces of $H$ whose intersection is $\{0\}$ and whose sum is $\bar{H}$. The space $\bar{M}^{\perp}$ is calied the orthogonal complement of $M$.

PROOF If $E \subset H$, the linearity of $(x, y)$ as a function of $x$ shows that $E^{\perp}$ is a subspace of $H$, and the Schwarz inequality (1) of Theorem 12.2 implies then that $E^{\perp}$ is closed.

If $x \in M$ and $x \in M^{\perp}$, then $(x, x)=0$; hence $x=0$. Thus $M \cap M^{\perp}=\{0\}$.

If $x \in H$, appiy Theorem 12.3 to the set $x-M$ to conclude that there exists $x_{1} \in M$ that minimizes $\left\|x-x_{1}\right\|$. Put $x_{2}=x-x_{1}$. Then $\left\|x_{2}\right\| \leq\left\|x_{2}+y\right\|$ for all $y \in M$. Hence $x_{2} \in M^{\perp}$, by Theorem 12.2. Since $x=x_{1}+x_{2}$, we have shown that $M+M^{\perp}=H$.

Corollary If $M$ is a closed subspace of $H$, then

$$
\left(\bar{M}^{\perp}\right)^{\perp}=\bar{M}
$$

PROOF The inclusion $M \subset\left(M^{\perp}\right)^{\perp}$ is obvious. Since

$$
M \oplus M^{\perp}=H=M^{\perp} \oplus\left(M^{\perp}\right)^{\perp}
$$

$M$ cannot be a proper subspace of $\left(M^{\perp}\right)^{\perp}$.

We now describe the dual space $H^{*}$ of $H$.

12.5 Theorem There is a conjugate-linear isometry $y \rightarrow \Lambda$ of $H$ onto $H^{*}$, given by

$$
\Lambda x=(x, y) \quad(x \in H)
$$

PROOF If $y \in H$ and $\Lambda$ is defined by (1), the Schwarz inequality (1) of Theorem 12.2 shows that $\Lambda \in H^{*}$ and that $\|\Lambda\| \leq\|y\|$. Since

$$
\|y\|^{2}=(y, y)=\Lambda y \leq\|\Lambda\|\|y\|,
$$

it follows that $\|\Lambda\|=\|y\|$.

It remains to be shown that every $\Lambda \in H^{*}$ has the form (1).

If $\Lambda=0$, take $y=0$. If $\Lambda \neq 0$, let $\mathscr{N}(\Lambda)$. be the null space of $\Lambda$. By Theorem 12.4 there exists $z \in \mathscr{N}(\Lambda)^{\perp}, z \neq 0$. Since

$$
(\Lambda x) z-(\Lambda z) x \in \mathscr{N}(\Lambda) \quad(x \in H)
$$

it follows that $(\Lambda x)(z, z)-(\Lambda z)(x, z)=0$. Hence (1) holds with $y=(z, z)^{-1}(\overline{\Lambda z}) z$.

12.6 Theorem If $\left\{x_{n}\right\}$ is a sequence of pairwise orthogonal vectors in $H$, then each of the following three statements implies the other two.

(a) $\sum_{n=1}^{\infty} x_{n}$ converges, in the norm topology of $H$.

(b) $\sum_{n=1}^{\infty}\left\|x_{n}\right\|^{2}<\infty$

(c) $\sum_{n=1}^{\infty}\left(x_{n}, y\right)$ converges, for every $y \in H$.

Thus strong convergence (a) and weak convergence $(c)$ are equivalent for series of orthogonal vectors.

PROOF Since $\left(x_{i}, x_{j}\right)=0$ if $i \neq j$, the equality

$$
\left\|x_{n}+\cdots+x_{m}\right\|^{2}=\left\|x_{n}\right\|^{2}+\cdots+\left\|x_{m}\right\|^{2}
$$

holds whenever $n \leq m$. Hence (b) implies that the partial sums of $\sum x_{n}$ form a Cauchy sequence in $H$. Since $H$ is complete, $(b)$ implies $(a)$. The Schwarz inequality shows that $(a)$ implies $(c)$. Finally, assume that $(c)$ holds. Define $\Lambda_{n} \in H^{*}$ by

$$
\Lambda_{n} y=\sum_{i=1}^{n}\left(y, x_{i}\right) \quad(y \in H, n=1,2,3, \ldots)
$$

By $(c),\left\{\Lambda_{n} y\right\}$ converges for every $y \in H$; hence $\left\{\left\|\Lambda_{n}\right\|\right\}$ is bounded, by the BanachSteinhaus theorem. But

$$
\left\|\Lambda_{n}\right\|=\left\|x_{1}+\cdots+x_{n}\right\|=\left\{\left\|x_{1}\right\|^{2}+\cdots+\left\|x_{n}\right\|^{2}\right\}^{1 / 2}
$$

Hence $(c)$ implies $(b)$.

\section{Bounded Operators}
In conformity with notations used earlier, $\mathscr{B}(H)$ will now denote the Banach algebra of all bounded linear operators $T$ on a Hilbert space $H \neq\{0\}$, normed by

$$
\|T\|=\sup \{\|T x\|: x \in H,\|x\| \leq 1\} .
$$

We shail see that $\mathscr{\mathscr { B }}(H)$ has an involution which makes it into a $\bar{B}^{*}$-algebra.

We begin with a simple but useful uniqueness theorem.

12.7 Theorem If $T \in \mathscr{B}(H)$ and if $(T x, x)=0$ for every $x \in H$, then $T=0$. PROOF Since $(T(x+y), x+y)=0$, we see that

$$
(T x, y)+(T y, x)=0 \quad(x \in H, y \in H)
$$

If $y$ is replaced by $i y$ in (1), the result is

$$
-i(T x, y)+i(T y, x)=0 \quad(x \in H, y \in H)
$$

Multiply (2) by $i$ and add to (1), to obtain

$$
(T x, y)=0 \quad(x \in H, y \in H)
$$

With $y=T x$, (3) gives $\|T x\|^{2}=0$. Hence $T x=0$.

Corollary If $S \in \mathscr{B}(H), T \in \mathscr{B}(H)$, and

$$
(S x, x)=(T x, x)
$$

for every $x \in H$, then $S=T$.

PROOF Apply the theorem to $S-T$. Note that Theorem 12.7 would fail if the scalar field were $R$. To see this, consider rotations in $R^{2}$.

12.8 Theorem Iff: $H \times H \rightarrow \complement$ is sesquilinear and bounded, in the sense that

$$
M=\sup \{|f(x, y)|:\|x\|=\|y\|=1\}<\infty
$$

then there exists a unique $S \in \mathscr{B}(H)$ that satisfies

$$
f(x, y)=(x, S y) \quad(x \in H, y \in H)
$$

Moreover, $\|S\|=M$.

PROOF Since $|f(x, y)| \leq M\|x\|\|y\|$, the mapping

$$
x \rightarrow f(x, y)
$$

is, for each $y \in H$, a bounded linear functional on $H$, of norm at most $M\|y\|$. It now follows from Theorem 12.5 that to each $y \in H$ corresponds a unique element $S y \in H$ such that (2) holds; also, $\|S y\| \leq M\|y\|$. It is clear that $S: H \rightarrow H$ is additive. If $\alpha \in \mathscr{C}$, then

$$
(x, S(\alpha y))=f(x, \alpha y)=\bar{\alpha} f(x, y)=\bar{\alpha}(x, S y)=(x, \alpha S y)
$$

for all $x$ and $y$ in $H$. If follows that $S$ is linear. Hence $S \in \mathscr{B}(H)$, and $\|S\| \leq M$.

But we also have

$$
|f(x, y)|=|(x, S y)| \leq\|x\|\|S y\| \leq\|x\|\|S\|\|y\|,
$$

which gives the opposite inequality $M \leq\|S\|$.

12.9 Adjoints If $T \in \mathscr{B}(H)$, then $(T x, y)$ is linear in $x$, conjugate-linear in $y$, and bounded. Theorem 12.8 shows therefore that there exists a unique $T^{*} \in \mathscr{B}(H)$ for which

$$
(T x, y)=\left(x, T^{*} y\right) \quad(x \in H, y \in H)
$$

and also that

$$
\left\|T^{*}\right\|=\|T\|
$$

We claim that $T \rightarrow T^{*}$ is an involution on $\mathscr{B}(H)$, that is, that the following four properties hold:

$$
\begin{aligned}
(T+S)^{*} & =T^{*}+S^{*} \\
(\alpha T)^{*} & =\bar{\alpha} T^{*} \\
(S T)^{*} & =T^{*} S^{*} \\
T^{*} & =T .
\end{aligned}
$$

Of these, (3) is obvious. The computations

$$
\begin{aligned}
(\alpha T x, y) & =\alpha(T x, y)=\alpha\left(x, T^{*} y\right)=\left(x, \bar{\alpha} T^{*} y\right), \\
(S T x, y) & =\left(T x, S^{*} y\right)=\left(x, T^{*} S^{*} y\right) \\
(T x, y) & =\overline{\left(T^{*} y, x\right)}=\overline{\left(y, T^{* *} x\right)}=\left(T^{* *} x, y\right)
\end{aligned}
$$

give (4), (5), and (6). Since

$$
\|T x\|^{2}=(T x, T x)=\left(T^{*} T x, x\right) \leq\left\|T^{*} T\right\|\|x\|^{2}
$$

for every $x \in H$, we have $\|T\|^{2} \leq\left\|T^{*} T\right\|$. On the other hand, (2) gives

$$
\left\|T^{*} T\right\| \leq\left\|T^{*}\right\|\|T\|=\|T\|^{2}
$$

Hence the equality

$$
\left\|T^{*} T\right\|=\|T\|^{2}
$$

holds for every $T \in \mathscr{B}(H)$.

We have thus proved that $\mathscr{B}(H)$ is a $B^{*}$-algebra, relative to the involution $T \rightarrow T^{*}$ defined by (1).

Note: In the preceding setting, $T^{*}$ is sometimes called the Hilbert space adjoint of $T$, to distinguish it from the Banach space adjoint that was discussed in Chapter 4. The only difference between the two is that in the Hilbert space setting $T \rightarrow T^{*}$ is conjugate-linear instead of linear. This is due to the conjugate-linear nature of the isometry described in Theorem 12.5. If $T^{*}$ were regarded as an operator on $H^{*}$ rather than on $H$, we would be exactly in the situation of Chapter 4 .

12.10 Theorem If $T \in \mathscr{B}(H)$, then

$$
\mathscr{N}\left(T^{*}\right)=\mathscr{R}(T)^{\perp} \quad \text { and } \quad \mathscr{N}(T)=\mathscr{R}\left(T^{*}\right)^{\perp}
$$

We recall that $\mathscr{N}(T)$ and $\mathscr{R}(T)$ denote the null space and range of $T$, respectively. PROOF Each of the following four statements is clearly equivalent to the one that follows and/or precedes it.

$$
\begin{aligned}
T^{*} y & =0 \\
\left(x, T^{*} y\right) & =0 \text { for every } x \in H . \\
(T x, y) & =0 \text { for every } x \in H . \\
y & \in \mathscr{R}(T)^{\perp}
\end{aligned}
$$

Thus $\mathscr{N}\left(T^{*}\right)=\mathscr{R}(T)^{\perp}$. Since $T^{* *}=T$, the second assertion follows from the first if $T$ is replaced by $T^{*}$.

12.11 Definition An operator $T \in \mathscr{B}(H)$ is said to be

(a) normal if $T T^{*}=T^{*} T$,

(b) self-adjoint (or hermitian) if $T^{*}=T$,

(c) unitary if $T^{*} T=I=T T^{*}$, where $I$ is the identity operator on $H$,

(d) a projection if $T^{2}=T$.

It is clear that self-adjoint operators and unitary operators are normal. Most of the theorems obtained in this chapter will be about normal operators.

12.12 Theorem Suppose $T \in \mathscr{B}(H)$.

(a) $T$ is normal if and only if $\|T x\|=\left\|T^{*} x\right\|$ for every $x \in H$.

(b) If $T$ is normal, then $\mathscr{N}(T)=\mathscr{N}\left(T^{*}\right)=\mathscr{R}(T)^{\perp}$.

(c) If $T$ is normal and $T x=\alpha x$ for some $x \in H$ and $\alpha \in \mathscr{C}$, then $T^{*} x=\bar{\alpha} x$.

(d) If $T$ is normal and if $\alpha$ and $\beta$ are distinct eigenvalues of $T$, then the corresponding eigenspaces are orthogonal to each other.

PROOF To see $(a)$, combine the equalities

$$
\begin{aligned}
\|T x\|^{2} & =(T x, T x)=\left(T^{*} T x, x\right) \\
\left\|T^{*} x\right\|^{2} & =\left(T^{*} x, T^{*} x\right)=\left(T T^{*} x, x\right)
\end{aligned}
$$

with the corollary to Theorem 12.7. Obviously, $(b)$ follows from $(a)$ and Theorem 12.10. If $(b)$ is applied to $T-\alpha I$ in place of $T,(c)$ is obtained. Finally, if $T x=\alpha x$ and $T y=\beta y$, an application of $(c)$ gives

$$
\alpha(x, y)=(\alpha x, y)=(T x, y)=\left(x, T^{*} y\right)=(x, \bar{\beta} y)=\beta(x, y)
$$

Since $\alpha \neq \beta$, we conclude that $x \perp y$.

12.13 Theorem, If $U \in \mathscr{B}(H)$, the following three statements are equivalent.

(a) $U$ is unitary.

(b) $\mathscr{R}(U)=H$ and $(U x, U y)=(x, y)$ for all $x \in H, y \in H$.

(c) $\overline{\mathscr{R}}(U)=H$ and $\|U x\|=\|x\|$ for every $x \in H$.

PROOF If $U$ is unitary, then $\mathscr{R}(U)=H$ because $U U^{*}=I$. Also, $U^{*} U=I$, so that

$$
(U x, U y)=\left(x, U^{*} U y\right)=(x, y) .
$$

Thus $(a)$ implies $(b)$. It is obvious that $(b)$ implies $(c)$. If $(c)$ holds, then

$$
\left(U^{*} U x, x\right)=(U x, U x)=\|\overline{U x}\|^{2}=\|x\|^{2}=(x, x)
$$

for every $x \in H$, so that $U^{*} U=I$. But (c) implies also that $U$ is a linear isometry of $H$ onto $H$, so that $U$ is invertible in $\mathscr{B}(H)$. Since $U^{*} U=I, U^{-1}=U^{*}$, and therefore $U$ is unitary.

Note: The equivalence of $(a)$ and $(b)$ shows that the unitary operators are precisely those linear isomorphisms of $H$ that also preserve the inner product. They are therefore the Hilbert space automorphisms.

The equivalence of $(b)$ and $(c)$ is also a corollary of Exercise 2.

12.14 Theorem Each of the following four properties of a projection $P \in \mathscr{B}(H)$ implies the other three:

(a) $P$ is self-adjoint.

(b) $P$ is normal.

(c) $\mathscr{R}(P)=\mathscr{N}(P)^{\perp}$.

(d) $(P x, x)=\|P x\|^{2}$ for every $x \in H$.

Property $(c)$ is usually expressed by saying that $P$ is an orthogonal projection.

PROOF It is trivial that $(a)$ implies $(b)$. Statement $(b)$ of Theorem 12.12 shows that $\mathscr{N}(P)=\mathscr{R}(P)^{\perp}$ if $P$ is normal; since $P$ is a projection, $\mathscr{R}(P)=\mathscr{N}(I-P)$, so that $\mathscr{R}(P)$ is closed. It now follows from the corollary to Theorem 12.4 that $(b)$ implies $(c)$.

If (c) holds, every $x \in H$ has the form $x=y+z$, with $y \perp z, P y=0$, $P z=z$. Hence $P x=z$, and $(P x, x)=(z, z)$. This proves $(d)$.

Finally, assume $(d)$ holds. Then

$$
\|P x\|^{2}=(P x, x)=\left(x, P^{*} x\right)=\left(P^{*} x, x\right)
$$

The last equality holds because $\|P x\|^{2}$ is real and $\left(x, P^{*} x\right)=\|P x\|^{2}$. Thus $(P x, x)=\left(P^{*} x, x\right)$, for every $x \in H$, so that $P=P^{*}$, by Theorem 12.7. Hence (d) implies $(a)$.

12.15 Theorem Suppose $S \in \mathscr{B}(H)$, and $S$ is self-adjoint. Then $S T=0$ if and only if $\mathscr{R}(S) \perp \mathscr{R}(T)$.

PROOF $(S x, T y)=(x, S T y)$.

This result will be most frequently used when both $S$ and $T$ are orthogonal projections.

\section{A Commutativity Theorem}
Let $x$ and $y$ be commuting elements in some Banach algebra with an involution. It is then obvious that $x^{*}$ and $y^{*}$ commute, simply because $x^{*} y^{*}=(y x)^{*}$. Does it follow that $x$ commutes with $y^{*}$ ? Of course, the answer is negative whenever $x$ is not normal and $y=x$. But it can be negative even when both $x$ and $y$ are normal (Exercise 28). It is therefore an interesting fact that the answer is affirmative (if $x$ is normal) in $\mathscr{B}(H)$, relative to the involution furnished by the Hilbert space adjoint:

If $N \in \mathscr{B}(H)$ is normal, if $T \in \mathscr{B}(H)$, and if $N T=T N$, then $N^{*} T=T N^{*}$.

In fact, a more general result is true:

12.16 Theorem (Fuglede-Putnam-Rosenblum) Assume that $M, N, T \in \mathscr{B}(H)$, $M$ and $N$ are normal, and

$$
M T=T N .
$$

Then $M^{*} T=T N^{*}$.

Proof Suppose first that $S \in \mathscr{B}(H)$. Put $V=S-S^{*}$, and define

$$
Q=\exp (V)=\sum_{n=0}^{\infty}\left(\frac{1}{n !}\right) V^{n}
$$

Then $V^{*}=-V$, and therefore

$$
Q^{*}=\exp \left(V^{*}\right)=\exp (-V)=Q^{-1} .
$$

Hence $Q$ is unitary. The consequence we need is that

$$
\left\|\exp \left(S-S^{*}\right)\right\|=1 \quad \text { for every } S \in \mathscr{B}(H)
$$

or

If (1) holds, then $M^{k} T=T N^{k}$ for $k=1,2,3, \ldots$, by induction. Hence

$$
\exp (M) T=T \exp (N)
$$

$$
T=\exp (-M) T \exp (N)
$$

Put $U_{1}=\exp \left(M^{*}-M\right), U_{2}=\exp \left(N-N^{*}\right)$. Since $M$ and $N$ are normal, it follows from (6) that

$$
\exp \left(M^{*}\right) T \exp \left(-N^{*}\right)=U_{1} T U_{2}
$$

By (4), $\left\|U_{\|}\right\|=\left\|U_{2}\right\|=1$, so that (7) implies

We now define

$$
\left\|\exp \left(M^{*}\right) T \exp \left(-N^{*}\right)\right\| \leq\|T\|
$$

$$
f(\lambda)=\exp \left(\lambda M^{*}\right) T \exp \left(-\lambda N^{*}\right) . \quad(\lambda \in \mathscr{C})
$$

The hypotheses of the theorem hold with $\bar{\lambda} M$ and $\bar{\lambda} N$ in place of $M$ and $N$. Therefore (8) implies that $\|f(\lambda)\| \leq\|T\|$ for every $\lambda \in \mathscr{C}$. Thus $f$ is a bounded entire $\mathscr{B}(H)$-valued function. By Liouville's theorem 3.32, $f(\lambda)=f(0)=T$, for every $\lambda \in \mathscr{C}$. Hence (9) becomes

$$
\exp \left(\lambda M^{*}\right) T=T \exp \left(\lambda N^{*}\right) \quad(\lambda \in \mathscr{C})
$$

If we equate the coefficients of $\lambda$ in (10), we obtain $M^{*} T=T N^{*}$.

Remark Inspection of this proof shows that it uses no properties of $\mathscr{B}(H)$ which are not shared by every $B^{*}$-algebra. This observation does not lead to a generalization of the theorem, however, because of Theorem 12.41.

\section{Resolutions of the Identity}
12.17 Definition Let $\mathfrak{M}$ be a $\sigma$-algebra in a set $\Omega$, and let $H$ be a Hilbert space. In this setting, a resolution of the identity (on $\mathfrak{M}$ ) is a mapping

$$
E: \mathfrak{M} \rightarrow \mathscr{B}(H)
$$

with the following properties:

(a) $E(\varnothing)=0, E(\Omega)=I$.

(b) Each $E(\omega)$ is a self-adjoint projection.

(c) $E\left(\omega^{\prime} \cap \omega^{\prime \prime}\right)=E\left(\omega^{\prime}\right) E\left(\omega^{\prime \prime}\right)$.

(d) If $\omega^{\prime} \cap \omega^{\prime \prime}=\varnothing$, then $E\left(\omega^{\prime} \cup \omega^{\prime \prime}\right)=E\left(\omega^{\prime}\right)+E\left(\omega^{\prime \prime}\right)$.

(e) For every $x \in H$ and $y \in H$, the set function $E_{x, y}$ defined by

$$
E_{x, y}(\omega)=(E(\omega) x, y)
$$

is a complex measure on $\mathfrak{M}$.

When $\mathfrak{M}$ is the $\sigma$-algebra of all Borel sets on a compact or locally compact Hausdorff space, it is customary to add another requirement to $(e)$ : Each $E_{x, y}$ should be a regular Borel measure. (This is automatically satisfied on compact metric spaces, for instance. See [23].)

Here are some immediate consequences of these properties.

Since each $E(\omega)$ is a self-adjoint projection, we have

$$
E_{x, x}(\omega)=(E(\omega) x, x)=\|E(\omega) x\|^{2} \quad(x \in H)
$$

so that each $E_{x, x}$ is a positive measure on $\mathfrak{M}$ whose total variation is

$$
\left\|E_{x, x}\right\|=E_{x, x}(\Omega)=\|x\|^{2} .
$$

By $(c)$, any two of the projections $E(\omega)$ commute with each other.

If $\omega^{\prime} \cap \omega^{\prime \prime}=\varnothing,(a)$ and $(c)$ show that the ranges of $E\left(\omega^{\prime}\right)$ and $E\left(\omega^{\prime \prime}\right)$ are orthogonal to each other (Theorem 12.15).

By $(d), E$ is finitely additive. The question arises whether $E$ is countably additive, i.e., whether the series

$$
\sum_{n=1}^{\infty} E\left(\omega_{n}\right)
$$

converges, in the norm topology of $\mathscr{B}(H)$, to $E(\omega)$, whenever $\omega$ is the union of the disjoint sets $\omega_{n} \in \mathfrak{M}$. Since the norm of any projection is either 0 or at least 1 , the partial sums of the scrics (3) cannot form a Cauchy sequence, unless all but finitely many of the $E\left(\omega_{n}\right)$ are 0 . Thus $E$ is not countably additive, except in some trivial situations.

However, let $\left\{\omega_{n}\right\}$ be as above, and fix $x \in H$. Since $E\left(\omega_{n}\right) E\left(\omega_{m}\right)=0$ when $n \neq m$, the vectors $E\left(\omega_{n}\right) x$ and $E\left(\omega_{m}\right) x$ are orthogonal to each other (Theorem 12.15). By $(e)$,

$$
\sum_{n=1}^{\infty}\left(E\left(\omega_{n}\right) x, y\right)=(E(\omega) x, y)
$$

for every $y \in H$. It now follows from Theorem 12.6 that

$$
\sum_{n=1}^{\infty} E\left(\omega_{n}\right) x=E(\omega) x
$$

The series (5) converges in the norm topology of $H$. We summarize the result just proved:

12.18 Proposition If $E$ is a resolution of the identity, and if $x \in H$, then

$$
\omega \rightarrow E(\omega) x
$$

is a countably additive $H$-valued measure on $\mathfrak{M}$.

Moreover, sets of measure zero can be handled in the usual way:

12.19 Proposition Suppose $E$ is a resolution of the identity. If $\omega_{n} \in \mathfrak{M}$ and $E\left(\omega_{n}\right)=0$ for $n=1,2,3, \ldots$, and if $\omega=\bigcup_{n=1}^{\infty} \omega_{n}$, then $E(\omega)=0$.

PROOF Since $E\left(\omega_{n}\right)=0, E_{x, x}\left(\omega_{n}\right)=0$ for every $x \in H$. Since $\mu_{x, x}$ is countably additive, it follows that $E_{x, x}(\omega)=0$. But $\|E(\omega) x\|^{2}=E_{x, x}(\omega)$. Hence $E(\omega)=0$.

12.20 The algebra $L^{\infty}(E)$ Let $E$ be a resolution of the identity on $\mathfrak{M}$, as above. Let $f$ be a complex $\mathfrak{M}$-measurable function on $\Omega$. There is a countable collection $\left\{D_{i}\right\}$ of open discs which forms a base for the topology of $\mathscr{C}$. Let $V$ be the union of those $D_{i}$ for which $E\left(f^{-1}\left(D_{i}\right)\right)=0$. By Proposition 12.19, $E\left(f^{-1}(V)\right)=0$. Also, $V$ is the largest open subset of $\mathscr{C}$ with this property.

The essential range of $f$ is, by definition, the complement of $V$. It is the smallest closed subset of $\mathscr{C}$ that contains $f(p)$ for almost all $p \in \Omega$, that is, for all $p \in \Omega$ except those that lie in some set $\omega \in \mathfrak{M}$ with $E(\omega)=0$.

We say that $f$ is essentially bounded if its essential range is bounded, hence compact. In that case, the largest value of $|\lambda|$, as $\lambda$ runs through the essential range of $f$, is called the essential supremum $\|f\|_{\infty}$ of $f$.

Let $B$ be the algebra of all bounded complex $\mathfrak{M}$-measurable functions on $\Omega$; with the norm

$$
\|f\|=\sup \{|f(p)|: p \in \Omega\}
$$

one sees easily that $B$ is a Banach algebra and that

$$
N=\left\{f \in B:\|f\|_{\infty}=0\right\}
$$

is an ideal of $B$ which is closed, by Proposition 12.19. Hence $B / N$ is a Banach algebra, which we denote (in the usual manner) by $L^{\infty}(E)$.

The norm of any coset $[f]=f+N$ of $L^{\infty}(E)$ is then equal to $\|f\|_{\infty}$, and its spectrum $\sigma([f])$ is the essential range of $f$. As is usually done in measure theory, the distinction between $f$ and its equivalence class $[f]$ will be ignored.

12.21 Theorem If $E$ is a resolution of the identity, as above, then the formula

$$
(\Psi(f) x, y)=\int_{\Omega} f d E_{x, y} \quad(x \in H, y \in H)
$$

defines an isometric isomorphism $\Psi$ of the Banach algebra $L^{\infty}(E)$ onto a closed normal subalgebra A of $\mathscr{B}(H)$. This isomorphism also satisfies

$$
\Psi(f)=\Psi(f)^{*} \quad\left(f \in L^{\infty}(E)\right)
$$

and

(3)

$$
\|\Psi(f) x\|^{2}=\int_{\Omega}|f|^{2} d E_{x, x} \quad\left(x \in H, f \in L^{\infty}(E)\right)
$$

Moreover, an operator $Q \in \mathscr{B}(H)$ commutes with every $E(\omega)$ if and only if $Q$ commutes with every $\Psi(f)$.

Formula (1) will sometimes be abbreviated to

$$
\Psi(f)=\int_{\Omega} f d E
$$

We recall that a normal subalgebra $A$ of $\mathscr{B}(H)$ is a commutative one which has the property that $T^{*} \in A$ whenever $T \in A$; see Definition 11.24.

PROOF To begin with, let $\left\{\omega_{1}, \ldots, \omega_{n}\right\}$ be a partition of $\Omega$, with $\omega_{i} \in \mathfrak{M}$, and let $s$ be a simple function, such that $s=\alpha_{i}$ on $\omega_{i}$. Define $\Psi(s) \in \mathscr{B}(H)$ by

$$
\Psi(s)=\sum_{i=1}^{n} \alpha_{i} E\left(\omega_{i}\right)
$$

Since each $E\left(\omega_{i}\right)$ is self-adjoint,

$$
\Psi(s)^{*}=\sum_{i=1}^{n} \bar{\alpha}_{i} E\left(\omega_{i}\right)=\Psi(\bar{s})
$$

If $\left\{\omega_{1}^{\prime}, \ldots, \omega_{m}^{\prime}\right\}$ is another partition of this kind, and if $t=\beta_{j}$ on $\omega_{j}^{\prime}$, then

$$
\Psi(s) \Psi(t)=\sum_{i, j} \alpha_{i} \beta_{i} E\left(\omega_{i}\right) E\left(\omega_{j}^{\prime}\right)=\sum_{i, j} \alpha_{i} \beta_{j} E\left(\omega_{i} \cap \omega_{j}^{\prime}\right)
$$

Since $s t$ is the simple function that equals $\alpha_{i} \beta_{j}$ on $\omega_{i} \cap \omega_{j}^{\prime}$, it follows that

$$
\Psi(s) \Psi(t)=\Psi(s t)
$$

An entirely analogous argument shows that

$$
\Psi(\alpha s+\beta t)=\alpha \Psi(s)+\beta \Psi(t)
$$

If $x \in H$ and $y \in H$, (5) leads to

$$
(\mathrm{Y}(s) x, y)=\sum_{i=1}^{n} \alpha_{i}\left(E\left(\omega_{i}\right) x, y\right)=\sum_{i=1}^{n} \alpha_{i} E_{x, y}\left(\omega_{i}\right)=\int_{\Omega} s d E_{x, y} .
$$

By (6) and (7),

$$
\Psi(s)^{*} \Psi(s)=\Psi(\bar{s}) \Psi(s)=\Psi(\bar{s} s)=\Psi\left(|s|^{2}\right)
$$

Hence (9) yields

$$
\|\Psi(s) x\|^{2}=\left(\Psi(s)^{*} \Psi(s) x, x\right)=\left(\Psi\left(|s|^{2}\right) x, x\right)=\int_{\Omega}|s|^{2} d E_{x, x},
$$

so that

$$
\|\Psi(s) x\| \leq\|s\|_{\infty}\|x\|,
$$

by formula (2) of Section 12.17. On the other hand, if $x \in \mathscr{R}\left(E\left(\omega_{j}\right)\right)$, then

$$
\Psi(s) x=\alpha_{j} E\left(\omega_{j}\right) x=\alpha_{j} x
$$

since the projections $E\left(\omega_{i}\right)$ have mutually orthogonal ranges. If $j$ is chosen so that $\left|\alpha_{j}\right|=\|s\|_{\infty}$, it follows from (12) and (13) that

$$
\|\Psi(s)\|=\|s\|_{\infty}
$$

Now suppose $f \in L^{\infty}(E)$. There is a sequence of simple measurable functions $s_{k}$ that converges to $f$ in the norm of $L^{\infty}(E)$. By (14), the corresponding operators $\Psi\left(s_{k}\right)$ form a Cauchy sequence in $\mathscr{B}(H)$ which is therefore normconvergent to an operator that we call $\Psi(f)$; it is easy to see that $\Psi(f)$ does not depend on the particular choice of $\left\{s_{k}\right\}$. Obviously (14) leads to

$$
\|\Psi(f)\|=\|f\|_{\infty} \quad\left[f \in L^{\infty}(E)\right] .
$$

Now (1) follows from (9) (with $s_{k}$ in place of $s$ ), since each $E_{x, y}$ is a finite measure; (2) and (3) follow from (6) and (11); and if bounded measurable functions $f$ and $g$ are approximated, in the norm of $L^{\infty}(E)$, by simple measurable functions $s$ and $t$, we see that (7) and (8) hold with $f$ and $g$ in place of $s$ and $t$.

Thus $\Psi$ is an isometric isomorphism of $L^{\infty}(E)$ into $\mathscr{B}(H)$. Since $L^{\infty}(E)$ is complete, its image $A=\Psi\left(L^{\infty}(E)\right)$ is closed in $\mathscr{B}(H)$, because of (15).

Finally, if $Q$ commutes with every $E(\omega)$, then $Q$ commutes with $\Psi(s)$ whenever $s$ is simple, and therefore the approximation process used above shows that $Q$ commutes with every member of $A$.

IIII

\section{The Spectral Theorem}
The principal assertion of the spectral theorem is that every bounded normal operator $T$ on a Hilbert space induces (in a canonical way) a resolution $E$ of the identity on the Borel subsets of its spectrum $\sigma(T)$ and that $T$ can be reconstructed from $E$ by an integral of the type discussed in Theorem 12.21. A large part of the theory of normal operators depends on this fact.

It should perhaps be stated explicitly that the spectrum $\sigma\left(T^{\circ}\right)$ of an operator $T \in \mathscr{B}(H)$ will always refer to the full algebra $\mathscr{B}(H)$. In other words, $\lambda \in \sigma(T)$ if and only if $T-\lambda I$ has no inverse in $\mathscr{B}(H)$. Sometimes we shall also be concerned with closed subalgebras $A$ of $\mathscr{B}(H)$ which have the additional property that $I \in A$ and $T^{*} \in A$ whenever $T \in A$. (Such algebras are sometimes called *-algebras.) Since $\mathscr{B}(H)$ is a $B^{*}$-algebra, Theorem 11.29 tells us, in this situation, that $\sigma(T)=\sigma_{A}(T)$ for every $T \in A$.

Thus $T$ has the same spectrum relative to all closed *-algebras in $\mathscr{B}(H)$ that contain $T$.

Theorem 12.23 will be obtained as a special case of the following result, which deals with normal algebras of operators rather than with individual ones.

12.22 Theorem If $A$ is a closed normal subalgebra of $\mathscr{B}(H)$ which contains the identity operator $I$, and if $\triangle$ is the maximal ideal space of $A$, then the following assertions are true:

(a) There exists a unique resolution of the identity $E$ on the Borel subsets of $\Delta$, that satisfies

$$
T=\int_{\Delta} \hat{T} d E
$$

for every $T \in A$, where $\hat{T}$ is the Gelfand transform of $T$.

(b) $E(\omega) \neq 0$ for every nonempty open set $\omega \subset \Delta$.

(c) An operator $S \in \mathscr{B}(H)$ commutes with every $T \in A$ if and only if $S$ commutes with every projection $E(\omega)$.

As in Theorem 12.21, formula (1) means that

$$
(T x, y)=\int_{\Delta} \hat{T} d E_{x, y} \quad(x \in H, y \in H, T \in A)
$$

PROOF Since $\mathscr{B}(H)$ is a $B^{*}$-algebra (Section 12.9), our given algebra $A$ is a commutative $B^{*}$-algebra. The Gelfand-Naimark theorem 11.18 asserts therefore that $T \rightarrow \hat{T}$ is an isometric *-isomorphism of $A$ onto $C(\Delta)$.

This leads to an easy proof of the uniqueness of $E$. Suppose $E$ satisfies (2). Since $\hat{T}$ ranges over all of $C(\Delta)$, the assumed regularity of the complex Borel measures $E_{x, y}$ shows that cach $E_{x, y}$ is uniquely determined by (2); this follows from the uniqueness assertion that is part of the Riesz representation theorem ([23], Th. 6.19). Since, by definition

$$
(E(\omega) x, y)=E_{x, y}(\omega)
$$

each projection $E(\omega)$ is also uniquely determined by (2).

This uniqueness proof motivates the following proof of the existence of $E$. If $x \in H$ and $y \in H$, Theorem 11.18 shows that

$$
\hat{T} \rightarrow(T x, y)
$$

is a bounded linear functional on $C(\Delta)$, of norm $\leq\|x\|\|y\|$, since $\|\hat{T}\|_{\infty}=\|T\|$.

The Riesz representation theorem supplies us therefore with unique regular complex Borel measures $\mu_{x, y}$ on $\Delta$, such that

$$
(T x, y)=\int_{\Delta} \hat{T} d \mu_{x, y} \quad(x \in H, y \in H, T \in A)
$$

When $\hat{T}$ is real, $T$ is self-adjoint, so that $(T x, y)$ and $(T y, x)$ are complex conjugates of each other. Hence

$$
\mu_{x, y}=\bar{\mu}_{y, x} \quad(x \in H, y \in H) .
$$

For fixed $T \in A$, the left side of (5) is linear in $x$ and conjugate-linear in $y$. The uniqueness of the measures $\mu_{x, y}$ implies therefore that $\mu_{x, y}(\omega)$ is, for every Borel set $\omega \subset \Delta$, a sesquilinear functional. Since $\left\|\mu_{x, y}\right\| \leq\|x\|\|y\|$, it follows that

$$
\int_{\Delta} f d \mu_{x, y}
$$

is a bounded sesquilinear functional on $H$, for every bounded Borel function $f$ on $\Delta$. By Theorem 12.8 there corresponds to every such $f$ an operator $\Phi(f) \in \mathscr{B}(H)$

$$
(\Phi(f) x, y)=\int_{\Delta} f d \mu_{x, y} \quad(x \in H, y \in H)
$$

Comparison with (5) shows that

$$
\Phi(\hat{T})=T \quad(T \in A)
$$

Thus $\Phi$ is an extension of the mapping $\hat{T} \rightarrow T$ that takes $C(\Delta)$ onto $A$.

If $f$ is real, then (6) shows that $(\Phi(f) x, y)$ is the complex conjugate of $(\Phi(f) y, x)$. This implies that $\Phi(f)$ is self-adjoint.

Our next objective is the equality

$$
\Phi(f g)=\Phi(f) \Phi(g)
$$

for bounded Borel functions $f$ and $g$.

If $S \in A$ and $T \in A$, then $(S T)^{\wedge}=\hat{S} \hat{T}$, and (5) implies

$$
\int_{\Delta} \hat{S} \hat{T} d \mu_{x, y}=(S T x, y)=\int_{\Delta} \hat{S} d \mu_{T x, y}
$$

Since $\hat{A}=C(\Delta)$, it follows that

$$
\widehat{T} d \mu_{x, y}=d \mu_{T x, y}
$$

for every choice of $x, y$, and $T$. The integrals (11) remain therefore equal if $\hat{S}$ is replaced by $f$. Hence

$$
\begin{aligned}
\int_{\Delta} f \hat{T} d \mu_{x, y} & =\int_{\Delta} f d \mu_{T x, y} \\
& =(\Phi(f) T x, y)=(T x, z)=\int_{\Delta} \hat{T} d \mu_{x, z}
\end{aligned}
$$

where $z=\Phi(f)^{*} y$. The same reasoning as above shows that the first and last integrals in (13) remain equal when $\hat{T}$ is replaced by any bounded Borel function g. Consequently,

$$
\begin{aligned}
(\Phi(f g) x, y) & =\int_{\Delta} f g d \mu_{x, y}=\int_{\Delta} g d \mu_{x, z} \\
& =(\Phi(g) x, z)=(\Phi(f) \Phi(g) x, y)
\end{aligned}
$$

which proves (10).

We are ready to define $E$. If $\omega$ is a Borel subset of $\Delta$, let $f$ be the characteristic function of $\omega$, and put $E(\omega)=\Phi(f)$.

By $(10), E\left(\omega \cap \omega^{\prime}\right)=E(\omega) E\left(\omega^{\prime}\right)$. With $\omega^{\prime}=\omega$, this shows that each $E(\omega)$ is a projection. Since $\Phi(f)$ is self-adjoint when $f$ is real, each $E(\omega)$ is self-adjoint. It is clear that $E(\varnothing)=\Phi(0)=0$. That $E(\Delta)=I$ follows from (9). The finite additivity of $E$ is a consequence of (8), as is the relation

$$
(E(\omega) x, y)=\mu_{x, y}(\omega)
$$

Hence $E$ is a resolution of the identity.

The proof of part $(a)$ is now complete, since (2) follows from (5) and (15).

Suppose next that $\omega$ is open and $E(\omega)=0$. If $T \in A$ and $\widehat{T}$ has its support in $\omega$, (1) implies that $T=0$; hence $\hat{T}=0$. Since $\hat{A}=C(\Delta)$, Urysohn's lemma implies now that $\omega=\varnothing$. This proves $(b)$.

To prove (c), choose $S \in \mathscr{B}(H), x \in \mathscr{H}, y \in \dddot{H}$, and put $z=S^{*} y$. For any $T \in A$ and any Borel set $\omega \subset \Delta$ we then have

$$
\begin{aligned}
(S T x, y) & =(T x, z)=\int_{\Delta} \hat{T} d E_{x, z}, \\
(T S x, y) & =\int_{\Delta} \hat{T} d E_{S x, y}, \\
(S E(\omega) x, y) & =(E(\omega) x, z)=E_{x, z}(\omega), \\
(E(\omega) S x, y) & =E_{S x, y}(\omega) .
\end{aligned}
$$

If $S T=T S$ for every $T \in A$, the measures in (16) and (17) are equal, so that $S E(\omega)=E(\omega) S$. The same argument establishes the converse. This completes the proof.

We now specialize this theorem to a single operator.

12.23 Theorem If $T \in \mathscr{B}(H)$ and $T$ is normal, then there exists a unique resolution of the identity $E$ on the Borel subsets of $\sigma(T)$ which satisfies

$$
T=\int_{\sigma(T)} \lambda d E(\lambda)
$$

Furthermore, every projection $E(\omega)$ commutes with every $S \in \mathscr{B}(H)$ which commutes with $T$.

We shall refer to this $E$ as the spectral decomposition of $T$.

Sometimes, it is convenient to think of $E$ as being defined for all Borel sets in $\ell$; to achieve this, put $E(\omega)=0$ if $\omega \cap \sigma(T)=\varnothing$.

PROOF Let $A$ be the smallest closed subalgebra of $\mathscr{B}(H)$ that contains $I, T$, and $T^{*}$. Since $T$ is normal, Theorem 12.22 applies to $A$. By Theorem 11.19 , the maximal ideal space of $A$ can be identified with $\sigma(T)$ in such a way that $\widehat{T}(\lambda)=\lambda$ for every $\lambda \in \sigma(T)$. The existence of $E$ follows now from Theorem 12.22.

On the other hand, if $E$ exists so that (1) holds, Theorem 12.21 shows that

$$
p\left(T, T^{*}\right)=\int_{\sigma(T)} p(\lambda, \bar{\lambda}) d E(\lambda)
$$

where $p$ is any polynomial in two variables (with complex coefficients). By the Stone-Weierstrass theorem, these polynomials are dense in $C(\sigma(T))$. The projections $E(\omega)$ are therefore uniquely determined by the integrals (2), hence by $T$, just as in the uniqueness proof in Theorem 12.22.

If $S T=T S$, then also $S T^{*}=T^{*} S$, by Theorem 12.16; hence $S$ commutes with every member of $A$. By $(c)$ of Theorem 12.22, $S E(\omega)=E(\omega) S$ for every Borel set $\omega \subset \sigma(T)$.

12.24 The symbolic calculus for normal operators If $E$ is the spectral decomposition of a normal operator $T \in \mathscr{B}(H)$, and if $f$ is a bounded Borel function on $\sigma(T)$, it is customary to denote the operator

$$
\Psi(f)=\int_{\sigma(T)} f d E
$$

by $f(T)$.

Using this notation, part of the content of Theorems 12.21 to 12.23 can be summarized as follows:

The mapping $f \rightarrow f(T)$ is a homomorphism of the algebra of all bounded Borel functions on $\sigma(T)$ into $\mathscr{B}(H)$, which carries the function 1 to $I$, which carries the identity function on $\sigma(T)$ to $T$, and which satisfies

$$
\bar{f}(T)=f(T)^{*}
$$

and

$$
\|f(T)\| \leq \sup \{|f(\lambda)|: \lambda \in \sigma(T)\}
$$

If $f \in C(\sigma(T))$, then equality holds in (3).

If $f_{n} \rightarrow f$ uniformly, then $\left\|f_{n}(T)-f(T)\right\| \rightarrow 0$, as $n \rightarrow \infty$.

If $S \in \mathscr{B}(H)$ and $S T=T S$, then $S f(T)=f(T) S$ for every bounded Borel function $f$.

Since the identity function can be uniformly approximated, on $\sigma(T)$, by simple Borel functions, it follows that $T$ is a limit, in the norm topology of $\mathscr{B}(H)$, of finite linear combinations of projections $E(\omega)$.

The following proof contains our first application of this symbolic calculus.

12.25 Theorem If $T \in \mathscr{B}(H)$ is normal, then

$$
\|T\|=\sup \{|(T x, x)|: x \in H,\|x\| \leq 1\}
$$

PROof Choose $\varepsilon>0$. It is clearly enough to show that

$$
\left|\left(T x_{0}, x_{0}\right)\right|>\|T\|-\varepsilon
$$

for some $x_{0} \in H$ with $\left\|x_{0}\right\|=1$.

Since $\|T\|=\|\hat{T}\|_{\infty}=\rho(T)$ (Theorem 11.18), there exists $\lambda_{0} \in \sigma(T)$ such that $\left|\lambda_{0}\right|=\|T\|$. Let $\omega$ be the set of all $\lambda \subset \sigma(T)$ for which $\left|\lambda-\lambda_{0}\right|<\varepsilon$. If $E$ is the spectral decomposition of $T$, then $(b)$ of Theorem 12.22 implies that $E(\omega) \neq 0$. Therefore there exists $x_{0} \in H$ with $\left\|x_{0}\right\|=1$ and $E(\omega) x_{0}=x_{0}$.

Define $f(\lambda)=\lambda-\lambda_{0}$ for $\lambda \in \omega$; put $f(\lambda)=0$ for all other $\lambda \in \sigma(T)$. Then

$$
f(T)=\left(T-\lambda_{0} I\right) E(\omega)
$$

so that

$$
f(T) x_{0}=T x_{0}-\lambda_{0} x_{0} .
$$

Hence

$$
\left|\left(T x_{0}, x_{0}\right)-\lambda_{0}\right|=\left|\left(f(T) x_{0}, x_{0}\right)\right| \leq\|f(T)\| \leq \varepsilon
$$

since $|f(\lambda)|<\varepsilon$ for all $\lambda \in \sigma(T)$. This implies (1), because $\left|\lambda_{0}\right|=\|T\|$.

12.26 Theorem A normal $T \in \mathscr{B}(H)$ is

(a) self-adjoint if and only if $\sigma(T)$ lies in the real axis,

(b) unitary if and only if $\sigma(T)$ lies on the unit circle.

PROOF Choose $A$ as in the proof of Theorem 12.23. Then $\hat{T}(\lambda)=\lambda$ and $\left(T^{*}\right)^{\wedge}(\lambda)=\bar{\lambda}$ on $\sigma(T)$. Hence $T=T^{*}$ if and only if $\lambda=\bar{\lambda}$ on $\sigma(T)$, and $T T^{*}=I$ if and only if $\lambda \bar{\lambda}=1$ on $\sigma(T)$.

12.27 Invariant subspaces A closed subspace $M$ of $H$ is an invariant subspace of a set $\sum \subset \mathscr{B}(H)$ if every $T \in \sum$ maps $M$ into $M$. For example, every eigenspace of $T$ is an invariant subspace of $T$. When $\operatorname{dim} H<\infty$, the spectral theorem implies that
the eigenspaces of every normal operator $T$ span $H$. [Sketch of proof: The characteristic function of each point in $\sigma(T)$ corresponds to a projection in $H$. The sum of these projections is $E(\sigma(T))=I$.] If $\operatorname{dim} H=\infty$, it can happen that $T$ has no eigenvalues (Exercise 20). But normal operators still have invariant subspaces that are nontrivial (that is, $\neq\{0\}$ and $\neq H$ ).

In fact, let $A$ be a normal algebra, as in Theorem 12.22, and let $E$ be its resolution of the identity, on the Borel subsets of $\Delta$. If $\Delta$ consists of a single point, then $A$ consists of the scalar multiples of $I$, and every subspace of $H$ is invariant under $A$. Suppose that $\Delta=\omega \cup \omega^{\prime}$, where $\omega$ and $\omega^{\prime}$ are nonempty disjoint Borel sets. Let $M$ and $M^{\prime}$ be the ranges of $E(\omega)$ and $E\left(\omega^{\prime}\right)$. Then $T E(\omega)=E(\omega) T$ for every $T \in A$. If $x \in M$, it follows that

$$
T x=T E(\omega) x=E(\omega) T x
$$

so that $T x \in M$. The same. holds for $M^{\prime}$.

Hence $M$ and $M^{\prime}$ are invariant subspaces of $A$.

Moreover, $M^{\prime}=M^{\perp}$, and $H=M \oplus M^{\prime}$.

Decompositions of $\Delta$ into finitely many (or even countably many) disjoint Borel sets induce, in the same manner, decompositions of $H$ into pairwise orthogonal invariant subspaces of $A$.

It is an open problem whether every (nonnormal) $T \in \mathscr{B}(H)$ has a nontrivial invariant subspace if $H$ is an infinite-dimensional separable Hilbert space.

\section{Eigenvalues of Normal Operators}
If $T \in \mathscr{B}(H)$ is normal, its eigenvalues bear a simple relation to its spectral decomposition (Theorem 12.29). This will be derived from the following application of the symbolic calculus:

12.28 Theorem Suppose $T \in \mathscr{B}(H)$ is normal and $E$ is its spectral decomposition. If $f \in C(\sigma(T))$ and if $\omega_{0}=f^{-1}(0)$, then

$$
\mathscr{N}(f(T))=\mathscr{R}\left(E\left(\omega_{0}\right)\right)
$$

PROOF Put $g(\lambda)=1$ on $\omega_{0}, g(\lambda)=0$ at all other points of $\sigma(T)$. Then $f g=0$, so that $f(T) g(T)=0$. Since $g(T)=E\left(\omega_{0}\right)$, it follows that

$$
\mathscr{R}\left(E\left(\omega_{0}\right)\right) \subset \mathscr{N}(f(T))
$$

If $\tilde{\omega}$ is the complement of $\omega_{0}$, relative to $\sigma(T)$, then $\tilde{\omega}$ is the union of disjoint Borel sets $\omega_{n}(n=1,2,3, \ldots)$, each of which has positive distance from the compact set $\omega_{0}$. Define

$$
f_{n}(\lambda)= \begin{cases}1 / f(\lambda) & \text { on } \omega_{n}, \\ 0 & \text { elsewhere on } \sigma(T) .\end{cases}
$$

Each $f_{n}$ is a bounded Borel function on $\sigma(T)$, and

$$
f_{n}(T) f(T)=E\left(\omega_{n}\right) \quad(n=1,2,3, \ldots)
$$

If $f(T) x=0$, it follows that $E\left(\omega_{n}\right) x=0$. The countable additivity of the mapping $\omega \rightarrow E(\omega) x$ (Proposition 12.18) shows therefore that $E(\tilde{\omega}) x=0$. But $E(\tilde{\omega})+E\left(\omega_{0}\right)=I$. Hence $E\left(\omega_{0}\right) x=x$. We have now proved that

$$
\mathscr{N}(f(T)) \subset \mathscr{R}\left(E\left(\omega_{0}\right)\right)
$$

and (1) follows from (2) and (5).

12.29 Theorem Suppose $E$ is the spectral decomposition of a normal $T \in \mathscr{B}(H)$, $\lambda_{0} \in \sigma(T)$, and $E_{0}=E\left(\left\{\lambda_{0}\right\}\right)$. Then

(a) $\mathscr{N}\left(T-\lambda_{0} I\right)=\mathscr{R}\left(E_{0}\right)$

(b) $\lambda_{0}$ is an eigenvalue of $T$ if and only if $E_{0} \neq 0$, and

(c) every isolated point of $\sigma(T)$ is an eigenvalue of $T$.

(d) Moreover, if $\sigma(T)=\left\{\lambda_{1}, \lambda_{2}, \lambda_{3}, \ldots\right\}$ is a countable set, then every $x \in H$ has a unique expansion of the form

$$
x=\sum_{i=1}^{\infty} x_{i}
$$

where $T x_{i}=\lambda_{i} x_{i}$. Also, $x_{i} \perp x_{j}$ whenever $i \neq j$.

Statements $(b)$ and $(c)$ explain the term point spectrum of $T$ for the set of all eigenvalues of $T$.

PROOF Part $(a)$ is an immediate corollary of Theorem 12.28, with $f(\lambda)=\lambda-\lambda_{0}$. It is clear that $(b)$ follows from $(a)$. If $\lambda_{0}$ is an isolated point of $\sigma(T)$, then $\left\{\lambda_{0}\right\}$ is a nonempty open subset of $\sigma(T)$; hence $E_{0} \neq 0$, by $(b)$ of Theorem 12.22. Therefore $(c)$ follows from $(b)$.

To prove $(d)$, put $E_{i}=E\left(\left\{\lambda_{i}\right\}\right), i=1,2,3, \ldots$ At limit points $\lambda_{i}$ of $\sigma(T)$, $E_{i}$ may or may not be 0 . In any case, the projections $E_{i}$ have pairwise orthogonal ranges. The countable additivity of $\omega \rightarrow E(\omega) x$ (Proposition 12.18) shows that

$$
\sum_{i=1}^{\infty} E_{i} x=E(\sigma(T)) x=x \quad(x \in H)
$$

The series converges, in the norm of $H$. This gives the desired representation of, $x$, if $x_{i}=E_{i} x$. The uniqueness follows from the orthogonality of the vectors $x_{i}$, and $T x_{i}=\lambda_{i} x_{i}$ follows from $(a)$.

12.30 Theorem A.normal operator $T \in \mathscr{B}(H)$ is compact if and only if it satisfies the following two conditions:
(a). $\sigma(T)$ has no limit point except possibly 0 .

(b) If $\lambda \neq 0$, then $\operatorname{dim} \mathscr{N}(T-\lambda I)<\infty$.

PROOF For the necessity, see $(d)$ of Theorem 4.18, and Theorem 4.25.

To prove the sufficiency, assume $(a)$ and $(b)$ hold, let $\left\{\lambda_{i}\right\}$ be an enumeration of the nonzero points of $\sigma(T)$ such that $\left|\lambda_{1}\right| \geq\left|\lambda_{2}\right| \geq \cdots$, define $f_{n}(\lambda)=\lambda$ if $\lambda=\lambda_{i}$ and $i \leq n$, and put $f_{n}\left(\lambda_{0}\right)=0$ at the other points of $\sigma(T)$. If $E_{i}=E\left(\left\{\lambda_{i}\right\}\right)$, as in Theorem 12.29, then

$$
f_{n}(T)=\lambda_{1} E_{1}+\cdots+\lambda_{n} E_{n}
$$

Since $\operatorname{dim} \mathscr{R}\left(E_{i}\right)=\operatorname{dim} \mathscr{N}\left(T-\lambda_{i} I\right)<\infty$, each $f_{n}(T)$ is a compact operator. Since $\left|\lambda-f_{n}(\lambda)\right| \leq\left|\lambda_{n}\right|$ for all $\lambda \in \sigma(T)$, we have

$$
\left\|T-f_{n}(T)\right\| \leq\left|\lambda_{n}\right| \rightarrow 0 \quad \text { as } \quad n \rightarrow \infty
$$

It now follows from $(c)$ of Theorem 4.18 that $T$ is compact.

\subsection{Theorem Suppose $T \in \mathscr{B}(H)$ is normal and compact. Then}
(a) $T$ has an eigenvalue $\lambda$, with $|\lambda|=\|T\|$, and

(b) $f(T)$ is compact if $f \in C(\sigma(T))$ and $f(0)=0$.

PROOF Since $T$ is normal, Theorem 11.18 shows that there exists $\lambda \in \sigma(T)$ with $|\lambda|=\|T\|$. If $\|T\|>0$, this $\lambda$ is an isolated point of $\sigma(T)$ (Theorem 12.30), hence an eigenvalue of $T$ (Theorem 12.29). If $\|T\|=0,(a)$ is obvious.

Since $\sigma(T)$ is an at most countable compact set in $\mathbb{C}$, its complement is connected. Mergelyan's theorem (see [23]) shows therefore that there are polynomials $p_{n}$, with $p_{n}(0)=0$, which converge to $f$, uniformly on $\sigma(T)$. The operators $p_{n}(T)$ converge therefore, in the norm of $\mathscr{B}(H)$, to $f(T)$. Since $p_{n}(0)=0$, $(f)$ of Theorem 4.18 shows that each $p_{n}(T)$ is compact. Hence $f(T)$ is compact, by $(c)$ of Theorem 4.18 .

This proof of $(b)$ could also have been based on the classical approximation theorem of Runge rather than on the more difficult one of Mergelyan.

\section{Positive Operators and Square Roots}
\subsection{Theorem Suppose $T \in \mathscr{B}(H)$. Then}
(a) $(T x, x) \geq 0$ for every $x \in H$ if and only if

(b) $T=T^{*}$ and $\sigma(T) \subset[0, \infty)$.

If $T \in \mathscr{B}(H)$ satisfies (a), we call $T$ a positive operator and write $T \geq 0$.

The theorem asserts that this terminology agrees with Definition 11.27.

PROOF In general, $(T x, x)$ and $(x, T x)$ are complex conjugates of each other. But if $(a)$ holds, then $(T x, x)$ is real, so that

$$
\left(x, T^{*} x\right)=(T x, x)=(x, T x)
$$

for every $x \in H$. By Theorem 12.7, $T=T^{*}$, and thus $\sigma(T)$ lies in the real axis (Theorem 12.26). If $\lambda>0,(a)$ implies that

$$
\lambda\|x\|^{2}=(\lambda x, x) \leq((T+\lambda I) x, x) \leq\|(T+\lambda I) x\|\|x\|,
$$

so that

$$
\|(T+\lambda I) x\| \geq \lambda\|x\| .
$$

Hence $T+\lambda I$ is invertible in $\mathscr{B}(H)$, and $-\lambda$ is not in $\sigma(T)$. It follows that $(a)$ implies $(b)$.

Assume now that $(b)$ holds, and let $E$ be the spectral decomposition of $T$, so that

$$
(T x, x)=\int_{\sigma(T)} \lambda d E_{x, x}(\lambda) \quad(x \in H) .
$$

Since each $E_{x, x}$ is a positive measure, and since $\lambda \geq 0$ on $\sigma(T)$, we have $(T x, x) \geq 0$. Thus $(b)$ implies $(a)$.

12.33 Theorem Every positive $T \in \mathscr{B}(H)$ has a unique positive square root $S \in \mathscr{B}(H)$. If $T$ is inveritible, so is $S$.

PROOF Let $A$ be any closed normal subalgebra of $\mathscr{B}(H)$ that contains $I$ and $T$, and let $\Delta$ be the maximal ideal space of $A$. By Theorem 11.18, $\hat{A}=C(\Delta)$. Since $T$ satisfies condition $(b)$ of Theorem 12.32, and since $\sigma(T)=\hat{T}(\Delta)$, we see that $\hat{T} \geq 0$. Since every nonnegative continuous function has a unique nonnegative continuous square root, it follows that there is a unique $S \in A$ that satisfies $S^{2}=T$ and $\hat{S} \geq 0$; by Theorem 12.32, $\hat{S} \geq 0$ is equivalent to $S \geq 0$.

In particular, let $A_{0}$ be the smallest of these algebras $A$. Then there exists $S_{0} \in A_{0}$ such that $S_{0}^{2}=T$ and $S_{0} \geq 0$. If $S \in \mathscr{B}(H)$ is any positive square root of $T$, let $A$ be the smallest closed subalgebra of $\mathscr{B}(H)$ that contains $I$ and $S$. Then $T \in A$, since $T=S^{2}$. Hence $A_{0} \subset A$, so that $S_{0} \in A$. The conclusion of the preceding paragraph shows now that $S=S_{0}$.

Finally, if $T$ is invertible, then $S^{-1}=T^{-1} S$, since $S$ and $T$ commute.

12.34 Theorem If $T \in \mathscr{B}(H)$, then the positive square root of $T^{*} T$ is the only positive operator $P \in \mathscr{B}(H)$ that satisfies $\|P x\|=\|T x\|$ for every $x \in H$.

PROOF Note first that

$$
\left(T^{*} T x, x\right)=(T x, T x)=\|T x\|^{2} \geq 0 \quad(x \in H)
$$

so that $T^{*} T \geq 0$. (In the more abstract setting of Theorem 11.28 this was much harder to prove!)

Next, if $P \in \mathscr{B}(H)$ and $P=P^{*}$, then

$$
\left(P^{2} x, x\right)=(P x, P x)=\|P x\|^{2} \quad(x \in H) .
$$

By Theorem 12.7 , it follows that $\|P x\|=\|T x\|$ for every $x \in I$ if and only if $P^{2}=T^{*} T$.

This completes the proof.

The fact that every complex number $\lambda$ can be factored in the form $\lambda=\alpha|\lambda|$, where $|\alpha|=1$, suggests the problem of trying to factor $T \in \mathscr{B}(H)$ in the form $T=U P$, with $U$ unitary and $P \geq 0$. When this is possible, we call $U P$ a polar decomposition of $T$.

Note that $U$, being unitary, is an isometry. Theorem 12.34 shows therefore that $P$ is uniquely determined by $T$.

\subsection{Theorem}
(a) If $T \in \mathscr{B}(H)$ is invertible, then $T$ has a unique polar decomposition $T=U P$.

(b) If $T \in \mathscr{B}(H)$ is normal, then $T$ has a polar decomposition $T=U P$ in which $U$ and $P$ commute with each other and with $T$.

PROOF (a) If $T$ is invertible, so are $T^{*}$ and $T^{*} T$, and Theorem 12.33 shows that the positive square root $P$ of $T^{*} T$ is also invertible. Put $U=T P^{-1}$. Then $U$ is invertible, and

$$
U^{*} U=P^{-1} T^{*} T P^{-1}=P^{-1} P^{2} P^{-1}=I,
$$

so that $U$ is unitary. Since $P$ is invertible, it is obvious that $T P^{-1}$ is the only possible choice for $U$.

(b) Put $p(\lambda)=|\lambda|, u(\lambda)=\lambda /|\lambda|$ if $\lambda \neq 0, u(0)=1$. Then $p$ and $u$ are bounded Borel functions on $\sigma(T)$. Put $P=p(T), U=u(T)$. Since $p \geq 0$, Theorem 12.32 shows that $P \geq 0$. Since $u \bar{u}=1, U U^{*}=U^{*} U=I$. Since $\lambda=u(\lambda) p(\lambda)$, the relation $T=U P$ follows from the symbolic calculus.

Remark It is not true that every $T \in \mathscr{B}(H)$ has a polar decomposition. (See Exercise 19.) However, if $P$ is the positive square root of $T^{*} T$, then $\|P x\|=$ $\|T x\|$ for every $x \in H$, so that the formula

$$
V P x=T x
$$

defines a linear isometry $V$ of $\mathscr{R}(P)$ onto $\mathscr{R}(T)$, which has a continuous extension to a linear isometry of the closure of $\mathscr{R}(P)$ onto the closure of $\mathscr{R}(T)$.

If there is a linear isometry of $\mathscr{R}(P)^{\perp}$ onto $\mathscr{R}(T)^{\perp}$, then $V$ can be extended to a unitary operator on $H$, and then $T$ has a polar decomposition. This always happens when $\operatorname{dim} H<\infty$, since $\mathscr{R}(P)$ and $\mathscr{R}(T)$ have then the same codimension.

If $V$ is extended to a member of $\mathscr{B}(H)$ by defining $V y=0$ for all $y \in \mathscr{R}(P)^{\perp}$, then $V$ is called a partial isometry.

Every $T \in \mathscr{B}(H)$ thus has a factorization $T=V P$ in which $P$ is positive and $V$ is a partial isometry.

In combination with Theorem 12.16, the polar decomposition leads to an interesting result concerning similarity of normal operators.

12.36 Theorem Suppose $M, N, T \in \mathscr{B}(H), M$ and $N$ are normal, $T$ is invertible, and

$$
M=T N T^{-1}
$$

If $T=U P$ is the polar decomposition of $T$, then

$$
M=U N U^{-1} .
$$

Two operators $M$ and $N$ that satisfy (i) are usualiy called similar. If $U$ is unitary and (2) holds, $M$ and $N$ are said to be unitarily equivalent. The theorem thus asserts that similar normal operators are actually unitarily equivalent.

PROOF By (1), $M T=T N$. Hence $M^{*} T=T N^{*}$, by Theorem 12.16. Consequently,

$$
T^{*} M=\left(M^{*} T\right)^{*}=\left(T N^{*}\right)^{*}=N T^{*} \text {, }
$$

so that

$$
N P^{2}=N T^{*} T=T^{*} M T=T^{*} T N=P^{2} N
$$

since $P^{2}=T^{*} T$. Hence $N$ commutes with $f\left(P^{2}\right)$, for every $f \in C\left(\sigma\left(P^{2}\right)\right)$. (See Section 12.24.) Since $P \geq 0, \sigma\left(P^{2}\right) \subset[0, \infty)$. If $f(\lambda)=\lambda^{1 / 2} \geq 0$ on $\sigma\left(P^{2}\right)$, it follows that $N P=P N$. Hence (1) yields

$$
M=(U P) N(U P)^{-1}=U P N P^{-1} U^{-1}=U N U^{-1}
$$

\section{The Group of Invertible Operators}
Some features of the group of all invertible elements in a Banach algebra $A$ were described at the end of Chapter 10. The following two theorems contain further information about this group, in the special case $A=\mathscr{B}(H)$.

12.37 Theorem The group $G$ of all invertible operators $T \in \mathscr{B}(H)$ is connected, and every $T \in G$ is the product of two exponentials.

$S \in \mathscr{B}(H)$.

Here an exponential is, of course, any operator of the form $\exp (S)$ with

PROOF Let $T=U P$ be the polar decomposition of some $T \in G$. Recall that $U$ is unitary and that $P$ is positive and invertible. Since $\sigma(P) \subset(0, \infty), \log$ is a continuous real function on $\sigma(P)$. It follows from the symbolic calculus that there is a self-adjoint $S \in \mathscr{B}(H)$ such that $P=\exp (S)$. Since $U$ is unitary, $\sigma(U)$ lies on the unit circle, so that there is a real bounded Borel function $f$ on $\sigma(U)$ that satisfies

$$
\exp \{\text { if }(\lambda)\}=\lambda \quad[\lambda \in \sigma(U)]
$$

(Note that there may not exist any continuous $f$ with this property!) Put $Q=$ $f(U)$. Then $Q \in \mathscr{B}(H)$ is self-adjoint, and $U=\exp (i Q)$. Thus

$$
T=U P=\exp (i Q) \exp (S)
$$

From this it follows easily that $G$ is connected, for if $T_{\boldsymbol{r}}$ is defined, for $0 \leq r \leq 1$, by

$$
T_{r}=\exp (\operatorname{ir} Q) \exp (r S)
$$

then $r \rightarrow T_{r}$ is a continuous mapping of the unit interval $[0,1]$ into $G, T_{0}=I$, and $T_{1}=T$. This completes the proof.

It is now natural to ask whether every $T \in G$ is an exponential, rather than merely the product of two exponentials. In other words, is every product of two exponentials an exponential? The answer is affirmative if $\operatorname{dim} H<\infty$; in fact, it is affirmative in every finite-dimensional Banach algebra, as a consequence of Theorem 10.30. But in general the answer is negative, as we shall now see.

12.38 Theorem Let $D$ be a bounded open set in $C$ such that the set

$$
\Omega=\left\{\alpha \in \mathscr{C}: \alpha^{2} \in D\right\}
$$

is connected and such that 0 is not in the closure of $D$. Let $H$ be the space of all holomorphic functions $f$ in $D$ that satisfy

$$
\int_{D}|f|^{2} d m_{2}<\infty
$$

(where $m_{2}$ is Lebesgue measure in the plane), with inner product

$$
(f, g)=\int_{D} f \bar{g} d m_{2}
$$

Then $H$ is a Hilbert space. Define the multiplication operator $M \in \mathscr{B}(H)$ by

$$
(M f)(z)=z f(z) \quad(f \in H, z \in D)
$$

Then $M$ is invertible, but $M$ has no square root in $\mathscr{B}(H)$.

Since every exponential has roots of all orders, it follows that $M$ is not an exponential.

PROOF It is clear that (3) defines an inner product that makes $H$ a unitary space. We show now that $H$ is complete. Let $K$ be a compact subset of $D$, whose distance from the complement of $D$ is $\delta$. If $z \in K$, if $\Delta$ is the open circular disc with radius $\delta$ and center $z$, and if $f(\zeta)=\sum a_{n}(\zeta-z)^{n}$ for $\zeta \in \Delta$, a simple computation shows that

$$
\sum_{n=0}^{\infty}(n+1)^{-1}\left|a_{n}\right|^{2} \delta^{2 n+2}=\frac{1}{\pi} \int_{\Delta}|f|^{2} d m_{2}
$$

Since $f(z)=a_{0}$, it follows that

$$
|f(z)| \leq \pi^{-1 / 2} \delta^{-1}\|f\| \quad(z \in K, f \subset H)
$$

where $\|f\|=(f, f)^{1 / 2}$. Every Cauchy sequence in $H$ converges therefore uniformly on compact subsets of $D$. From this it follows easily that $H$ is complete. Hence $H$ is a Hilbert space.

Since $D$ is bounded, $M \in \mathscr{B}(H)$. Since $1 / z$ is bounded in $D, M^{-1} \in \mathscr{B}(H)$.

Assume now, to reach a contradiction, that $M=Q^{2}$ for some $Q \in \mathscr{B}(H)$.

Fix $\alpha \in \Omega$. Put $\lambda=\alpha^{2}$. Then $\lambda \in D$. Define

$$
M_{\lambda}=M-\lambda I, \quad S=Q-\alpha I, \quad T=Q+\alpha I
$$

so that

$$
S T=M_{\lambda}=T S .
$$

Since we are dealing with holomorphic functions, the formula

$$
\left(M_{\lambda} g\right)(z)=(z-\lambda) g(z) \quad(z \in D, g \in H)
$$

shows that $M_{\lambda}$ is one-to-one and that its range $\mathscr{R}\left(M_{\lambda}\right)$ consists of exactly those $f \in H$ that satisfy $f(\lambda)=0$. Hence (6) shows that $\mathscr{R}\left(M_{\lambda}\right)$ is a closed subspace of $H$, of codimension 1 .

Since $M_{\lambda}$ is one-to-one, the first equation (8) shows that $T$ is one-to-one; the second shows that $S$ is one-to-one. Since $\mathscr{R}\left(M_{\lambda}\right) \neq H, M_{\lambda}$ is not invertible in $\mathscr{B}(H)$. Hence at least one of $S$ and $T$ is not invertible. Suppose $S$ is not invertible. Since $M_{\lambda}=S T, \mathscr{R}\left(M_{\lambda}\right) \subset \mathscr{R}(S)$, so that $\mathscr{R}(S)$ is either $\mathscr{R}\left(M_{\lambda}\right)$ or $H$. In the latter case, the open mapping theorem would imply that $S$ is invertible.

Hence $S$ is a one-to-one mapping of $H$ onto $\mathscr{R}\left(M_{\lambda}\right)$. But the equation $M_{\lambda}=S T$ shows that $S$ maps $\mathscr{R}(T)$ onto $\mathscr{R}\left(M_{\lambda}\right)$. Hence $\mathscr{R}(T)=H$, and another application of the open mapping theorem shows that $T^{-1} \in \mathscr{B}(H)$.

We have now proved that one and only one of the operators $S$ and $T$ is invertible in $\mathscr{B}(H)$. Therefore exactly one of the numbers $\alpha$ and $-\alpha$ lies in $\sigma(Q)$, if $\alpha \in \Omega$. It follows that $\Omega$ is the union of two disjoint congruent sets, $\sigma(Q) \cap \Omega$ and $-\sigma(Q) \cap \Omega$, both of which are closed (relative to $\Omega$ ) since $\sigma(Q)$ is compact. The assumption that $M=Q^{2}$ leads thus to the conclusion that $\Omega$ is not connected, which contradicts the hypothesis.

This completes the proof.

The simplest example of a region $D$ that satisfies the hypothesis of Theorem 12.38 is a circular annulus with center at 0 .

\section{A Characterization of $B^{*}$-algebras}
The fact that every $\mathscr{B}(H)$ is a $B^{*}$-algebra has been exploited throughout this chapter. We shall now establish a converse (Theorem 12.41) which asserts that every $B^{*-}$ algebra (commutative or not) is isometrically *-isomorphic to some closed subalgebra of some $\mathscr{B}(H)$. The proof depends on the existence of a sufficiently large supply of positive functionals.

12.39 Theorem If $A$ is a $B^{*}$-algebra and if $z \in A$, then there exists a positive functional $F$ on $A$ such that

$$
F(e)=1 \quad \text { and } \quad F\left(z z^{*}\right)=\|z\|^{2} \text {. }
$$

PROOF Let $A_{r}$ (the "real part" of $A$ ) be the real vector space that consists of the hermitian elements of $A$, and let $P$ be the set of all $x \in A_{\boldsymbol{r}}$ with $\sigma(x) \subset[0, \infty)$. In the terminology of Deninition 11.27, $x \in \bar{P}$ if and only if $x \geq 0$. By Theorem 11.28, $P$ is a cone: if $x \in P, y \in P$, and $c$ is a positive scalar, then $c x \in P$ and $x+y \in P$. Also, $P$ contains all elements of the form $x x^{*}$, for $x \in A$. To prove the theorem, it is therefore enough to find a real-linear functional $f$ on $A_{r}$ that satisfies (1) and

$$
f(x) \geq 0 \quad \text { for every } x \in P
$$

for we can then define $F(x)=f(u)+i f(v)$ if $x=u+i v$ and $u \in A_{r}, v \in A_{r}$. Since this definition gives $F(i x)=i F(x), F$ is complex-linear, and (2) shows that $F$ is positive. by

Let $M_{0}$ be the subspace of $A_{r}$ generated by $e$ and $z z^{*}$, and define $f_{0}$ on $M_{0}$

$$
f_{0}\left(\alpha e+\beta z z^{*}\right)=\alpha+\beta\left\|z z^{*}\right\| \quad(\alpha, \beta \in R)
$$

Note that $f_{0}$ is well defined on $M_{0}$, even if $e$ and $z z^{*}$ are linearly dependent. By $(a)$ of Theorem $11.28\left\|z z^{*}\right\| \in \sigma\left(z z^{*}\right)$. Hence $\alpha+\beta\left\|z z^{*}\right\|$ lies in $\sigma\left(\alpha e+\beta z z^{*}\right)$. In other words, $f_{0}(x) \in \sigma(x)$ if $x \in M_{0}$, so that $f_{0}(x) \geq 0$ for every $x \in P \cap M_{0}$. Also, $f$ satisfies (1).

Assume that $f_{0}$ has been extended to a real-linear functional $f_{1}$ on a subspace $M_{1}$ of $A_{r}$, such that $f_{1}(x) \geq 0$ for all $x \in P \cap M_{1}$, and assume that $y \in A_{r}, y \notin M_{1}$. Put

$$
E^{\prime}=M_{1} \cap(y-P), \quad E^{\prime \prime}=M_{1} \cap(y+P)
$$

If $x^{\prime} \in E^{\prime}$ and $x^{\prime \prime} \in E^{\prime \prime}$, then $y-x^{\prime} \in P$ and $x^{\prime \prime}-y \in P$; hence so is their sum, $x^{\prime \prime}-x^{\prime}$, and therefore $f_{1}\left(x^{\prime}\right) \leq f_{1}\left(x^{\prime \prime}\right)$. It follows that there is a real number $c$ that satisfies

$$
f_{1}\left(x^{\prime}\right) \leq c \leq f_{1}\left(x^{\prime \prime}\right) \quad\left(x^{\prime} \in E^{\prime}, x^{\prime \prime} \in E^{\prime \prime}\right) .
$$

Define

$$
f_{2}(x+\alpha y)=f_{1}(x)+\alpha c \quad\left(x \in M_{1}, \alpha \in R\right)
$$

If $x+y \in P$, then $-x \in E^{\prime}, f_{1}(-x) \leq c, f_{1}(x) \geq-c$; hence $f_{2}(x+y) \geq 0$. If $x-y \in P$, then $x \in E^{\prime \prime}, f_{1}(x) \geq c$, and $f_{2}(x-y) \geq c-c=0$. It follows from these two cases that $f_{2} \geq 0$ on $P \cap M_{2}$.

The proof can now be completed by transfinite induction, just as in the Hahn-Banach theorem.

12.40 Theorem If $A$ is a $B^{*}$-algebra and if $u \in A, u \neq 0$, there exists a Hilbert space $H_{u}$ and there exists a homomorphism $T_{u}$ of $A$ into $\mathscr{B}\left(H_{u}\right)$ that satisfies $T_{u}(e)=I$,

$$
\begin{array}{cc}
T_{u}\left(x^{*}\right)=T_{u}(x)^{*} & (x \in A), \\
\left\|T_{u}(x)\right\| \leq\|x\| & (x \in A)
\end{array}
$$

and $\left\|T_{u}(u)\right\|=\|u\|$.

PROOF We regard $u$ as fixed and omit the subscripts $u$. Fix a positive functional $F$ on $A$ that satisfies

$$
F(e)=1 \quad \text { and } \quad F\left(u^{*} u\right)=\|u\|^{2}
$$

Such an $F$ exists, by Theorem 12.39. Define

$$
Y=\{y \in A: F(x y)=0 \text { for every } x \in A\} .
$$

Since $F$ is continuous (Theorem 11.31), $Y$ is a closed subspace of $A$. Denote cosets of $Y$, that is, elements of $A / Y$, by $x^{\prime}$ :

$$
x^{\prime}=x+Y \quad(x \in A)
$$

We claim that

$$
\left(a^{\prime}, b^{\prime}\right)=F\left(b^{*} a\right)
$$

defines an inner product on $A / Y$.

To see that $\left(a^{\prime}, b^{\prime}\right)$ is well defined by (6), i.e., that it is independent of the choice of representatives $a$ and $b$, it is enough to show that $F\left(b^{*} a\right)=0$ if at least one of $a$ or $b$ lies in $Y$. If $a \in Y, F\left(b^{*} a\right)=0$ follows from (4). If $b \in Y$, then

$$
F\left(b^{*} a\right)=F\left(a^{*} b\right)=0
$$

by $(a)$ of Theorem 11.31 and another application of (4). Thus $\left(a^{\prime}, b^{\prime}\right)$ is well defined, it is linear in $a^{\prime}$, and conjugate-linear in $b^{\prime}$, and

$$
\left(a^{\prime}, a^{\prime}\right)=F\left(a^{*} a\right) \geq 0
$$

since $F$ is a positive functional. If $\left(a^{\prime}, a^{\prime}\right)=0$, then $F\left(a^{*} a\right)=0$; hence $F(x a)=0$ for every $x \in A$, by ( $b$ ) of Theorem 11.31 , so that $a \in Y$ and $a^{\prime}=0$.

$A / Y$ is thus an inner product space, with norm $\left\|a^{\prime}\right\|=F\left(a^{*} a\right)^{1 / 2}$. Its completion $H$ is the Hilbert space that we are looking for. We define linear operators $T(x)$ on $A / Y$ by

$$
T(x) a^{\prime}=(x a)^{\prime} .
$$

Again, one checks easily that this definition is independent of the choice of $a \in a^{\prime}$, for if $y \in Y$, (4) implies that $x y \in Y$. ( $Y$ is a left ideal in $A$.) It is obvious that $x \rightarrow T(x)$ is linear and that

$$
T\left(x_{1}\right) T\left(x_{2}\right)=T\left(x_{1} x_{2}\right) \quad\left(x_{1} \in A, x_{2} \in A\right)
$$

in particular, (9) shows that $T(e)$ is the identity operator on $A / Y$. We now claim that

$$
\|T(x)\| \leq\|x\| \quad(x \in A) .
$$

Once this is shown, the uniform continuity of the operators $T(x)$ enables us to extend them to bounded linear operators on $H$. Note that

$$
\left\|T(x) a^{\prime}\right\|^{2}=\left((x a)^{\prime},(x a)^{\prime}\right)=F\left(a^{*} x^{*} x a\right) .
$$

For fixed $a \in A$, define $G(x)=F\left(a^{*} x a\right)$. Then $G$ is a positive functional on $A$, so that

$$
G\left(x^{*} x\right) \leq G(e)\|x\|^{2},
$$

by $(d)$ of Theorem 11.31. Thus

$$
\left\|T(x) a^{\prime}\right\|^{2}=G\left(x^{*} x\right) \leq F\left(a^{*} a\right)\|x\|^{2}=\left\|a^{\prime}\right\|^{2}\|x\|^{2},
$$

which proves (11).

Next, the computation

$$
\begin{aligned}
\left(T\left(x^{*}\right) a^{\prime}, b^{\prime}\right) & =\left(\left(x^{*} a\right)^{\prime}, b^{\prime}\right)=F\left(b^{*} x^{*} a\right)=F\left((x b)^{*} a\right) \\
& =\left(a^{\prime},(x b)^{\prime}\right)=\left(a^{\prime}, T(x) b^{\prime}\right)=\left(T(x)^{*} a^{\prime}, b^{\prime}\right)
\end{aligned}
$$

shows that $T\left(x^{*}\right) a^{\prime}=T(x)^{*} a^{\prime}$, for all $a^{\prime} \in A / Y$. Since $A / Y$ is dense in $H$, this proves (1).

Finally, (3) and (12) show that

$$
\|u\|^{2}=F\left(u^{*} u\right)=\left\|T(u) e^{\prime}\right\|^{2} \leq\|T(u)\|^{2}
$$

since $\left\|e^{\prime}\right\|^{2}=F\left(e^{*} e\right)=F(e)=1$. In conjunction with (11), (15) gives $\|T(u)\|=$ $\|u\|$, and the proof is complete.

12.41 Theorem If $A$ is a $B^{*}$-algebra, there exists an isometric *-isomorphism of $A$ onto a closed subalgebra of $\mathscr{B}(H)$, where $H$ is a suitably chosen Hilbert space.

PROOF Let $H$ be the "direct sum" of the Hilbert spaces $H_{u}$ constructed in Theorem 12.40. Here is a precise description of $H$ : Let $\pi_{\mu}(v)$ be the $H_{u}-$ coordinate of an element $v$ of the cartesian product of the spaces $H_{u}$. Then, by definition, $v \in H$ if and only if

$$
\sum_{u}\left\|\pi_{u}(v)\right\|^{2}<\infty
$$

where $\left\|\pi_{u}(v)\right\|$ denotes the $H_{u}$-norm of $\pi_{u}(v)$. The convergence of (1) implies that at most countably many $\pi_{u}(v)$ are different from 0 . The inner product in $H$ is given by

$$
\left(v^{\prime}, v^{\prime \prime}\right)=\sum_{u}\left(\pi_{u}\left(v^{\prime}\right), \pi_{u}\left(v^{\prime \prime}\right)\right) \quad\left(v^{\prime}, v^{\prime \prime} \in H\right)
$$

so that $\|v\|^{2}=(v, v)$ is the left side of (1). We leave it as an exercise to verify that all Hilbert space axioms are now satisfied by $\boldsymbol{H}$.

If $S_{u} \in \mathscr{B}\left(H_{u}\right)$, if $\left\|S_{u}\right\| \leq M$ for all $u$, and if $S v$ is defined to be the vector whose coordinate in $H_{u}$ is

$$
\pi_{u}(S v)=S_{u} \pi_{u}(v)
$$

one verifies easily that $S v \in H$ if $v \in H$, that $S \in \mathscr{B}(H)$, and that

$$
\|S\|=\sup _{u}\left\|S_{u}\right\|
$$

We now associate with each $x \in A$ an operator $T(x) \in \mathscr{B}(H)$, by requiring that

$$
\pi_{u}(T(x) v)=T_{u}(x)\left(\pi_{u}(v)\right)
$$

where $T_{u}$ is as in Theorem 12.40. Since

$$
\left\|T_{u}(x)\right\| \leq\|x\|=\left\|T_{x}(x)\right\|
$$

by Theorem 12.40, it follows from (4) that

$$
\|T(x)\|=\sup _{u}\left\|T_{u}(x)\right\|=\|x\| .
$$

That the mapping $x \rightarrow T(x)$ of $A$ into $\mathscr{B}(H)$ has the other required properties follows from a coordinate wise application of Theorem 12.40 .


\end{document}