\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{bbold}

\begin{document}
\section{COMMUTATIVE BANACH ALGEBRAS}
This chapter deals primarily with the Gelfand theory of commutative Banach algebras, although some of the results of this theory will be applied to noncommutative situations. The terminology of the preceding chapter will be used without change. In particular, Banach algebras will not be assumed to be commutative unless this is explicilly stated, but the presence of a unit will be assumed without special mention, as will the fact that the scalar field is $\mathscr{C}$.

\section{Ideals and Homomorphisms}
11.1 Definition A subset $\vec{J}$ of a commutative complex algebra $A$ is said to be an ideal if

(a) $J$ is a subspace of $A$ (in the vector space sense), and

(b) $x y \in J$ whenever $x \in A$ and $y \in J$.

If $\boldsymbol{J} \neq A, \boldsymbol{J}$ is a proper ideal. Maximal ideals are proper ideals which are not contained in any larger proper ideal.

\subsection{Proposition}
(a) No proper ideal of A contains any invertible element of $A$.

(b) If $J$ is an ideal in a commutative Banach algebra $A$, ihen its closure $\bar{J}$ is also an ideal.

The proofs are so simple that they are left as an exercise.

\subsection{Theorem}
(a) If $A$ is a commutative complex algebra with unit, then every proper ideal of $A$ is contained in a maximal ideal of $A$.

(b) If $A$ is a commutative Banach algebra, then every maximal ideal of $A$ is closed. PROOF (a) Let $J$ be a proper ideal of $A$. Let $\mathscr{P}$ be the collection of all proper ideals of $A$ that contain $J$. Partially order $\mathscr{P}$ by set inclusion, let $\mathscr{Q}$ be a maximal ' totally ordered subcollection of $\mathscr{P}$ (the existence of $\mathscr{Q}$ is assured by Hausdorff's maximality theorem), and let $M$ be the union of all members of 2 . Being the union of a tolly ordered collection of ideals, $M$ is an ideal. Obviously $J \subset M$, and $M \neq A$ since no member of $\mathscr{P}$ contains the unit of $A$. The maximality of 2 implies that $M$ is a maximal ideal of $A$.

(b) Suppose $M$ is a maximal ideal in $A$. Since $M$ contains no invertible element of $A$ and since the set of all invertible elements is open, $\bar{M}$ contains no invertible element either. Thus $\bar{M}$ is a proper ideal of $A$, and the maximality of $M$ shows therefore that $M=\bar{M}$.

11.4 Homomorphisms and quotient algebras If $A$ and $B$ are commutative Banach algebras and $\phi$ is a homomorphism of $A$ into $B$ (see Section 10.4) then the null space or kernel of $\phi$ is obviously an ideal in $A$, which is closed if $\phi$ is continuous. Conversely, suppose $J$ is a proper closed ideal in $A$ and $\pi: A \rightarrow A / J$ is the quotient map, as in Definition 1.40. Then $A / J$ is a Banach space, with respect to the quotient norm (Theorem 1.41). We will show that $A / J$ is actually a Banach algebra and that $\pi$ is a homomorphism.

$$
\text { If } x^{\prime}-x \in J \text { and } y^{\prime}-y \in J \text {, the identity }
$$

$$
x^{\prime} y^{\prime}-x y=\left(x^{\prime}-x\right) y^{\prime}+x\left(y^{\prime}-y\right)
$$

shows that $x^{\prime} y^{\prime}-x y \in J$; hence $\pi\left(x^{\prime} y^{\prime}\right)=\pi(x y)$. Multiplication can therefore be unambiguously defined in $A / J$ by

$$
\pi(x) \pi(y)=\pi(x y) \quad(x \in A, y \in A) .
$$

It is then easily verified that $A / J$ is a complex algebra and that $\pi$ is a homomorphism. Since $\|\pi(x)\| \leq\|x\|$, by the definition of the quotient norm, $\pi$ is continuous.

Suppose $x_{i} \in A(i=1,2)$ and $\delta>0$. Then

$$
\left\|x_{i}+y_{i}\right\| \leq\left\|\pi\left(x_{i}\right)\right\|+\delta \quad(i=1,2)
$$

for some $y_{i} \in J$, by the definition of the quotient norm. Since

$$
\left(x_{1}+y_{1}\right)\left(x_{2}+y_{2}\right) \in x_{1} x_{2}+J
$$

we have

$$
\left\|\pi\left(x_{1} \dot{x_{2}}\right)\right\| \leq\left\|\left(x_{1}+y_{1}\right)\left(x_{2}+y_{2}\right)\right\| \leq\left\|x_{1}+y_{1}\right\|\left\|x_{2}+y_{2}\right\|
$$

so that (3) implies the multiplicative inequality

$$
\left\|\pi\left(x_{1}\right) \pi\left(x_{2}\right)\right\| \leq\left\|\pi\left(x_{1}\right)\right\|\left\|\pi\left(x_{2}\right)\right\|
$$

Finally, if $e$ is the unit element of $A$, then (2) shows that $\pi(e)$ is the unit of $A / J$, and since $\pi(e) \neq 0$, (5) shows that $\|\pi(e)\| \geq 1=\|e\|$. Since $\|\pi(x)\| \leq\|x\|$ for every $x \in A,\|\pi(e)\|=1$. This completes the proof.

Part $(a)$ of the next theorem is one of the key facts of the whole theory. The set $\Delta$ that appears in it will later be given a compact Hausdorff topology (Theorem 11.9). The study of commutative Banach algebras will then to a large extent be reduced to the study of more familiar (and more special) objects, namely, algebras of continuous complex functions on $\Delta$, with pointwise addition and multiplication. However, Theorem 11.5 has interesting concrete consequences even without the introduction of this topology. Sections 11.6 and 11.7 illustrate this point.

11.5 Theorem Let $A$ be a commutative Banach algebra, and let $\Delta$ be the set of all complex homomorphisms of $A$.

(a) Every maximal ideal of $A$ is the kernel of some $h \in \Delta$.

(b) If $h \in \Delta$, the kernel of $h$ is a maximal ideal of $A$.

(c) An element $x \in A$ is invertible in $A$ if and only if $h(x) \neq 0$ for every $h \in \mathbf{\Delta}$.

(d) An element $x \in A$ is invertible in $A$ if and only if $x$ lies in no proper ideal of $A$.

(e) $\lambda \in \sigma(x)$ if and only if $h(x)=\lambda$ for some $h \in \Delta$.

PROOF (a) Let $M$ be a maximal ideal of $A$. Then $M$ is closed (Theorem 11.3) and $A / M$ is therefore a Banach algebra. Choose $x \in A, x \dot{\notin} M$, and put

$$
J=\{a x+y: a \in A, y \in M\}
$$

Then $J$ is an ideal in $A$ which is larger than $M$, since $x \in J$. (Take $a=e, y=0$.) Thus $J=A$, and $a x+y=e$ for some $a \in A, y \in M$. If $\pi: A \rightarrow A / M$ is the quotient map, it follows that $\pi(a) \pi(x)=\pi(e)$. Every nonzero element $\pi(x)$ of the Banach algebra $A / M$ is therefore invertible in $A / M$. By the Gelfand-Mazur theorem, there is an isomorphism $j$ of $A / M$ onto $\mathbb{C}$. Put $h=j \circ \pi$. Then $h \in \Delta$, and $M$ is the null space of $h$.
(b) If $h \in \Delta$, then $h^{-1}(0)$ is an ideal in $A$ which is maximal because it has codimension 1 .

(c) If $x$ is invertible in $A$ and $h \in \Delta$, then

$$
h(x) h\left(x^{-1}\right)=h\left(x x^{-1}\right)=h(e)=1,
$$

so that $h(x) \neq 0$. If $x$ is not invertible, then the set $\{a x: a \in A\}$ does not contain $e$, hence is a proper ideal which lies in a maximal one (Theorem 11.3) and which is therefore annihilated by some $h \in \Delta$, because of $(a)$.

(d) No invertible element lies in any proper ideal. The converse was proved in the proof of $(c)$.

(e) Apply $(c)$ to $\lambda e-x$ in place of $x$.

Our first application concerns functions on $R^{n}$ that are sums of absolutely convergent trigonometric series. The notation is as in Exercise 22 of Chapter 7.

\subsection{Wiener's lemma Suppose $f$ is a function on $R^{n}$, and}
$$
f(x)=\sum a_{m} e^{i m \cdot x}, \quad \sum\left|a_{m}\right|<\infty,
$$

where both sums are extended over all $m \in Z^{n}$. If $f(x) \neq 0$ for every $x \in R^{n}$, then

$$
\frac{1}{f(x)}=\sum b_{m} e^{i m \cdot x} \quad \text { with } \quad \sum\left|b_{m}\right|<\infty
$$

PROOF Let $A$ be the set of functions of the form (1), normed by $\|f\|=\sum\left|a_{m}\right|$. One checks easily that $A$ is a commutative Banach algebra, with respect to pointwise multiplication. Its unit is the constant function 1. For each $x$, the evaluation $f \rightarrow f(x)$ is a complex homomorphism of $A$. The assumption about the given function $f$ is that no evaluation annihilates it. If we can prove that $A$ has no other complex homomorphisms, ' $(c)$ of Theorem 11.5 will imply that $f$ is invertible in $A$, which is exactly the desired conclusion.

For $r=1, \ldots, n$, put $g_{r}(x)=\exp \left(i x_{r}\right)$, where $x_{r}$ is the $r$ th coordinate of $x$. Then $g_{r}$ and $1 / g_{r}$ are in $A$ and have norm 1. If $h \in \Delta$, it follows from (c) of Theorem 10.7 that

$$
\left|h\left(g_{r}\right)\right| \leq 1 \quad \text { and } \quad\left|\frac{1}{h\left(g_{r}\right)}\right|=\left|h\left(\frac{1}{g_{r}}\right)\right| \leq 1 \text {. }
$$

Hence there are real numbers $y_{r}$ such that

$$
h\left(g_{r}\right)=\exp \left(i y_{r}\right)=g_{r}(y) \quad(1 \leq r \leq n)
$$

where $y=\left(y_{1}, \ldots ; y_{n}\right)$. If $P$ is a trigonometric polynomial (which means, by
definition, that $P$ is a finite linear combination of products of integral powers of the functions $g_{r}$ and $1 / g_{r}$ ), then (3) implies

$$
h(P)=P(y)
$$

because $h$ is linear and multiplicative. Since $h$ is continuous on $A$ (Theorem 10.7) and since the set of all trigonometric polynomials is dense in $A$ (as is obvious from the definition of the norm), (4) implies that $h(f)=f(y)$ for every $f \in A$. Thus $h$ is evaluation at $y$, and the proof is complete.

This lemma was used (with $n=1$ ) in the original proof of the tauberian theorem 9.7. To see the connection, let us reinterpret the lemma. Regard $Z^{n}$ as being embedded in $R^{n}$ in the obvious way. The given coefficients $a_{m}$ define then a measure $\mu$ on $R^{n}$, concentrated on $Z^{n}$, which assigns mass $a_{m}$ to each $m \in Z^{n}$. Consider the problem of finding a complex measure $\sigma$, concentrated on $Z^{n}$, such that the convolution $\mu * \sigma$ is the Dirac measure $\delta$. Wiener's lemma states that this problem can be solved if (and trivially only if) the Fourier transform of $\mu$ has no zero on $R^{n}$; this is precisely the tauberian hypothesis in Theorem 9.7.

For our next application, let $U^{n}$ be the set of all points $z=\left(z_{1}, \ldots, z_{n}\right)$ in $\mathbb{C}^{n}$ such that $\left|z_{i}\right|<1$ for $1 \leq i \leq n$. In other words, this polydisc $U^{n}$ is the cartesian product of $n$ copies of the open unit disc $U$ in $\mathscr{C}$. We define $A\left(U^{n}\right)$ to be the set of all functions $f$ that are holomorphic in $U^{n}$ (see Definition 7.20) and that are continuous on its closure $\bar{U}^{n}$.

11.7 Theorem Suppose $f_{1}, \ldots, f_{k} \in A\left(U^{n}\right)$, and suppose that to each $z \in \bar{U}^{n}$ there corresponds at least one $i$ such that $f_{i}(z) \neq 0$. Then there exist functions $\phi_{1}, \ldots$, $\phi_{k} \in A\left(U^{n}\right)$ such that

$$
f_{1}(z) \phi_{1}(z)+\cdots+f_{k}(z) \phi_{k}(z)=1 \quad\left(z \in \bar{U}^{n}\right)
$$

PROOF $A=A\left(U^{n}\right)$ is a commutative Banach algebra, with pointwise multiplication and the supremum norm. Let $J$ be the set of all sums $\sum f_{i} \phi_{i}$, with $\phi_{i} \in A$. Then $J$ is an ideal. If the conclusion is false, then $J \neq A$; hence $J$ lies in some maximal ideal of $A$ (Theorem 11.3), and some $h \in \Delta$ annihilates $J$, by (a) of Theorem 11.5 .

For $1 \leq r \leq n$, put ${ }^{*} g_{r}(z)=z_{r}$. Then $\left\|g_{r}\right\|=1$; hence $h\left(g_{r}\right)=w_{r}$, with $\left|w_{r}\right| \leq 1$. Put $w=\left(w_{1}, \ldots, w_{n}\right)$. Then $w \in \bar{U}^{n}$, and $h\left(g_{r}\right)=g_{r}(w)$. It follows that $h(P)=P(w)$ for every polynomial $P$, since $h$ is a homomorphism. The polynomials are dense in $A\left(U^{n}\right)$ (Exercise 4). Hence $h(f)=f(w)$ for every $f \in A$, by essentially the same argument that was used in the proof of Theorem 11.6.

Since $h$ annihilates $J, f_{i}(w)=0$ for $1 \leq i \leq k$. This contradicts the hypothesis.

\section{Gelfand Transforms}
11.8 Definitions Let $\Delta$ be the set of all complex homomorphisms of a commutative Banach algebra $A$. The formula

$$
\hat{x}(h)=h(x) \quad(h \in \Delta)
$$

assigns to each $x \in A$ a function $\hat{x}: \Delta \rightarrow \mathscr{C}$; we call $\hat{x}$ the Gelfand transform of $x$.

Let $\hat{A}$ be the set of all $\hat{x}$, for $x \in A$. The Gelfand topology of $\Delta$ is the weak topology induced by $\hat{A}$, that is, the weakest topology that makes every $\hat{x}$ continuous. Then obviously $\hat{A} \subset C(\Delta)$, the algebra of all complex continuous functions on $\Delta$.

Since there is a one-to-one correspondence between the maximal ideals of $A$ and the members of $\Delta$ (Theorem 11.5), $\Delta$, equipped wilh its Gelfand topology, is usually called the maximal ideal space of $A$.

The term "Gelfand transform" is also applied to the mapping $x \rightarrow \hat{x}$ of $A$ onto $\hat{A}$. The radical of $A$, denoted by $\operatorname{rad} A$, is the intersection of all maximal ideals of $A$. If $\operatorname{rad} A=\{0\}, A$ is called semisimple.

11.9 Theorem Let $\Delta$ be the maximal ideal space of a commutative Banach algebra A.

(a) $\Delta$ is a compact Hausdorff space.

(b) The Gelfand transform is a homomorphism of $A$ onto a subalgebra $\hat{A}$ of $C(\Delta)$, whose kernel is rad $A$. The Gelfand transform is therefore an isomorphism if and only if $A$ is semisimple.

(c) For each $x \in A$, the range of $\hat{x}$ is the spectrum $\sigma(x)$. Hence

$$
\|\hat{x}\|_{\infty}=\rho(x) \leq\|x\|,
$$

where $\|\hat{x}\|_{\infty}$ is the maximum of $|\hat{x}(h)|$ on $\Delta$, and $x \in \operatorname{rad} A$ if and only if $\rho(x)=0$.

PRoof We first prove $(b)$ and (c). Suppose $x \in A, y \in A, \alpha \in \overparen{C}, h \in \Delta$. Then

$$
\begin{gathered}
(\alpha x)^{\wedge}(h)=h(\alpha x)=\alpha h(x)=(\alpha \hat{x})(h) \\
(x+y)^{\wedge}(h)=h(x+y)=h(x)+h(y)=\hat{x}(h)+\hat{y}(h)=(\hat{x}+\hat{y})(h)
\end{gathered}
$$

and

$$
(x y)^{\wedge}(h)=h(x y)=h(x) h(y)=\hat{x}(h) \hat{y}(h)=(\hat{x} \hat{y})(h) .
$$

Thus $x \rightarrow \hat{x}$ is a homomorphism. Its kernel consists of those $\dot{x} \in A$ which satisfy $h(x)=0$ for every $h \in \Delta$; by Theorem 11.5, this is the intersection of all maximal ideals of $A$, that is, $\operatorname{rad} A$.

To say that $\lambda$ is in the range of $\hat{x}$ means that $\lambda=\hat{x}(h)=h(x)$ for some $h \in \Delta$. By $(c)$ of Theorem 11.5, this happens if and only if $\lambda \in \sigma(x)$. This proves $(b)$ and $(c)$.

To prove (a), let $A^{*}$ be the dual space of $A$ (regarded as a Banach space), and let $K$ be the norm-closed unit ball of $A^{*}$. By the Banach-Alaoglu theorem, $K$ is weak*-compact. By (c) of Theorem 10.7, $\Delta \subset K$. The Gelfand topology of $\Delta$ is evidently the restriction to $\Delta$ of the weak*-topology of $A^{*}$. It is therefore enough to show that $\Delta$ is a weak*-closed subset of $A^{*}$.

Let $\Lambda_{0}$ be in the weak*-closure of $\Delta$. We have to show that

$$
\Lambda_{0}(x y)=\Lambda_{0} x \Lambda_{0} y \quad(x \in A, y \in A)
$$

and

$$
\Lambda_{0} e=1
$$

[Note that (2) is necessary; otherwise $\Lambda_{0}$ would be the zero homomorphism, which is not in $\Delta$.]

Fix $x \in A, y \in A, \varepsilon>0$. Put

$$
W=\left\{\Lambda \in A^{*}:\left|\Lambda z_{i}-\Lambda_{0} z_{i}\right|<\varepsilon \text { for } 1 \leq i \leq 4\right\}
$$

where $z_{1}=e, z_{2}=x, z_{3}=y, z_{4}=x y$. Then $W$ is a weak*-neighborhood of $\Lambda_{0}$ which therefore contains an $h \in \Delta$. For this $h$,

$$
\left|1-\Lambda_{0} e\right|=\left|h(e)-\Lambda_{0} e\right|<\varepsilon,
$$

which gives (2), and

$$
\begin{aligned}
\Lambda_{0}(x y)-\Lambda_{0} x \Lambda_{0} y & =\left[\Lambda_{0}(x y)-h(x y)\right]+\left[h(x) h(y)-\Lambda_{0} x \Lambda_{0} y\right] \\
& =\left[\Lambda_{0}(x y)-h(x y)\right]+\left[h(y)-\Lambda_{0} y\right] h(x)+\left[h(x)-\Lambda_{0} x\right] \Lambda_{0} y
\end{aligned}
$$

which gives

$$
\left|\Lambda_{0}(x y)-\Lambda_{0} x \Lambda_{0} y\right|<\left(1+\|x\|+\left|\Lambda_{0} y\right|\right) \varepsilon .
$$

Since (5) implies (1), the proof is complete.

Semisimple algebras have an important property which was earlier proved for $\mathbb{C}$ :

11.10 Theorem If $\psi: B \rightarrow A$ is a homomorphism of a commutative Banach algebra $B$ into a semisimple commutative Banach algebra $A$, then $\psi$ is continuous.

PROOF Suppose $x_{n} \rightarrow x$ in $B$ and $\psi\left(x_{n}\right) \rightarrow y$ in $A$. By the closed graph theorem, it is enough to show that $y=\psi(x)$.

Let $\Delta_{A}$ and $\Delta_{B}$ be the respective maximal ideal spaces. Fix $h \in \Delta_{A}$; put $\phi=h \circ \psi$. Then $\phi \in \Delta_{B}$. By Theorem 10.7, $h$ and $\phi$ are continuous. Hence

$$
h(y)=\lim h\left(\psi\left(x_{n}\right)\right)=\lim \phi\left(x_{n}\right)=\phi(x)=h(\psi(x))
$$

for every $h \in \Delta_{A}$. Hence $y-\psi(x) \in \operatorname{rad} A$. Since $\operatorname{rad} A=\{0\}, y=\psi(x)$.

Corollary Every isomorphism between two semisimple commutative Banach algebras is a homeomorphism.

In particular, this is true of every automorphism of a semisimple commutative Banach algebra. The topology of such an algebra is therefore completely determined by its algebraic structure.

In Theorem 11.9, the algebra $\widehat{A}$ may or may not be closed in $C(\Delta)$, with respect to the supremum norm. Which of these cases occurs can be decided by comparing $\left\|x^{2}\right\|$ with $\|x\|^{2}$, for all $x \in A$. Recall that $\left\|x^{2}\right\| \leq\|x\|^{2}$ is always true.

11.11 Lemma If $A$ is a commutative Banach algebra and

$$
r=\inf \frac{\left\|x^{2}\right\|}{\|x\|^{2}}, \quad s=\inf \frac{\|\hat{x}\|_{\infty}}{\|x\|} \quad(x \in A, x \neq 0)
$$

then $s^{2} \leq r \leq s$

PRoOF Since $\|\hat{x}\|_{\infty} \geq s\|x\|$,

$$
\left\|x^{2}\right\| \geq\left\|\hat{x}^{2}\right\|_{\infty}=\|\hat{x}\|_{\infty}^{2} \geq s^{2}\|x\|^{2}
$$

for every $x \in A$. Thus $s^{2} \leq r$.

Since $\left\|x^{2}\right\| \geq r\|x\|^{2}$ for every $x \in A$, induction on $n$ shows that

$$
\left\|x^{m}\right\| \geq r^{m-1}\|x\|^{m} \quad\left(m=2^{n}, n=1,2,3, \ldots\right)
$$

Take $m$ th roots in (3) and let $m \rightarrow \infty$. By the spectral radius formula and (c) of Theorem 11.9,

$$
\|\hat{x}\|_{\infty}=\rho(x) \geq r\|x\| \quad(x \in A) .
$$

Hence $r \leq s$.

11.12 Theorem Suppose A is a commutative Banach algebra.

(a) The Gelfand transform is an isometry (that is, $\|x\|=\|\hat{x}\|_{\infty}$ for every $x \in A$ ) if and only if $\left\|x^{2}\right\|=\|x\|^{2}$ for every $x \in A$.

(b) $A$ is semisimple and $\hat{A}$ is closed in $C(\Delta)$ if and only if there exists $K<\infty$ such that $\|x\|^{2} \leq K\left\|x^{2}\right\|$ for every $x \in A$.

PROOF (a) In the terminology of Lemma 11.11, the Gelfand transform is an isometry if and only if $s=1$, which happens (by the lemma) if and only if $r=1$.

(b) The existence of $K$ is equivalent to $r>0$, hence to $s>0$, by the lemma. If $s>0$, then $x \rightarrow \hat{x}$ is one-to-one and has a continuous inverse, so that $\hat{A}$ is complete (hence closed) in $C(\Lambda)$. Conversely, if $x \rightarrow \hat{x}$ is one-to-one and if $\widehat{A}$ is closed in $C(\Delta)$, the open mapping theorem implies that $s>0$.

11.13 Examples In some cases, the maximal ideal space of a given commutative Banach algebra can easily be described explicitly. In others, extreme pathologies occur. We shall now give some examples to illustrate this.

(a) Let $X$ be a compact Hausdorff space, put $A=C(X)$, with the supremum norm. For each $x \in X, f \rightarrow f(x)$ is a complex homomorphism $h_{x}$. Since $C(X)$ separates points on $X$ (Urysohn's lemma), $x \neq y$ implies $h_{x} \neq h_{y}$. Thus $x \rightarrow h_{x}$ embeds $X$ in $\Delta$.

We claim that each $h \in \Delta$ is an $h_{x}$. If this is false, there is a maximal ideal $M$ in $C(X)$ which contains, for each $p \in X$, a function $f$ with $f(p) \neq 0$. The compactness of $X$ implies then that $M$ contains finitely many functions $f_{1}, \ldots, f_{n}$ such that at least one of them is $\neq 0$ at each point of $X$. Put

$$
g=f_{1} \bar{f}_{1}+\cdots+f_{n} \bar{f}_{n} .
$$

Then $g \in M$, since $M$ is an ideal; $g>0$ at every point of $X$; hence $g$ is invertible in $C(X)$. But proper ideals contain no invertible elements.

Thus $x \leftrightarrow h_{x}$ is a one-to-one correspondence between $X$ and $\Delta$ and can be used to identify $\Delta$ with $X$. This identification is also correct in terms of the two topologies that are involved: The Gelfand topology $\gamma$ of $X$ is the weak topology induced by $C(X)$ and is therefore weaker than $\tau$, the original one, but $\gamma$ is a Hausdorff topology; hence $\gamma=\tau$. [See $(a)$ of Section 3.8.]

Summing up, $X$ "is" the maximal ideal space of $C(X)$, and the Gelfand transform is the identity mapping on $C(X)$.

(b) Let $A$ be the algebra of all absolutely convergent trigonometric series, as in Section 11.6. We found there that the complex homomorphisms are the evaluations at points of $R^{n}$. Since the members of $A$ are $2 \pi$-periodic in each variable, $\Delta$ is the torus $T^{n}$ obtained from $R^{n}$ by the mapping

$$
\left(x_{1}, \ldots, x_{n}\right) \rightarrow\left(e^{i x_{1}}, \ldots, e^{i x_{n}}\right)
$$

This is an example in which $\hat{A}$ is dense in $C(\Delta)$, although $\hat{A} \neq C(\Delta)$.

(c) In the same way, the proof of Theorem 11.7 contains the result that $\bar{U}^{n}$ is the maximal ideal space of $A\left(U^{n}\right)$. The argument used at the end of $(a)$ shows that the natural topology of $\bar{U}^{n}$ is the same as the Gelfand topology induced by $A\left(\bar{U}^{n}\right)$; the same remark applies to $(b)$.

(d) The preceding example has interesting generalizations. Let $A$ now be a commutative Banach algebra with a finite set of generators, say $x_{1}, \ldots, x_{n}$. This means that $x_{i} \in A(1 \leq i \leq n)$ and that the set of all polynomials in $x_{1}, \ldots, x_{n}$ is dense in $A$. Define

$$
\phi(h)=\left(\hat{x}_{1}(h), \ldots, \hat{x}_{n}(h)\right) \quad(h \in \Delta)
$$

Then $\phi$ is a homeomorphism of $\Delta$ onto a compact set $\bar{K} \subset \mathscr{C}^{n}$. Indeed, $\phi$ is continuous since $\hat{A} \subset C(\Delta)$. If $\phi\left(h_{1}\right)=\phi\left(h_{2}\right)$, then $h_{1}\left(x_{i}\right)=h_{2}\left(x_{i}\right)$ for all $i$; hence $h_{1}(x)=h_{2}(x)$ whenever $x$ is a polynomial in $x_{1}, \ldots, x_{n}$, and since these polynomials are dense in $A$, $h_{1}=h_{2}$. Thus $\phi$ is one-to-one.

We can now transfer $\hat{A}$ from $\Delta$ to $K$ and may thus regard $K$ as the maximal ideal space of $A$. To make this precise, define

$$
\psi(x)=\hat{x} \circ \phi^{-1} \quad(x \in A) .
$$

Then $\psi$ is a homomorphism (an isomorphism if $A$ is semisimple) of $A$ onto a subalgebra $\psi(A)$ of $C(K)$. One verifies easily that

$$
\psi\left(x_{i}\right)(z)=z_{i} \quad \text { if } z=\left(z_{1}, \ldots, z_{n}\right) \in K
$$

and therefore

$$
\psi\left(P\left(x_{1}, \ldots, x_{n}\right)\right)(z)=P(z) \quad(z \in K)
$$

for every polynomial $P$ in $n$ variables.

It follows that every member of $\psi(A)$ is a uniform limit of polynomials, on $K$.

The sets $K \subset \mathbb{C}^{n}$ which arise in this fashion as maximal ideal spaces have a property known as polynomial convexity:

If $w \in \mathbb{C}^{n}$ and $w \notin K$, there exists a polynomial $P$ such that $|P(z)| \leq 1$ for every $z \in K$, but $|P(w)|>1$.

To prove this, assume there is no such polynomial. The norm-decreasing property of the Gelfand transform implies then that

$$
|P(w)| \leq\left\|P\left(x_{1}, \ldots, x_{n}\right)\right\|
$$

for every polynomial $P$; the norm is that of $A$. Since $\left\{x_{1}, \ldots, x_{n}\right\}$ is a set of generators of $A$, it follows from (5) that there is an $h \in \Delta$ such that $\phi(h)=w$. But then $w \in K$, and we have a contradiction.

The compact polynomially convex subsets of $\mathbb{C}$ are simply those whose complement is connected; this is an easy consequence of Runge's theorem. In $\mathscr{C}^{n}$, the structure of the polynomially convex sets is by no means fully understood.

(e) Our next example shows that the Gelfand transform is a generalization of the Fourier transform, at least in the $L^{1}$-context.

Let $A$ be $L^{1}\left(R^{n}\right)$ with a unit attached, as described in $(d)$ of Section 10.3. The members of $A$ are of the form $f+\alpha \delta$, where $f \in L^{1}\left(R^{n}\right), \alpha \in \mathbb{C}$, and $\delta$ is the Dirac measure on $R^{n}$; multiplication in $A$ is convolution:

$$
(f+\alpha \delta) *(g+\beta \delta)=(f * g+\beta f+\alpha g)+\alpha \beta \delta
$$

For each $t \in R^{n}$, the formula

$$
h_{t}(f+\alpha \delta)=\hat{f}(t)+\alpha
$$

defines a complex homomorphism of $A$; here $\hat{f}$ is the Fourier transform of $f$. In addition,

$$
h_{\infty}(f+\alpha \delta)=\alpha
$$

also defines a complex homomorphism. There are no others. (A proof will be sketched presently.) Thus $\Delta$, as a set, is $R^{n} \cup\{\infty\}$. Give $\Delta$ the topology of the one-point compactification of $R^{n}$. Since $\hat{f}(t) \rightarrow 0$ as $|t| \rightarrow \infty$, for every $f \in L^{1}\left(R^{n}\right)$, it follows from (6) and (7) that $\hat{A} \subset C(\Delta)$. Since $\hat{A}$ separates points on $\Delta$, the weak topology induced on $\Delta$ by $\hat{A}$ is the same as the one that we just chose.

It remains to be proved that every $h \in \Delta$ is of the form (6) or (7). If $h(f)=0$ for every $f \in L^{1}\left(R^{n}\right)$, then $h=h_{\infty}$. Assume $h(f) \neq 0$ for some $f \in L^{1}\left(R^{n}\right)$. Then $h(f)=\int f \beta d m_{n}$, for some $\beta \in L^{\infty}\left(R^{n}\right)$. Since $h(f * g)=h(f) h(g)$, one can prove that $\beta$ coincides almost everywhere with a continuous function $b$ which satisfies

$$
b(x+y)=b(x) b(y) \quad\left(x, y \in R^{n}\right)
$$

Finally, every bounded solution of (8) is of the form

$$
b(x)=e^{-i x \cdot t} \quad\left(x \in R^{n}\right)
$$

for some $t \in R^{n}$. Thus $h(f)=\hat{f}(t)$, and $h$ has the form (6).

For $n=1$, the details that complete the preceding sketch may be found in Sec. 9.22 of [23]. The case $n>1$ is quite similar.

$(f)$ Our final example is $L^{\infty}(m)$. Here $m$ is Lebesgue measure on the unit interval $[0,1]$, and $L^{\infty}(m)$ is the usual Banach space of equivalence classes (modulo sets of measure 0 ) of complex bounded measurable functions on $[0,1]$, normed by the essential supremum. Under pointwise multiplication, this is obviously a commutative Banach algebra.

If $f \in L^{\infty}(m)$ and $G_{f}$ is the union of all open sets $G \subset \mathbb{C}$ with $m\left(f^{-1}(G)\right)=0$, then the complement of $G_{f}$ (called the essential range of $f$ ) is easily seen to coincide with the spectrum $\sigma(f)$ of $f$, hence with the range of its Gelfand transform $\hat{f}$. It follows that $\hat{f}$ is real if $f$ is real. Hence $L^{\infty}(m)^{\wedge}$ is closed under complex conjugation. By the Stone-Weierstrass theorem, $L^{\infty}(m)^{\wedge}$ is therefore dense in $C(\Delta)$, where $\Delta$ is the maximal ideal space of $L^{\infty}(m)$. It also follows that $f \rightarrow \hat{f}$ is an isometry, so that $L^{\infty}(m)^{\wedge}$ is closed in $C(\Delta)$.

We conclude that $f \rightarrow \hat{f}$ is an isometry of $L^{\infty}(m)$ onto $C(\Delta)$.

Next, $\hat{f} \rightarrow \int f d m$ is a bounded linear functional on $C(\Delta)$. By the Riesz representation theorem, there is therefore a regular Borel probability measure $\hat{m}$ on $\Delta$ that satisfies

$$
\int_{\Delta} \hat{f} d \hat{m}=\int_{0}^{1} f d m \quad\left[f \in L^{\infty}(m)\right]
$$

If $\Omega$ is a nonempty open set in $\Delta$, Urysohn's lemma implies that there exists $\hat{f} \in C(\Delta), \hat{f} \geq 0$, such that $\hat{f}=0$ outside $\Omega$, and $\hat{f}(p)=1$ at some $p \in \Omega$. Hence $f$ is not the zero element of $L^{\infty}(m)$ and the integrals (10) are positive.

Thus $\hat{m}(\Omega)>0$ if $\Omega$ is open and nonempty.

Assume next that $\phi$ is a Borel function on $\Delta,|\phi| \leq 1$. By Lusin's theorem [23] there are functions $\hat{f}_{n} \in C(\Delta),\left|\hat{f}_{n}\right| \leq 1$, that converge to $\phi$ in the norm of $L^{2}(\hat{m})$. Since $f \rightarrow \hat{f}$ preserves complex conjugation (as we saw above) and is a homomorphism, it follows from (10), applied to $\left(f_{i}-f_{j}\right)\left(\bar{f}_{i}-\bar{f}_{j}\right)$, that

$$
\int_{\Delta}\left|\hat{f}_{i}-\hat{f}_{j}\right|^{2} d \hat{m}=\int_{0}^{1}\left|f_{i}-f_{j}\right|^{2} d m
$$

Thus $\left\{f_{n}\right\}$ is a Cauchy sequence in $L^{2}(m)$. Also, $\left|f_{n}\right| \leq 1$ a.e. $[m]$. Hence there exists $f \in L^{\infty}(m)$ such that $f_{n} \rightarrow f$ in $L^{2}(m)$, and now (11) implies that $\hat{f}_{n} \rightarrow \hat{f}$ in $L^{2}(\hat{m})$. The conclusion is that $\phi=\hat{f}$ a.e. $[\hat{m}]$ :

Every bounded Borel function $\phi$ on $\Delta$ coincides with some $\hat{f} \in C(\Delta)$ a.e. $[\hat{m}]$.

Thus $C(\Delta)$ and $L^{\infty}(\hat{m})$ are identical as Banach spaces!

Another consequence of the last result is that $\Delta$ is extremally disconnected. This means, by definition, that the closure of every open set is open. (Hence disjoint open sets have disjoint closures.)

To prove this, let $\Omega_{0}$ be open in $\Lambda$, let $\Omega_{1}$ be the complement of the closure $\bar{\Omega}_{0}$ of $\Omega_{0}$, let $\phi$ be the characteristic function of $\Omega_{1}$, and choose $\hat{f} \in C(\Delta)$ so that $\hat{f}=\phi$ a.e. $[\hat{m}]$. Since $\phi=0$ in $\Omega_{0}$ and since nonempty open sets have positive measure, the continuity of $\hat{f}$ shows that $\hat{f}(p)=0$ at every $p \in \Omega_{0}$. Likewise, $\hat{f}(p)=1$ if $p \in \Omega_{1}$. The set on which $\hat{f}$ is neither 0 nor 1 is open and has measure 0 , since $\hat{f}=\phi$ a.e. $[\hat{m}]$; hence it is empty. Let $K_{i}=\{p \in \Delta: f(p)=i\}, i=0,1$. Then $K_{0}$ and $K_{1}$ are disjoint compact sets whose union is $\Delta$. They are therefore open; also $\Omega_{0} \subset K_{0}, \Omega_{1} \subset K_{1}$. It follows that $\bar{\Omega}_{0}=K_{0}$, and the proof is complete.

We have also proved, incidentally, that boundaries of open sets have measure 0 , since $\hat{m}\left(\Omega_{0}\right)=\hat{m}\left(K_{0}\right)$.

We conclude with an application to measure theory. If $E$ and $F$ are measurable sets, let us say that $F$ almost contains $E$ if $F$ contains $E$ except for a set of measure 0, that is, if $m(E-F)=0$.

The union of an uncountable collection of measurable sets is not always measurable. However, the following is true:

If $\left\{E_{\alpha}\right\}$ is an arbitrary collection of measurable sets in $[0,1]$, therc is a measurable set $E \subset[0,1]$ with the following two properties:

(i) E almost contains every $E_{\alpha}$.

(ii) If $F$ is measurable and $F$ almost contains every $E_{\alpha}$, then $F$ almost contains $E$.

Thus $E$ is the least upper bound of $\left\{E_{\alpha}\right\}$. The existence of $E$ implies that the Boolean algebra of measurable sets (modulo sets of measure 0 ) is complete.

With the machinery now at our disposal, the proof is very simple.

Let $f_{\alpha}$ be the characteristic function of $E_{\alpha}$. Its Gelfand transform $\hat{f}_{\alpha}$ is then the characteristic function of an open (and closed) set $\Omega_{\alpha} \subset \Delta$. Let $\Omega$ be the union of all these $\Omega_{\alpha}$. Then $\Omega$ is open, so is its closure $\bar{\Omega}$, and there exists $f \in L^{\infty}(m)$ such that $\hat{f}$ is the characteristic function of $\bar{\Omega}$. The desired set $E$ is the set of all $x \in[0,1]$ at which $f(x)=1$.

\section{Involutions}
11.14 Definition A mapping $x \rightarrow x^{*}$ of a complex (not necessarily commutative) algebra $A$ into $A$ is called an involution on $A$ if it has the following four properties, for all $x \in A, y \in A$, and $\lambda \in \mathbb{C}$ :

$$
\begin{aligned}
(x+y)^{*} & =x^{*}+y^{*} \\
(\lambda x)^{*} & =\lambda x^{*} \\
(x y)^{*} & =y^{*} x^{*} \\
x^{* *} & =x .
\end{aligned}
$$

In other words, an involution is a conjugate-linear antiautomorphism of period 2. Any $x \in A$ for which $x^{*}=x$ is called hermitian, or self-adjoint.

For example, $f \rightarrow \bar{f}$ is an involution on $C(X)$. The one that we will be most concerned with later is the passage from an operator on a Hilbert space to its adjoint.

11.15 Theorem If $A$ is a Banach algebra with an involution, and if $x \in A$, then

(a) $x+x^{*}, i\left(x-x^{*}\right)$, and $x x^{*}$ are hermitian,

(b) $x$ has a unique representation $x=u+i v$, with $u \in A, v \in A$, and both $u$ and $v$ hermitian,

(c) the unit e is hermitian,

(d) $x$ is invertible in $A$ if and only if $x^{*}$ is invertible, in which case $\left(x^{*}\right)^{-1}=\left(x^{-1}\right)^{*}$, and

(e) $\lambda \in \sigma(x)$ if and only if $\bar{\lambda} \in \sigma\left(x^{*}\right)$.

PROOF Statement $(a)$ is obvious. If $2 u=x+x^{*}, 2 v=i\left(x^{*}-x\right)$, then $x=u+i v$ is a representation as in (b). Suppose $x=u^{\prime}+i v^{\prime}$ is another one. Put $w=v^{\prime}-v$. Then both $w$ and $i w$ are hermitian, so that

$$
i w=(i w)^{*}=-i w^{*}=-i w
$$

Hence $w=0$, and the uniqueness follows.

Since $e^{*}=e e^{*},(a)$ implies $(c) ;(d)$ follows from $(c)$ and $(x y)^{*}=y^{*} x^{*}$. Finally, $(e)$ follows if $(d)$ is applied to $\lambda e-x$ in place of $x$.

11.16 Theorem If the Banach algebra $A$ is commutative and semisimple, then every involution on $A$ is coniinuous.

PROOF Let $h$ be a complex homomorphism of $A$, and define $\phi(x)=\bar{h}\left(x^{*}\right)$. Properties (1) to (3) of Definition 11.14 show that $\phi$ is a complex homomorphism. Hence $\phi$ is continuous. Suppose $x_{n} \rightarrow x$ and $x_{n}^{*} \rightarrow y$ in $A$. Then

$$
\bar{h}\left(x^{*}\right)=\phi(x)=\lim \phi\left(x_{n}\right)=\lim \bar{h}\left(x_{n}^{*}\right)=\bar{h}(y)
$$

Since $A$ is semisimple, $y=x^{*}$. Hence $x \rightarrow x^{*}$ is continuous, by the closed graph theorem.

11.17 Definition A Banach algebra $A$ with an involution $x \rightarrow x^{*}$ that satisfies

$$
\left\|x x^{*}\right\|=\|x\|^{2}
$$

for every $x \in A$ is called a $B^{*}$-algebra.

Note that $\|x\|^{2}=\left\|x x^{*}\right\| \leq\|x\|\left\|x^{*}\right\|$ implies $\|x\| \leq\left\|x^{*}\right\|$, hence also

$$
\left\|x^{*}\right\| \leq\left\|x^{* *}\right\|=\|x\|
$$

Thus

$$
\left\|x^{*}\right\|=\|x\|
$$

in every $B^{*}$-algebra. It also follows that

$$
\left\|x x^{*}\right\|=\|x\|\left\|x^{*}\right\|
$$

Conversely, (2) and (3) obviously imply (1).

The following theorem is the key to the proof of the spectral theorem that will be given in Chapter 12.

11.18 Theorem (Gelfand-Naimark) Suppose $A$ is a commutative $B^{*}$-algebra, with maximal ideal space $\Delta$. The Gelfand transform is then an isometric isomorphism of $A$ onto $C(\Delta)$, which has the additional property that

$$
h\left(x^{*}\right)=\overline{h(x)} \quad(x \in A, h \in \Delta)
$$

or, equivalently, that

$$
\left(x^{*}\right)^{\wedge}=\overline{\hat{x}} \quad(x \in A)
$$

In particular, $x$ is hermitian if and only if $\hat{x}$ is a real-valued function.

The interpretation of (2) is that the Gelfand transform carries the given involution on $A$ to the natural involution on $C(\Delta)$, which is conjugation. Isomorphisms that preserve involutions in this manner are often called *-isomorphisms.

PROOF Assume first that $u \in A, u=u^{*}, h \in \Delta$. We have to prove that $h(u)$ is real. Put $z=u+i t e$, for real $t$. If $h(u)=\alpha+i \beta$, with $\alpha$ and $\beta$ real, then

$$
h(z)=\alpha+i(\beta+t), \quad z z^{*}=u^{2}+t^{2} e
$$

so that

$$
\alpha^{2}+(\beta+t)^{2}=|h(z)|^{2} \leq\|z\|^{2}=\left\|z z^{*}\right\| \leq\|u\|^{2}+t^{2}
$$

or

$$
\alpha^{2}+\beta^{2}+2 \beta t \leq\|u\|^{2} \quad(-\infty<t<\infty)
$$

By (3), $\beta=0$; hence $h(u)$ is real.

If $x \in A$, then $x=u+i v$, with $u=u^{*}, v=v^{*}$. Hence $x^{*}=u-i v$. Since $\hat{u}$ and $\hat{v}$ are real, (2) is proved.

Thus $\hat{A}$ is closed under complex conjugation. By the Stone-Weierstrass : theorem, $\hat{A}$ is therefore dense in $C(\Delta)$.

If $x \in A$ and $y=x x^{*}$, then $y=y^{*}$ so that $\left\|y^{2}\right\|=\|y\|^{2}$. It follows, by induction on $n$, that $\left\|y^{m}\right\|=\|y\|^{m}$ for $m=2^{n}$. Hence $\|\hat{y}\|_{\infty}=\|y\|_{\text {, by the }}$ spectral radius formula and $(c)$ of Theorem 11.9. Since $y=x x^{*}$, (2) implies that $\hat{y}=|\hat{x}|^{2}$. Hence

$$
\|\hat{x}\|_{\infty}^{2}=\|\hat{y}\|_{\infty}=\|y\|=\left\|x x^{*}\right\|=\|x\|^{2},
$$

or $\|\hat{x}\|_{\infty}=\|x\|$. Thus $x \rightarrow \hat{x}$ is an isometry. Hence $\hat{A}$ is closed in $C(\Delta)$. Since $\hat{A}$ is also dense in $C(\Delta)$, we conclude that $\hat{A}=C(\Delta)$. This completes the proof.

The next theorem is a special case of the one just proved. We shall state it in a form that involves the inverse of the Gelfand transform, in order to make contact with the symbolic calculus.

11.19 Theorem If $A$ is a commutative $B^{*}$-algebra which contains an element $x$ such that the polynomials in $x$ and $x^{*}$ are dense in $A$, then the formula

$$
(\Psi f)^{\wedge}=f \circ \hat{x}
$$

defines an isometric isomorphism $\Psi$ of $C(\sigma(x))$ onto A which satisfies

$$
\Psi^{\prime} \hat{f}=(\Psi f)^{*}
$$

for every $f \in C(\sigma(x))$. Moreover, if $f(\lambda)=\lambda$ on $\sigma(x)$, then $\Psi f=x$.

PROOF Let $\Delta$ be the maximal ideal space of $A$. Then $\hat{x}$ is a continuous function on $\Delta$ whose range is $\sigma(x)$. Suppose $h_{1} \in \Delta, h_{2} \in \Delta$, and $\hat{x}\left(h_{1}\right)=\hat{x}\left(h_{2}\right)$, that is, $h_{1}(x)=h_{2}(x)$. Theorem 11.18 implies then that $h_{1}\left(x^{*}\right)=h_{2}\left(x^{*}\right)$. If $P$ is any polynomial in two variables, it follows that

$$
h_{1}\left(P\left(x, x^{*}\right)\right)=h_{2}\left(P\left(x, x^{*}\right)\right)
$$

since $h_{1}$ and $h_{2}$ are homomorphisms. By hypothesis, elements of the form $P\left(x, x^{*}\right)$ are dense in $A$. The continuity of $h_{1}$ and $h_{2}$ implies therefore that $h_{1}(y)=h_{2}(y)$ for every $y \in A$. Hence $h_{1}=h_{2}$. We have proved that $\hat{x}$ is oneto-one. Since $\Delta$ is compact, it follows that $\hat{x}$ is a homeomorphism of $\Lambda$ onto $\sigma(x)$.

The mapping $f \rightarrow f \circ \hat{x}$ is therefore an isometric isomorphism of $C(\sigma(x))$ onto $C(\Delta)$ which also preserves complex conjugation.

Each $f \circ \hat{x}$ is thus (by Theorem 11.18) the Gelfand transform of a unique element of $A$ which we denote by $\Psi f$ and which satisfies $\|\Psi f\|=\|f\|_{\infty}$. Assertion (2) comes from (2) of Theorem 11.18. If $f(\lambda)=\lambda$, then $f \circ \hat{x}=\hat{x}$, so that (1) gives $\Psi f=x$.

Remark In the situation described by Theorem 11.19, it makes perfectly good sense to write $f(x)$ for the element of $A$ whose Gelfand transform is $f \circ \hat{x}$. This notation is indeed frequently used. It extends the symbolic calculus (for these particular algebras) to arbitrary continuous functions on the spectrum of $x$, whether they are holomorphic or not.

The existence of square roots is often of special interest, and in algebras with involution one may ask under what conditions hermitian elements have hermitian square roots.

11.20 Theorem Suppose $A$ is a commutative Banach algebra with an involution, $x \in A, x=x^{*}$, and $\sigma(x)$ contains no real $\lambda$ with $\lambda \leq 0$. Then there exists $y \in A$ with $y=y^{*}$ and $y^{2}=x$.

Note that the given involution is not assumed to be continuous. We shall see later (Theorem 11.26) that commutativity can be dropped from the hypothesis.

PROOF Let $\Omega$ be the complement (in $\mathscr{C}$ ) of the set of all nonpositive real numbers. There exists $f \in H(\Omega)$ such that $f^{2}(\lambda)=\lambda$, and $f(1)=1$. Since $\sigma(x) \subset \Omega$, we can . define $y \in A$ by

$$
y=\tilde{f}(x)
$$

as in Definition 10.26. Then $y^{2}=x$, by Theorem 10.27. We will prove that $y^{*}=y$.

Since $\Omega$ is simply connected, Runge's theorem furnishes polynomials $P_{n}$ that converge to $f$, uniformly on compact subsets of $\Omega$. Define $Q_{n}$ by

$$
2 Q_{n}(\lambda)=P_{n}(\lambda)+\overline{P_{n}(\bar{\lambda})} .
$$

Since $f(\bar{\lambda})=\overline{f(\lambda)}$, the polynomials $Q_{n}$ converge to $f$ in the same manner. Define

$$
y_{n}=Q_{n}(x) \quad(n=1,2,3, \ldots)
$$

By (2), the polynomials $Q_{n}$ have real coefficients. Since $x=x^{*}$, it follows that $y_{n}=y_{n}^{*}$. By Theorem 10.27,

$$
y=\lim _{n \rightarrow \infty} y_{n},
$$

since $Q_{n} \rightarrow f$, so that $Q_{n}(x) \rightarrow \tilde{f}(x)$. If the involution were assumed to be continuous, the set of hermitian elements would be closed, and $y^{*}=y$ would follow directly from (4).

Let $R$ be the radical of $A$. Let $\pi: A \rightarrow A / R$ be the quotient map. Define an involution in $A / R$ by

$$
[\pi(a)]^{*}=\pi\left(a^{*}\right) \quad(a \in A) .
$$

. If $a \in A$ is hermitian, so is $\pi(a)$. Since $\pi$ is continuous, $\pi\left(y_{n}\right) \rightarrow \pi(y)$. Since $A / R$ is isomorphic to $\hat{A}$ (Theorem 11.9), $A / R$ is semisimple, and therefore every involution in $A / R$ is continuous (Theorem 11.16). It follows that $\pi(y)$ is hermitian. Hence $\pi(y)=\pi\left(y^{*}\right)$.

We conclude that $y^{*}-y$ lies in the radical of $A$.

By Theorem 11.15, $y=u+i v$, where $u=u^{*}$ and $v=v^{*}$. We just proved that $v \in R$. Since $x=y^{2}$, we have

$$
x=u^{2}-v^{2}+2 i u v
$$

Let $h$ be any complex homomorphism of $A$. Since $v \in R, h(v)=0$. Hence $h(x)=$ $[h(u)]^{2}$. By hypothesis, $0 \notin \sigma(x)$. Thus $h(x) \neq 0$; hence $h(u) \neq 0$. By Theorem 11.5, $u$ is invertible in $A$. Since $x=x^{*}$, (6) implies that $u v=0$. Since $v=$ $u^{-1}(u v)$, we conclude that $v=0$. This completes the proof.

Remark If $\sigma(x) \subset(0, \infty)$, then also $\sigma(y) \subset(0, \infty)$. This follows from (1) (the definition of $y$ ) and the spectral mapping theorem.

\section{Applications to Noncommutative Algebras}
Noncommutative algebras always contain commutative ones. Their presence can sometimes be exploited to extend certain theorems from the commutative situation to the noncommutative one. On a trivial level, we have already done this: In the elementary discussion of spectra, our attention was usually fixed on one element $x \in A$;
the (closed) subalgebra $A_{0}$ of $A$ that $x$ generates is commutative, and much of the discussion took place within $A_{0}$. One possible difficulty was that $x$ might have different spectra with respect to $A$ and $A_{0}$. There is a simple construction (Theorem 11.22) that circumvents this. Another device (Theorem 11.25) can be used when $A$ has an involution.

11.21 Centralizers If $S$ is a subset of a Banach algebra $A$, the centralizer of $S$ is the set

$$
\Gamma(S)=\{x \in A: x s=s x \text { for every } s \in S\} .
$$

We say that $S$ commutes if any two elements of $S$ commute with each other. We shall use the following simple properties of centralizers.

(a) $\Gamma(S)$ is a closed subalgebra of $A$.

(b) $S \subset \Gamma(\Gamma(S))$.

(c) If $S$ commutes, then $\Gamma(\Gamma(S))$ commutes.

Indeed, if $x$ and $y$ commute with every $s \dot{\in} S$, so do $\lambda x, x+y$, and $x y$; since multiplication is continuous in $A, \Gamma(S)$ is closed. This proves $(a)$. Since every $s \in S$ commutes with every $x \in \Gamma(S),(b)$ holds. If $S$ commutes, then $S \subset \Gamma(S)$, hence $\Gamma(S) \supset \Gamma(\Gamma(S)$ ), which proves $(c)$, since $\Gamma(E)$ obviously commutes whenever $\Gamma(E) \subset E$.

11.22 Theorem Suppose $A$ is a Banach algebra, $S \subset A, S$ commutes, and $B=$ $\Gamma(\Gamma(S))$. Then $B$ is a commutative Banach algebra, $S \subset B$, and $\sigma_{B}(x)=\sigma_{A}(x)$ for every $x \in B$.

PROOF Since $e \in B$, Section 11.21 shows that $B$ is a commutative Banach algebra that contains $S$. Suppose $x \in B$ and $x$ is invertible in $A$. We have to show that $x^{-1} \in B$. Since $x \in B, x y=y x$ for every $y \in \Gamma(S)$; hence $y=x^{-1} y x$, $y x^{-1}=x^{-1} y$. This says that $x^{-1} \in \Gamma(\Gamma(S))=B$.

11.23 Theorem Suppose $A$ is a Banach algebra, $x \in A, y \in A$, and $x y=y x$. Then

$$
\sigma(x+y) \subset \sigma(x)+\sigma(y) \quad \text { and } \quad \sigma(x y) \subset \sigma(x) \sigma(y) .
$$

Proor Put $S=\{x, y\}$; put $B=\Gamma(\Gamma(S))$. Then $x+y \in B, x y \in B$, and Theorem 11.22 shows that we have to prove that

$$
\sigma_{B}(x+y) \subset \sigma_{B}(x)+\sigma_{B}(y) \quad \text { and } \quad \sigma_{B}(x y) \subset \sigma_{B}(x) \sigma_{B}(y)
$$

Since $B$ is commutative, $\sigma_{B}(z)$ is the range of the Gelfand transform $\hat{z}$, for every $z \in B$. (The Gelfand transforms are now functions on the maximal ideal space of $B$.) Since

$$
(x+y)^{\wedge}=\hat{x}+\hat{y} \quad \text { and } \quad(x y)^{\wedge}=\hat{x} \hat{y}
$$

we have the desired conclusion.

Corollary If $C_{x}=R_{x}-L_{x}$, as in Section 10.37, then $\sigma\left(C_{x}\right) \subset \sigma(x)-\sigma(x)$.

PROOF If the theorem is applied to the commuting elements $R_{x}$ and $-L_{x}$ of the algebra $\mathscr{B}(A)$, the conclusion is

$$
\sigma\left(C_{x}\right) \subset \sigma\left(R_{x}\right)-\sigma\left(L_{x}\right)
$$

But $\sigma\left(R_{x}\right)=\sigma(x)=\sigma\left(L_{x}\right)$.

11.24 Definition Let $A$ be an algebra with an involution. If $x \in A$ and $x x^{*}=x^{*} x$, then $x$ is said to be normal. A set $S \subset A$ is said to be normal if $S$ commutes and if $x^{*} \in S$ whenever $x \in S$.

11.25 Theorem Suppose A is a Banach algebra with an involution, and B is a normal subset of $A$ that is maximal with respect to being normal. Then

(a) $B$ is a closed commutative subalgebra of $A$, and

(b) $\sigma_{B}(x)=\sigma_{A}(x)$ for every $x \in B$.

Note that the involution is not assumed to be continuous but that $B$ nevertheless turns out to be closed.

PROOF We begin with a simple criterion for membership in $B:$ If $x \in A$, if $x x^{*}=x^{*} x$, and if $x y=y x$ for every $y \in B$, then $x \in B$.

For if $x$ satisfies these conditions, we also have $x y^{*}=y^{*} x$ for all $y \in B$, since $B$ is normal, and therefore $x^{*} y=y x^{*}$. It follows that $B \cup\left\{x, x^{*}\right\}$ is normal. Hence $x \in B$, since $B$ is maximal.

This criterion makes it clear that sums and products of members of $B$ are in $B$. Thus $B$ is a commutative algebra.

Suppose $x_{n} \in B$ and $x_{n} \rightarrow x$. Since $x_{n} y=y x_{n}$ for ali $y \in B$, and multiplication is continuous, we have $x y=y x$ and therefore also

$$
x^{*} y=\left(y^{*} x\right)^{*}=\left(x y^{*}\right)^{*}=y x^{*}
$$

In particular, $x^{*} x_{n}=x_{n} x^{*}$ for all $n$, which leads to $x^{*} x=x x^{*}$. Hence $x \in B$, by the above criterion. This proves that $B$ is closed and completes $(a)$.

Note also that $e \in B$. To prove (b), assume $x \in B, x^{-1} \in A$. Since $x$ is normal, so is $x^{-1}$, and since $x$ commutes with every $y \in B$, so does $x^{-1}$. Hence $x^{-1} \in B$.

Our first application of this is a generalization of Theorem 11.20:

11.26 Theorem The word "commutative" may be dropped from the hypothesis of Theorem 11.20.

PROOF By Hausdorff's maximality theorem, the given hermitian (hence normal) $x \in A$ lies in some maximal normal set $B$. By Theorem 11.25 we can apply Theorem 11.20 with $B$ in place of $A$.

Our next application of Theorem 11.25 will extend some consequences of Theorem 11.18 to arbitrary (not necessarily commutative) $B^{*}$-algebras.

11.27 Definition In a Banach algebra with involution, the statement " $x \geq 0$ " means that $x=x^{*}$ and that $\sigma(x) \subset[0, \infty)$.

11.28 Theorem Every $B^{*}$-algebra $A$ has the following properties:

(a) Hermitian elements have real spectra.

(b) If $x \in A$ is normal, then $\rho(x)=\|x\|$.

(c) If $y \in A$, then $\rho\left(y y^{*}\right)=\|y\|^{2}$.

(d) If $u \in A, v \in A, u \geq 0$, and $v \geq 0$, then $u+v \geq 0$.

(e) If $y \in A$, then $y y^{*} \geq 0$.

(f) If $y \in A$, then $e+y y^{*}$ is invertible in $A$.

PROOF Every normal $x \in A$ lies in a maximal normal set $\bar{B} \subset A$. By Theorems 11.18 and $11.25, B$ is a commutative $B^{*}$-algebra which is isometrically isomorphic to its Gelfand transform $\hat{B}=C(\Delta)$ and which has the property that

$$
\sigma(z)=\hat{z}(\Delta) \quad(z \in B)
$$

Here $\sigma(z)$ is the spectrum of $z$ relative to $A, \Delta$ is the maximal ideal space of $B$, and $\hat{z}(\Delta)$ is the range of the Gelfand transform of $z$, regarded as an element of $B$. If $x=x^{*}$, Theorem 11.18 shows that $\hat{x}$ is a real-valued function on $\Delta$. Hence (1) implies (a).

For any normal $x$, (1) implies $\rho(x)=\|\hat{x}\|_{\infty}$. Also, $\|\hat{x}\|_{\infty}=\|x\|$, since $B$ and $\hat{B}$ are isometric. This proves $(b)$.

If $y \in A$, then $y y^{*}$ is hermitian. Hence (c) follows from $(b)$, since $\rho\left(y y^{*}\right)=$ $\left\|y y^{*}\right\|=\|y\|^{2}$.

Suppose now that $u$ and $v$ are as in $(d)$. Put $\alpha=\|u\|, \beta=\|v\|, w=u+v$, $\gamma=\alpha+\beta$. Then $\sigma(u) \subset[0, \alpha]$, so that

$$
\sigma(\alpha e-u) \subset[0, \alpha]
$$

and $(b)$ implies therefore that $\|\alpha e-u\| \leq \alpha$. For the same reason, $\|\beta e-v\| \leq \beta$. Hence

$$
\|\gamma e-w\| \leq \gamma .
$$

Since $w=w^{*},(a)$ implies that $\sigma(\gamma e-w)$ is real. Thus

$$
\sigma^{\prime}(\gamma e-w) \subset[-\gamma, \gamma],
$$

because of (3). But (4) implies that $\sigma(w) \subset[0,2 \gamma]$. Thus $w \geq 0$, and $(d)$ is proved.

We turn to the proof of $(e)$. Put $x=y y^{*}$. Then $x$ is hermitian, and if $B$ is chosen as in the first paragraph of this proof, then $\hat{x}$ is a real-valued function on $\Delta$. By (1), we have to show that $\hat{x} \geq 0$ on $\Delta$.

Since $\widehat{B}=C(\Delta)$, there exists $z \in B$ such that

$$
\hat{z}=|\hat{x}|-\hat{x} \quad \text { on } \Delta .
$$

Then $z=z^{*}$, because $\hat{z}$ is real (Theorem 11.18). Put

$$
z y=w=u+i v
$$

where $u$ and $v$ are hermitian elements of $A$. Then

$$
w w^{*}=z y y^{*} z^{*}=z x z=z^{2} x
$$

and therefore

$$
w^{*} w=2 u^{2}+2 v^{2}-w w^{*}=2 u^{2}+2 v^{2}-z^{2} x
$$

Since $u=u^{*}, \sigma(u)$ is real, by (a), hence $u^{2} \geq 0$, by the spectral mapping theorem. Likewise, $v^{2} \geq 0$. By (5), $\hat{z}^{2} \hat{x} \leq 0$ on $\Delta$. Since $z^{2} x \in B$, it follows from (1) that $\therefore-z^{2} x \geq 0$. Now (8) and $(d)$ imply that $w^{*} w \geq 0$.

But $\sigma\left(w w^{*}\right) \subset \sigma\left(w^{*} w\right) \cup\{0\}$ (Exercise 2, Chapter 10). Hence $w w^{*} \geq 0$. By (7), this means that $\hat{z}^{2} \hat{x} \geq 0$ on $\Delta$. By (5), this last inequality holds only when $\hat{x}=|\hat{x}|$. Thus $\hat{x} \geq 0$, and $(e)$ is proved.

Finally, $(f)$ is a corollary of $(e)$.

Equality of spectra can now be proved in yet another situation, in which commutativity plays no role.

11.29 Theorem Suppose $A$ is a $B^{*}$-algebra, $B$ is a closed subalgebra of $A, e \in B$, and $x^{*} \in B$ for every $x \in B$. Then $\sigma_{A}(x)=\sigma_{B}(x)$ for every $x \in B$.

PROOF Suppose $x \in B$ and $x$ has an inverse in $A$. We have to show that $x^{-1} \in B$. Since $x$ is invertible in $A$, so is $x^{*}$, hence also $x x^{*}$. Thus $\sigma_{A}\left(x x^{*}\right) \subset(0, \infty)$, by (e) of Theorem 11.28. Since $\sigma_{A}\left(x x^{*}\right)$ has connected complement in $\mathscr{C}$, Theorem 10.18 shows that $\sigma_{B}\left(x x^{*}\right)=\sigma_{A}\left(x x^{*}\right)$. Hence $\left(x x^{*}\right)^{-1} \in B$, and finally $x^{-1}=x^{*}\left(x x^{*}\right)^{-1} \in \boldsymbol{D}$.

\section{Positive Functionals}
11.30 Definition A positive functional is a linear functional $F$ on a Banach algebra $A$ with an involution, that satisfies

$$
F\left(x x^{*}\right) \geq 0
$$

for every $x \in A$. Note that $A$ is not assumed to be commutative and that continuity of $F$ is not postulated. (The meaning of the term "positive" depends of course on the particular involution that is under consideration.)

11.31 Theorem Every positive functional $F$ on a Banach algebra A with involution has the following properties:

(a) $F\left(x^{*}\right)=\overline{F(x)}$.

(b) $\left|F\left(x y^{*}\right)\right|^{2} \leq F\left(x x^{*}\right) F\left(y y^{*}\right)$.

(c) $|F(x)|^{2} \leq F(e) F\left(x x^{*}\right) \leq F(e)^{2} \rho\left(x x^{*}\right)$.

(d) $|F(x)| \leq F(e) \rho(x)$ for every normal $x \in A$.

(e) $F$ is a bounded linear functional on $A$. Moreover, $\|F\|=F(e)$ if $A$ is commutative, and $\|F\| \leq \beta^{1 / 2} F(e)$ if the involution satisfies $\left\|x^{*}\right\| \leq \beta\|x\|$ for every $x \in A$.

PROOF If $x \in A$ and $y \in A$, put

$$
p=F\left(x x^{*}\right), q=F\left(y y^{*}\right), r=F\left(x y^{*}\right), s=F\left(y x^{*}\right) .
$$

Since $F\left[(x+\alpha y)\left(x^{*}+\bar{\alpha} y^{*}\right)\right] \geq 0$ for every $\alpha \in \mathscr{C}$,

$$
p+\bar{\alpha} r+\alpha s+|\alpha|^{2} q \geq 0
$$

With $\alpha=1$ and $\alpha=i$, (2) shows that $s+r$ and $i(s-r)$ are real. Hence $s=\bar{r}$. With $y=e$, this gives $(a)$.

If $r=0,(b)$ is obvious. If $r \neq 0$, take $\alpha=t r /|r|$ in (2), where $t$ is real. Then (2) becomes

$$
p+2|r| t+q t^{2} \geq 0 \quad(-\infty<t<\infty)
$$

so that $|r|^{2} \leq p q$. This proves $(b)$.

Since $e e^{*}=e$, the first half of $(c)$ is a special case of $(b)$. For the second half, pick $t>\rho\left(x x^{*}\right)$. Then $\sigma\left(t e-x x^{*}\right)$ lies in the open right half-plane. By Theorem 11.26, there exists $u \in A$, with $u=u^{*}$, such that $u^{2}=t e-x x^{*}$. Hence

$$
t F(e)-F\left(x x^{*}\right)=F\left(u^{2}\right) \geq 0
$$

It follows that

$$
F\left(x x^{*}\right) \leq F(e) \rho\left(x x^{*}\right)
$$

This completes part $(c)$.

If $x$ is normal, i.e., if $x x^{*}=x^{*} x$, Theorem 11.23 implies that $\sigma\left(x x^{*}\right) \subset$ $\sigma(x) \sigma\left(x^{*}\right)$, so that

$$
\rho\left(x x^{*}\right) \leq \rho(x) \rho\left(x^{*}\right)=\rho(x)^{2} .
$$

Clearly, $(d)$ follows from (6) and $(c)$.

If $A$ is commutative, then $(d)$ holds for every $x \in A$, so that $\|F\|=F(e)$. If $\left\|x^{*}\right\| \leq \beta\|x\|,(c)$ implies $|F(x)| \leq F(e) \beta^{1 / 2}\|x\|$, since $\rho\left(x x^{*}\right) \leq\|x\|\left\|x^{*}\right\|$. This disposes of the special cases of part $(e)$.

Before turning to the general case, we observe that $F(e) \geq 0$ and that $F(x)=0$ for every $x \in A$ if $F(e)=0$; this follows from $(c)$. In the remainder of this proof we shall therefore assume, without loss of generality, that

$$
F(e)=1
$$

Let $\bar{H}$ be the closure of $H$, the set of all hermitian elements of $A$. Note that $H$ and $i H$ are real vector spaces and that $A=H+i H$, by Theorem 11.15. By $(d)$, the restriction of $F$ to $H$ is a real-linear functional of norm 1, which therefore extends to a real-linear functional $\Phi$ on $\bar{H}$, also of norm 1 . We claim that

$$
\Phi(y)=0 \quad \text { if } y \in \bar{H} \cap i \bar{H}
$$

for if $y=\lim u_{n}=\lim \left(i v_{n}\right)$, where $u_{n} \in H$ and $v_{n} \in H$, then $u_{n}^{2} \rightarrow y^{2}, v_{n}^{2} \rightarrow-y^{2}$, so that $(c)$ and $(d)$ imply

$$
\left|F\left(u_{n}\right)\right|^{2} \leq F\left(u_{n}^{2}\right) \leq F\left(u_{n}^{2}+v_{n}^{2}\right) \leq\left\|u_{n}^{2}+v_{n}^{2}\right\| \rightarrow 0 .
$$

Since $\Phi(y)=\lim F\left(u_{n}\right),(8)$ is proved.

By Theorem 5.20, there is a constant $\gamma<\infty$ such that every $x \in A$ has a representation

$$
x=x_{1}+i x_{2}, x_{1} \in \bar{H}, x_{2} \in \bar{H},\left\|x_{1}\right\|+\left\|x_{2}\right\| \leq \gamma\|x\|
$$

If $x=u+i v$, with $u \in H, v \in H$, then $x_{1}-u$ and $x_{2}-v$ lie in $\bar{H} \cap i \bar{H}$. Hence (8) yields

$$
F(x)=F(u)+i F(v)=\Phi\left(x_{1}\right)+i \Phi\left(x_{2}\right),
$$

so that

$$
|F(x)| \leq\left|\Phi\left(x_{1}\right)\right|+\left|\Phi\left(x_{2}\right)\right| \leq\left\|x_{1}\right\|+\left\|x_{2}\right\| \leq \gamma\|x\| .
$$

This completes the proof.

Exercise 13 contains further information about part $(e)$.

Examples of positive functionals - and a relation between them and positive measures-are furnished by the next theorem. It contains Bochner's classical theorem about positive-definite functions as a very special case. The identifications that lead from one to the other are indicated in Exercise 14.

11.32 Theorem Suppose $A$ is a commutative Banach algebra, with maximal ideal space $\Delta$, and with an involution that is symmetric in the sense that

$$
h\left(x^{*}\right)=\overline{h(x)} \quad(x \in A, h \in \Delta) .
$$

Let $K$ be the set of all positive functionals $F$ on $A$ that satisfy $F(e) \leq 1$. Let $M$ be the set of all positive regular Borel measures $\mu$ on $\Delta$ that satisfy $\mu(\Delta) \leq 1$. Then the formula

$$
F(x)=\int_{\Delta} \hat{x} d \mu \quad(x \in A)
$$

establishes a one-to-one correspondence between the convex sets $K$ and $M$, which carries extreme points to extreme points.

Consequently, the multiplicative linear functionals on A are precisely the extreme points of $K$.

PROOF If $\mu \in M$ and $F$ is defined by (2), then $F$ is obviousiy linear, and $F\left(x x^{*}\right)$ $=\int|\hat{x}|^{2} d \mu \geq 0$, because (1) implies that $\left(x x^{*}\right)^{\wedge}=|\hat{x}|^{2}$. Since $F(e)=\mu(\Delta)$, $F \in K$.

If $F \in K$, then $F$ vanishes on the radical on $A$, by $(d)$ of Theorem 11.31. Hence there is a functional $\hat{F}$ on $\hat{A}$ that satisfies $\hat{F}(\hat{x})=F(x)$ for all $x \in A$. In fact,

$$
|\hat{\Gamma}(\hat{x})|=|F(x)| \leq F(e) \rho(x)=F(e)\|\hat{x}\|_{\infty} \quad(x \in A)
$$

by $(d)$ of Theorem 11.31. It follows that $\hat{F}$ is a linear functional of norm $F(e)$ on the subspace $\hat{A}$ of $C(\Delta)$. This extends to a functional on $C(\Delta)$, with the same norm, and now the Riesz representation theorem furnishes a regular Borel measure $\mu$, with $\|\mu\|=F(e)$, that satisfies (2). Since

$$
\mu(\Delta)=\int_{\Delta} \hat{e} d \mu=F(e)=\|\mu\|
$$

we see that $\mu \geq 0$. Thus $\mu \in M$.

By (1), $\hat{A}$ satisfies the hypotheses of the Stone-Weierstrass theorem and is therefore dense in $C(\Delta)$. This implies that $\mu$ is uniquely determined by $F$.

One extreme point of $M$ is 0 ; the others are unit masses concentrated at points $h \in \Delta$. Since every complex homomorphism of $A$ has the form $x \rightarrow \hat{x}(h)$, for some $h \in \Delta$, the proof is complete.

We conclude by showing that the extreme points of $K$ are multiplicative even if (1) is not satisfied.

11.33 Theorem Let $K$ be the set of all positive functionals $F$ on a commutative Banach algebra $A$ with an involution, that satisfy $F(e) \leq 1$. If $F \in K$, then each of the ... following three properties implies the other two:

(a) $F(x y)=F(x) F(y)$ for all $x$ and $y \in A$.

(b) $F\left(x x^{*}\right)=F(x) F\left(x^{*}\right)$ for every $x \in A$.

(c) $F$ is an extreme point of $K$.

PROOF It is trivial that $(a)$ implies $(b)$. Suppose $(b)$ holds. With $x=e,(b)$ shows that $F(e)=F(e)^{2}$, and so $F(e)=0$ or $F(e)=1$. When $F(e)=0$, then $F=0$, by $(c)$ of Theorem 11.31, and so $F$ is an extreme point of $K$. Assume $\bar{F}(e)=1$, and $2 F=F_{1}+F_{2}, F_{1} \in K, F_{2} \in K$. We have to show that $F_{1}=F$. Clearly, $F_{1}(e)=1=F(e)$. If $x \in A$ is such that $F(x)=0$, then

$$
\left|F_{1}(x)\right|^{2} \leq F_{1}\left(x x^{*}\right) \leq 2 F\left(x x^{*}\right)=2 F(x) F\left(x^{*}\right)=0
$$

by $(b)$ and Theorem 11.31. Thus $F_{1}$ coincides with $F$ on the null space of $F$ and at $e$. It follows that $F_{1}=F$. Hence $(b)$ implies $(c)$.

To show that $(c)$ implies $(a)$, let $F$ be an extreme point of $K$. Either $F(e)=0$, in which case there is nothing to prove, or $F(e)=1$. We shall first prove a special case of $(a)$, namely,

$$
F\left(x x^{*} y\right)=F\left(x x^{*}\right) F(y) \quad(x \in A, y \in A) .
$$

Choose $x$ so that $\left\|x x^{*}\right\|<1$. By Theorem 11.20 , there exists $z \in A, z=z^{*}$, such that $z^{2}=e-x x^{*}$. Define

$$
\Phi(y)=F\left(x x^{*} y\right) \quad(y \in A) .
$$

Then

$$
\Phi\left(y y^{*}\right)=F\left(x x^{*} y y^{*}\right)=F\left[(x y)(x y)^{*}\right] \geq 0,
$$

and also

$$
(F-\Phi)\left(y y^{*}\right)=F\left[\left(e-x x^{*}\right) y y^{*}\right]=F\left(z^{2} y y^{*}\right)=F\left[(y z)(y z)^{*}\right] \geq 0
$$

Since

$$
0 \leq \Phi(e)=F\left(x x^{*}\right) \leq F(e)\left\|x x^{*}\right\|<1,
$$

(4) and (5) show that both $\Phi$ and $F-\Phi$ are in $K$. If $\Phi(e)=0$, then $\Phi=0$. If $\Phi(e)>0$, (6) shows that

$$
F=\Phi(e) \cdot \frac{\Phi}{\Phi(e)}+(F-\Phi)(e) \cdot \frac{F-\Phi}{F(e)-\Phi(e)}
$$

a convex combination of members of $K$. Since $F$ is extreme, we conclude that

$$
\Phi=\Phi(e) F
$$

Now (2) follows from (8) and (3).

Finally, the passage from (2) to $(a)$ is accomplished by any of the following identities, which are satisfied by every involution:

If $n=3,4,5, \ldots$, if $\omega=\exp (2 \pi i / n)$, if $x \in A$, and if $z_{p}=e+\omega^{-p} x$, then

$$
x=\frac{1}{n} \sum_{p=1}^{n} \omega^{p} z_{p} z_{p}^{*}
$$

The proof of (9) is a straightforward computation which uses the fact that

$$
\sum_{p=1}^{n} \omega^{p}=\sum_{p=1}^{n} \omega^{2 p}=0
$$


\end{document}